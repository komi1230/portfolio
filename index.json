[{"body":"DigdagとGCP Digdagはワークフローエンジンとして有名なソフトで、複数個のタスク間の依存関係からなるワークフローを定義し、そのワークフローの実行及び管理を行う。\n具体的に、複数テーブルのインポートを行いたいとなったとき、それらに対して逐次的にEmbulkを手で叩くのではなく、DigdagがうまいことEmbulkを叩いてくれる。\n+some_job: sh\u0026gt;: embulk run some_table.yaml.liquid そんなDigdagであるが、バッチ処理に非常によく使われるため、GCPやAWSに対応したコマンドがDigdag側に用意されている。 これは本来ならば上記のようにsh\u0026gt;オペレータでシェルでコマンドを叩くが、BigQuery関係だとbq\u0026gt;とかbq_ddl\u0026gt;といったコマンドが用意されている。\n+some_bq_job: bq\u0026gt;: queries/step.sql destination_table: other_project:other_dataset.other_table これは実質的にsh\u0026gt;: bq ...コマンドの糖衣構文だけど、これは比較的便利なのでよく利用される。\nGKEでのクレデンシャルのセット Digdagの公式ドキュメントにはbq\u0026gt;オペレータを利用する際はDigdagのSecretsにサービスアカウントキーをセットするよう書いてある。\nDigdagが動いているコンテナ内で以下のコマンドを叩けば良い。\n$ digdag secret --project [YOUR_PROJECT_NAME] --set gcp.credential=@/path/to/sa_key.json こうするとbq\u0026gt;オペレータを叩く際にこのサービスアカウントとして実行される。\nしかし、ここでポイントとして、このクレデンシャルはコンテナ全体でサービスアカウントが有効化されているわけではない。\nGKEでポッドの中に入ってクレデンシャルを叩くと、GKEを動作しているサービスアカウントが出てくる。\n$ gcloud config list サービスアカウントの有効化 bq\u0026gt;オペレータやbq_ddl\u0026gt;オペレータでは微妙にやりきれない作業などはたまにあり、その際は直接シェルでbqを叩きたいケースがある。\n例えばテーブルのスキーマに説明を付与したくて、そのスキーマ情報はJSONで保存されているときなど。\nこうした際はSQLにCREATE TABLE文でやる方法もあるが、それよりもbq updateでテーブル情報をアップデートする方が簡単だったりする。\nこの場合、意図的にDigdag内でサービスアカウントを有効化させるジョブを挟み込む必要があり、\n+auth_sa: sh\u0026gt;: gcloud auth activate-service-account --key-file=/path/to/sa_key.json +some_job: sh\u0026gt;: bq update my_dataset.my_table schema/my_table.json というようにすればサービスアカウントで実行ができる。\n","categories":["Tech"],"date":1616284800,"description":"DigdagとEmbulkでBigQueryにデータを流す際にクレデンシャルのスイッチでハマったポイント","permalink":"http://komi.dev/post/2021-03-21-gcp-credential-in-digdag/","publishdate":"2021-03-21T00:00:00Z","section":"post","tags":["digdag","gcp"],"title":"GKEにおけるDigdagでのGCPのクレデンシャルの取り扱い","url":"/post/2021-03-21-gcp-credential-in-digdag/"},{"body":"","categories":null,"date":1616284800,"description":"","permalink":"http://komi.dev/post/","publishdate":"0001-01-01T00:00:00Z","section":"post","tags":null,"title":"Posts","url":"/post/"},{"body":"今どんな仕事してるか 今年から新しい会社に転職し、1人目のデータエンジニアとして入社した。 組織規模はもうすでに300人を超えて(2021年3月現在)、それなりの規模の会社になってきているが、データ系のチームについてはこれから拡大していくということで、去年の10月くらいに声をかけてもらい入社することにした。\nデータチームを拡大/強化するといっても現在のデータチームはアナリストがほとんどで、基盤整備にあたる人間は正社員だとまだ自分だけという状況である。\n業務内容としてはまさに基盤整備といったところで、主に色々な部署にヒアリングしながらデータ連携をしたり分析しやすい形にデータを綺麗にしたり、というような業務を行なっている。 技術スタックとしてはどちらかというとインフラ寄りで、最近はずっとDigdagとEmbulk、Kubernetes、Terraformと格闘している。\nどうして転職したのか 前職はソフトバンクで、新卒入社し、入社式では新入社員600人以上の代表として答辞をしたりもした(コロナで入社式はリモートだったので答辞は3/31に会社に集まって社長の前で喋る様子を録画し、それを4/1に配信という感じだった)\n自分はいわゆるAI系の部署に配属され、行なっていた業務としては社内向けのWebアプリの開発で、GUIで機械学習ができるというようなものの開発にあたっていた。\n余談として、ソフトバンクの新卒入社は600人以上いて、そのうちエンジニアは400人弱いるのだが、配属部署の希望では7割程度がAI系に出すものの実際にAI系に配属されるのは30人もいないということで、自分は割と配属ガチャで当たりを引いた方だった。(面接の時点である程度確約してもらっていたのだけど) 実際、AI系の部署は非常にホワイトで、他部署からは羨ましがられる具合だった(セキュリティ系の部署だと非常に多忙らしい)\n当時働いていたときは本当に気楽で、心理的安全性が非常に高いので働くのはそこまで苦ではなく、在宅ということもあって学生時代から大して感覚が変わらずのんびりやっていた。\nそんな具合だったが、どうして転職したのかというと理由としては大きく2点あり、技術レベルの低さとキャリアの低迷。\n業務では主にReactとDjangoを触っていたのだけど、あらゆるところでクソコードが蔓延しており、同時にどう考えても設計ミスとしか言えないようなクソ設計がちらほらあり、ハウルの動く城のようなアプリが出来上がっていた。 どうしてこれがちゃんと動いているのだろうか、と思うような具合だった。 具体的にどんなやばいコードがあったかというと、\n Reactでフックを使えば状態管理を関数の中に押し込められるのになぜかReduxで状態をグローバルに持ってきてpropsバケツリレーを20個以上のコンポーネントでやっており、おかげでメンテナンス性の著しい低下と超絶低速な動作 API設計でJSONのボディで値に配列を入れられるようにすれば通信回数は1回で済むのにN個のパターンに対してN回APIを叩くというクソ設計で、超絶低速な動作  当然、こんなものを作り上げた同じチームの人間の技術レベルはたかが知れていて、それなのに我々は最先端な開発をしているんだという謎の陶酔があり、正直言ってもうこれは立て直しは厳しすぎるなと感じた。 在籍していた当時はなんとかリファクタリングをしまくってバグを取りまくったりとかなりコミットしたが、解決されるクソコードに対して生成されるクソコードの方が多く、本当に精神が摩耗する日々だった。\nプロダクト自体もかなりひどかったが開発体制もかなり酷く、DBの中のレコードの文字列を置換するだけの簡単なAPIを書くのに(1時間もあれば終わるだろうに)同期はなぜか3ヶ月かかっていて、それを誰もフォローしないという状況だった。 他にもドキュメントが全く整備されていないし誰も書かないのでAPIの仕様や設計が明文化されておらず、オンボーディングのハードルが超絶高い、という具合だった。\nもちろん働き方は非常にホワイトだったし自分自身も働き方に対して嫌な感情を抱くことはなかったが、とにかく働いてて楽しくなかった。\nこういう場所に長いこといると数年後には業界の最先端にすらついていけなくなると感じ、若手のうちにレベルの高い組織に身を置いておきたいという気持ちから転職を決意した。\n自分は何をやりたいのか さて、転職をすると決めたものの、どういう会社でどういうことをしようと考えなければならない。\nとりあえず動き出してみようということで転職したいとツイッターで表明した際は結構引く手は数多で、50社以上からDMをもらった。 これ以外にも転職サービス系のところでも毎日1, 2社からスカウトが届くといった具合で、自分は割と市場価値が高いんだなと改めて感じた。\nただ、自分がこうやって周りから欲しがられても自分自身何がしたいのか決めなければならない。\n色々考えた結果、自分はそこまでコードを書くことにはこだわりは無いなと思った。 そもそもで自分はどちらかというと職業エンジニアで、寝ても覚めてもプログラミングが大好きという部類ではない。 むしろ、少しの希少性と市場価値の高さからなんとなくエンジニアをやっているというだけで、技術に対してとても強い気持ちはあまりない。 OSSコミットもコミュニティへの貢献の意味があるけど、それを通して自分の市場価値を上げるというモチベーションの方が比較的大きい。\nまず満たされるべきはお金。 給料はある程度以上じゃないと自分は満足できないなと感じた。 ソフトバンク時代はとにかく給料が低く(もちろん都内でちゃんと生活できるレベルだが)、技術レベルと自分の市場価値からすると低かった。\n別に生活レベルを上げたいみたいな気持ちはなくて、食材も普通に安いスーパーに遠くてもわざわざ行くし、服はGUやしまむら。 お金を使いたいんじゃなくて、単純に口座にお金が貯まる様子を見るのが楽しいタイプの人間なので、そういう意味でお金は欲しかった。\nただ、何か飲み会だったり遊びに行くとなったときにお金を払うのに躊躇しないレベルになりたいとは思っていて、要するに気持ちの問題だったりする。\nこのお金を満たした上で何をしたいかと考えると、体験にお金を払いたいと思った。 これは旅行だったり、もしくは何かしらの成功体験だったり。 例えばゲームの課金もこれに類すると思う(自分はやらないけど)\nこういうことを考えたとき、体験を得るサービスを開発しているところに行けたらいいなと思い、マスに訴えかけるより小さな個人を応援するというような動きに魅力を感じるようになった。 小さな八百屋さんだったり雑貨作りが趣味の人だったりを支えるという行為に尊さを感じた。\nこのように考えたとき、今の会社は非常に考え方にマッチしているなと感じ、入社することにした。\n他に見ていた会社もいくつかあったけど、エンジニアのレベルが高くなかったり経営陣が微妙だったり、もしくは社風が明らかに自分と合わなかったりというのがあり、最終的に今の会社に落ち着いた。\n今働いててどうか 今の会社に入ってもうすぐで3ヶ月が経つ。 まだまだわからないことだったり大変なことはたくさんあるけど、今はすごく自分らしく働けていると思っている。\nプライベートも充実しており、変なストレスを抱えることも前に比べたらだいぶ減ったと思う。\n自分の技術レベルはそこまで高いわけでは無いけど、これからもなんとかキャッチアップしながらコミットしていきたいと感じている。\n将来的には起業したいと考えており、CEOじゃなくてCTOみたいなポジションでもいいのだけど、自分で事業をハンドリングできるようになりたくて、そのための修行としても今の環境は最高なんじゃないかと思う。 今の社長も上場経験者ということもあって、経営陣とはかなり距離が近いので自分自身の将来のチャレンジのためにたくさん吸収できるものは吸収していきたい。\n","categories":["Life"],"date":1616284800,"description":"自分がキャリアとしてどんなことをしたいか、そのためになぜ今の会社が良い場所だと感じたかについて書く","permalink":"http://komi.dev/post/2021-03-15-why-i-change-job/","publishdate":"2021-03-21T00:00:00Z","section":"post","tags":["career"],"title":"転職した理由","url":"/post/2021-03-15-why-i-change-job/"},{"body":"GitHub ActionsとCloud Run CI/CDというと有名なのはCircle CIだろう。 他にはTravis CIやGitLab CIあたり？(Travisはなんかもうすぐ死ぬみたいなのを聞いたような気もするけど)\nそんな中、GitHubが公式に提供しているCI/CDツールとしてGitHub Actionsがある。\n今回行っていた作業はGitHub ActionsからCloud RunへのCD環境を整えることだったのだけど、その過程で色々落とし穴にハマった。\nこれらのCI/CDツールはそれぞれで文法が異なっていたりしたことや、Cloud Runのサービスアカウントのセットにミスったことなどたくさん学んだことがあったので今回はここでまとめておこうと思う。\n設定ファイル 最終的な設定ファイルとしてはこのようになっている。\nname:DeploytoCloudRunon:push:branches:- masterenv:ENVIRONMENT:productionGCP_SA_KEY:${{secrets.GCP_SERVICE_ACCOUNT_KEY}}GCP_PROJECT_ID:${{secrets.GCP_PROJECT_ID}}GCP_REGION:${{secrets.GCP_REGION}}jobs:deploy:name:SetupECruns-on:ubuntu-lateststeps:- name:Checkoutuses:actions/checkout@v2# gcloudコマンドの設定- name:Installgcloudcommandandconfigurecredentialsuses:google-github-actions/setup-gcloud@v0.2.0with:service_account_key:${{env.GCP_SA_KEY}}project_id:${{env.GCP_PROJECT_ID}}# DockerにgcloudコマンドのCredentialを使わせる- name:AuthDockerwithgcloudcredentialsrun:| gcloud --quiet auth configure-docker# Dockerイメージを作成 (今回はとりあえずEcho Serverで)- name:BuildDockerimagerun:| docker pull ealen/echo-server# DockerイメージをContainer RegistryにPush- name:Publishimagerun:| export IMAGE_NAME=${ENVIRONMENT}_serverexportDOCKER_TAG=asia.gcr.io/${GCP_PROJECT_ID}/${IMAGE_NAME}:${GITHUB_SHA::8}dockertagealen/echo-server$DOCKER_TAGdockerpush$DOCKER_TAG- name:Deployrun:| gcloud run deploy sample-server \\--image$DOCKER_TAG\\--project$GCP_PROJECT_ID\\--region$GCP_REGION\\--platformmanaged\\--quiet割と簡単な感じなのだけど地味にハマったポイントがいくつかあったのでまとめておく。\nDockerにCloud SDKのCredentialを使わせる 当初はGitHub Actionsでgcloudコマンドを使えれば良いと思っていて、google-github-actions/setup-gcloudのREADMEに書いてある通りのことだけを設定ファイルに記述していた。\nしかし、今回はCloud Runにデプロイする関係で一度コンテナをContainer Registryへとあげておかなければならない。\nそのためにdocker pushコマンドを叩くわけだけども、このコマンドを叩くにはdocker自体がCloud SDKのCredentialを把握しておく必要がある。\nこれは\n$ gcloud --quiet auth configure-docker で実現される。\n環境変数とGitHub Actionsの変数で文法が違う GitHub Actionsでは環境変数とワークフロー内での変数はレイヤーが異なる。\nワークフロー内のenvオブジェクトに環境変数が入り込むのである。\nワークフロー変数(GITHUB_SHAやenv.GCP_PROJECT_IDなど)を使うには${{ some_value }}として使い、環境変数を使うには${some_value}か${{ env.some_value }}とすれば良い。\nこれの何にハマったかというと、環境変数については${some_value}はオッケーだが${ some_value }はダメなのである。\n空白を入れてはいけないというルール。\n同様に、ワークフロー変数については${{ GITHUB_SHA }}はオッケーだが${{GITHUB_SHA}}はダメである。\nこれに気づかずCIを30回以上コケさせた。\nGCPでの設定 GCPではやるべきことは\n GitHub Actionsで動かす用にサービスアカウントを作成 Cloud RunとContainer Registryで使えるロールを付与  の2点だけ。\nロールの付与については\n Service Account User Cloud Run Admin Storage Admin  の3つ。\nこれも結構簡単なのだが結構ハマった。\nContainer Registryという名のCloud Storage Container Registryはコンテナのデータベースという感じでDocker Hubみたいなものだが、中身はCloud Storageである。\nそのためサービスアカウントにはCloud Storageの権限を与えれば良いが、Cloud Storageの権限は\n ストレージの中身の操作に関するもの(閲覧、作成と消去) 別のサービスへストレージの中身を転送するもの  の2つがある。\nセキュリティの観点から最小限の権利だけを与えようと思って1つ目のもののAdminだけを設定したのだが、ずっとPermission Deniedになってしまっていた。\ndenied: Token exchange failed for project '[project-id]'. Caller does not have permission 'storage.buckets.create'. To configure permissions, follow instructions at: https://cloud.google.com/container-registry/docs/access-control 色々試してみた結果、Storage全体のAdmin権限を渡したら動くようになった。\nまとめ GitHub ActionsとCloud Runはめちゃくちゃ便利だけど少し慣れていないと罠にハマるので気をつけたい。\n","categories":["Tech"],"date":1611014400,"description":"GitHub ActionsとCloud Runは便利だがCI/CDの設定で今回陥った罠についてツラツラと書く","permalink":"http://komi.dev/post/2021-01-19-cloud-run-from-github-actions/","publishdate":"2021-01-19T00:00:00Z","section":"post","tags":["GitHub Actions","CI","GCP"],"title":"GitHub ActionsからCloud Runを叩く","url":"/post/2021-01-19-cloud-run-from-github-actions/"},{"body":"モチベーション 最近はWebRTCにハマっていて、別に何か作りたいものがあったからというわけでは無いのだけど単純に面白いから見ており、それに際してその周辺技術にぼちぼちコミットしたりしている(こんな感じ)。\nただ実際のところは本当に趣味といった具合なので詳細な部分についてはまだまだ勉強中だったりする。\nそんなわけでこの記事はある程度理解が進んだSDPについての勉強メモみたいな感じ。\nSDPとは まず最初にSDPとググるとだいたいゼロトラストの方のSDPが出てくる。\nゼロトラストのSDPはSoftware Defined Perimeterの略語で、WebRTCのSDPとは全くの別物であることに注意(ただ、WebRTCはP2P通信でファイアウォールなどのネットワークの壁をどう越えるかみたいなところが結構大変で、そこらへんの概念にゼロトラストのSDPみたいな考え方が出てきたりするので無関係というわけではなさそうだけども\u0026hellip;)。\nとりあえず今回の記事ではSDPとはSession Description Protocolだと最初に断っておきたい。\nオファーアンサーモデル さて、WebRTCにおけるSDPの話というわけだけど、WebRTCはP2P通信で、クライアントとクライアントが通信することになる。\n何を通信するかというと、音声だったりテキストだったり画像とか動画。 ただ、前提として各クライアントがどのメディアを使えるかはお互いに確認してみないと分からないのである。\nそこでお互いが何のメディアを使えるかを伝え合う所作をオファーアンサーモデルという。\n具体的には\nアリス「こっち電話とビデオいけるけどそっちどうよ？」 ボブ「あーこっち電話しか使えないんだわ」 的なやり取りである。\n仕様を眺めてみる SDPがP2P通信においてお互いがどのメディアを使用可能か確認するお作法であることはわかったので、具体的にどのようにやっていくかを見ていく。\nクライアント間では以下のようなデータがやり取りされる。\nv=0 o=jdoe 2890844526 2890842807 IN IP4 10.47.16.5 s=SDP Seminar i=A Seminar on the session description protocol u=http://www.example.com/seminars/sdp.pdf e=j.doe@example.com (Jane Doe) c=IN IP4 224.2.17.12/127 t=2873397496 2873404696 a=recvonly m=audio 49170 RTP/AVP 0 m=video 51372 RTP/AVP 99 a=rtpmap:99 h263-1998/90000 このv=とかみたいなのはSDPにおけるDSLみたいなもので、それぞれがセッション情報だったり扱えるメディアについての情報、どのポート番号を解放するかなどを表している。\n簡単にいくと\n v= : セッションのバージョン番号。基本的に0で固定。 o= : 送信元の情報。 s= : セッション名。 i= : セッション情報。 u= : URI e= : メールアドレス。p=で電話番号が書かれることも。 c= : 接続データ。 b= : 帯域。 t= : タイミング、時間。スタートと終わりがUnixタイムで表現される。 r= : 繰り返し回数 z= : タイムゾーン k= : 暗号化キー a= : 属性情報、セッションの拡張情報 m= : メディア記述  という具合。\nこれらは全部が必須というわけではなくオプションのものもあるが、SDPの記述においてはいくつかの制約があったりする。\n具体的に言うと、例えばv=0などでは途中に空白を入れてはいけないことや、vやoなどの出現順序を間違えてはいけないことなどがある。\n詳しい話はこのSlideshareがめちゃくちゃわかりやすく解説してあるが、これの補足をいくつかしておく。\n m=行の数のオファーとアンサーで同一でなければいけないけど、互いに扱えるメディアの数が違う時はどうするの？  該当するメディアのポート番号を0として解放しない旨を示す   行の並びが指定されているけどm=が複数並んでる時は順序指定ってある？  audioを優先的に上にする。    ここら辺の仕様書は情報通信技術委員会が作ったものが参考になるので確認しよう。\nまた一番詳しいのはRFC4566なのでこれを読もう。\n","categories":["Tech"],"date":1609891200,"description":"WebRTCでは通信条件のネゴシエーションが必要だが、これを実現するためにSDPがある。ここではSDPがどのような形をしているかを見ていく。","permalink":"http://komi.dev/post/2021-01-06-about-sdp/","publishdate":"2021-01-06T00:00:00Z","section":"post","tags":["WebRTC","SDP"],"title":"WebRTCにおけるSDPを理解する","url":"/post/2021-01-06-about-sdp/"}]