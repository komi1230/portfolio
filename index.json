[{"body":"","categories":null,"date":1643155200,"description":"","permalink":"http://komi.dev/post/","publishdate":"0001-01-01T00:00:00Z","section":"post","tags":null,"title":"Posts","url":"/post/"},{"body":"Cocoaとは CocoaとはmacOSのAPI群の総称で、macOSに関する様々な機能がまとめてある。 例えば画面にウィンドウを描画するNSViewだったりOSのバージョンを出してくれるNSOperatingSystemVersionなどがある。 macOSは基本的にObjective-Cで実装されており、オブジェクト指向な設計となっているので自分たちでAPIを利用したアプリケーションを作る際は特定のクラスからサブクラスを作成して機能群を追加していくような具合となる。\nこのライブラリ系はmacOSでは/System/Library/Frameworks/を見てみると様々なframeworkが入っている。ここでframeworkとは動的共有ライブラリや nibファイル、imageファイル、ローカライズファイル、ヘッダファイル、ドキュメント等のリソースファイルを１つのパッケージにまとめたディレクトリ。\nRustから触る Rustはlinkアトリビュートを持っており、これを以下のように用いることで使える。\n#[link(name = \u0026#34;AppKit\u0026#34;, kind = \u0026#34;framework\u0026#34;)]extern\u0026#34;C\u0026#34;{}このコードではAppKitというframeworkを利用する際の宣言で、これによりobjcクレートを用いて\nuseobjc;fn main(){letcls=unsafe{objc::class!(NSView)};}として使える。\nちなみにlinkアトリビュートはexternとセットじゃないと意味がないらしく、\nuseobjc;#[link(name = \u0026#34;AppKit\u0026#34;, kind = \u0026#34;framework\u0026#34;)]fn main(){letcls=unsafe{objc::class!(NSView)};}というコードではエラーを吐いてしまう。\nobjc::class!マクロは内部的に\n#[macro_export]macro_rules!class{($name:ident)=\u0026gt;({#[allow(deprecated)]#[inline(always)]fn get_class(name: \u0026amp;str)-\u0026gt; Option\u0026lt;\u0026amp;\u0026#39;static$crate::runtime::Class\u0026gt;{unsafe{#[cfg_attr(feature = \u0026#34;cargo-clippy\u0026#34;, allow(replace_consts))]staticCLASS: ::std::sync::atomic::AtomicUsize=::std::sync::atomic::ATOMIC_USIZE_INIT;// `Relaxed` should be fine since `objc_getClass` is thread-safe. letptr=CLASS.load(::std::sync::atomic::Ordering::Relaxed)as*const$crate::runtime::Class;ifptr.is_null(){letcls=$crate::runtime::objc_getClass(name.as_ptr()as*const_);CLASS.store(clsasusize,::std::sync::atomic::Ordering::Relaxed);ifcls.is_null(){None}else{Some(\u0026amp;*cls)}}else{Some(\u0026amp;*ptr)}}}matchget_class(concat!(stringify!($name),\u0026#39;\\0\u0026#39;)){Some(cls)=\u0026gt;cls,None=\u0026gt;panic!(\u0026#34;Class with name {} could not be found\u0026#34;,stringify!($name)),}})}という具合でobjc::runtime::objc_getClass()という関数を叩いてクラスを呼び出しており、この関数自体は\n/// A marker type to be embedded into other types just so that they cannot be /// constructed externally. type PrivateMarker=[u8;0];/// A type that represents an Objective-C class. #[repr(C)]pubstruct Class{_priv: PrivateMarker,}#[link(name = \u0026#34;objc\u0026#34;, kind = \u0026#34;dylib\u0026#34;)]extern\u0026#34;C\u0026#34;{...pubfn objc_getClass(name: *constc_char)-\u0026gt; *constClass;...}というようにObjective-Cの関数となっている。\nこれらを用いてmacOSの機能を利用することができ、RustからMetalを触ることなどができる。\n終わりに ここ数日AlacrittyのIME対応のPRを出してやり取りしているのだけど、この実装の中でmacOSのクレート周りが非常に使いづらいことに気がつき、試験的に自分でmacOSのAPIラッパーを書けるか試していた。 そんな中で今回Rustのリンカー周りの挙動が気になったので調べてみた次第。\n","categories":["Tech"],"date":1643155200,"description":"RustからmacOSのAPIであるCocoaを触る際、どのようにリンクが行われるかについて見ていく","permalink":"http://komi.dev/post/2022-01-26-objc-from-rust/","publishdate":"2022-01-26T00:00:00Z","section":"post","tags":["Rust","macOS"],"title":"RustからCocoaを触る","url":"/post/2022-01-26-objc-from-rust/"},{"body":"はじめに 最近はデータに基づいた意思決定が云々ということで多くの組織でデータ基盤を整備する流れがある。\nデータ基盤の主要となるコンポーネントは何かというと、\n   コンポーネント 役割 例     BIツール データの可視化、ダッシュボードの構築 ReDash、Looker、Metabase   データウェアハウス 整備済みのデータを蓄積する場所 BigQuery, Redshift   データパイプライン アプリケーションDBからデータウェアハウスへデータを加工・転送するための基盤 Airflow, Luigi, Kubeflow, Argo Workflows、Digdag    というような感じになっていて、目的や供与可能なコスト分を考えながらここらへんをうまいこと組み合わせてデータ基盤というのは構築される。\n最近では多くの企業でデータエンジニアというポジションが募集されており、データエンジニアは何をしているかというとここらへんの構築・整備を行う。\n正直なところデータエンジニアの仕事というのはエンジニアリング的に難しいことは何もなくて、基本的に社内政治に振り回されながら泥臭い作業を行うだけの妖怪になるという悲しい役割に終始するのだけれど、ひとまず業務としてはワークフローエンジンの整備を行う。\nワークフローエンジンに何を使うかについては結構トレンドがあり、少し前(だいたい5年前とか？)はDigdagを使うのが主流だったのだけれど最近はユーザーも離れてしまいあまり開発も活発ではなくなってしまっており(DigdagはJavaで作られているのだが最近のLog4jの問題が発覚した際も関連Issueが全く立っていない)、今の流行りはAirflowあたりな気がしている。\nただ、最近AirflowからArgo Workflowsへ乗り換えようと検討するケースがたくさんあり、今後はArgo Workflowsがブームになりそうであるため、今回の記事ではArgo Workflowsについての基礎的な文法や色々についてまとめておこうと思う。\nArgo Workflowsについて Argo Workflowsは要するにただのワークフローエンジンなのだけれど、なぜAirflowなどと比較して良いとされているかというと以下のようなポイントがある。\n Kubernetesネイティブな設計となっており、ジョブごとにPodに切り分けて実行してくれるためコンピューティングリソースを有効活用できる ワークフロー定義などはKubernetesのマニフェストとなっていて、ワークフローの定義と各タスクにおけるロジックの関心が分離できる Airflowと同様のことができ、よりジェネラルなワークフローエンジンとなっている  AirflowやLuigiはPythonによってワークフローを記述していくが、Argo Workflowsはワークフロー自体はyamlで記述して各タスクについてはDockerイメージを実行するという機構になっているので、かなりジェネリックにタスクを投げることができる。\nデータエンジニアリングは基本的に付加的に要件が増えて様々なケースに対応する必要があり、差分デプロイが用意な機構となっているArgo Workflowsはデータエンジニアリングと非常に相性がいいのである。\nこうした点から最近はArgo Workflowsが使われるケースが増えている。\nということでArgo Workflowsについて簡単な解説をしようと思うのだけれど、日本ではArgo Workflowsを使っているケースがまだまだ少なく日本語の解説記事も少ないのでちょっとしたまとめを書いておこうと思う。\n環境構築 Argo Workflowsを使うにあたってまず準備する必要がある。\n本家のドキュメントを見てみるとQuick Startはあるようだけど、実際にプロダクション環境で使うにはどのようなマニフェストになるかについては詳しく書いてない(なんでやねん)\nということで基本的にQuick Startのやつを分解してプロダクション向けにカスタマイズしまくるのだけど、詳しいセットアップについては以下の記事を書いたので参照していただきたい。\nArgo Workflowsをセットアップする\n(会社のブログじゃなくてこっちのブログで書けばよかったな\u0026hellip;)\nArgo Workflowsのコンポーネント Argo Workflowsでは以下の概念がある。\n   概念 解説     Workflow 実行されるワークフローのこと   WorkflowTemplate 再利用性のあるワークフローで、ライブラリのように使える。他のWorkflowTemplateを参照でき、これをSubmitすることでWorkflowが実行される。   CronWorkflow Cronジョブで、WorkflowTemplateを指定する    例えばWorkflowの定義は以下のようになる。\napiVersion:argoproj.io/v1alpha1kind:Workflowmetadata:generateName:hello-namespace:argospec:entrypoint:exampleserviceAccountName:argo-satemplates:- name:examplesteps:- - name:print-messagetemplate:whalesayarguments:parameters:- name:messagevalue:\u0026#34;{{item}}\u0026#34;withItems:- hello world- goodbye world- name:whalesayinputs:parameters:- name:messagecontainer:image:docker/whalesay:latestcommand:[cowsay]args:[\u0026#34;{{inputs.parameters.message}}\u0026#34;]上記のマニフェストではtemplatesフィールドでWorkflowTemplateのリストが格納されており、それぞれにどのようなタスクをこなさせるかが記述される。\n見ての通りtemplate: whalesayとして他のWorkflowTemplateを呼び出しており、感覚として関数定義とその呼び出しに近い。\n一部で\u0026quot;{{...}}\u0026quot;という記述があるが、これはGoテンプレートの特徴で(ArgoはGoで開発されている)、ここにメタ的に変数を格納することができる。\n注意点としてserviceAccountNameというフィールドがあり、ここでどのKubernetesサービスアカウントを使うかを指定する必要がある(これを指定していないとデフォルトのサービスアカウントが使用され権限エラーでPodを作成することができなかったりする)\nfor文 loop系の処理をどのようにさせるかというと2通りのやり方があり、withItemsとwithSequence、withParamがある。\nwithItemsについては上記の例の通りでArray\u0026lt;String\u0026gt;の値として入れることによってその中身でループさせることができる。\nなお、ループで入る一時変数は\u0026quot;{{item}}\u0026quot;で受け取れる。\nwithSequenceについてはPythonでいるfor i in range(10, 20)のようなノリで、\n- name:sequence-start-endtemplate:echowithSequence:start:\u0026#34;100\u0026#34;end:\u0026#34;105\u0026#34;というように使える。\nまた、withSequenceの中身は\n- name:sequence-start-endtemplate:echowithSequence:count:\u0026#34;5\u0026#34;というようにcountを使っても良い。\nどのような範囲でループさせるかを動的に決定したい場合はwithParamを使えば良く、\nspec:entrypoint:loop-param-result-exampletemplates:- name:loop-param-result-examplesteps:- - name:generatetemplate:gen-number-list- - name:sleeptemplate:sleep-n-secarguments:parameters:- name:secondsvalue:\u0026#34;{{item}}\u0026#34;withParam:\u0026#34;{{steps.generate.outputs.result}}\u0026#34;- name:gen-number-listscript:image:python:alpine3.6command:[python]source:|import json import sys json.dump([i for i in range(20, 31)], sys.stdout)- name:sleep-n-secinputs:parameters:- name:secondscontainer:image:alpine:latestcommand:[sh, -c]args:[\u0026#34;echo sleeping for {{inputs.parameters.seconds}} seconds; sleep {{inputs.parameters.seconds}}; echo done\u0026#34;]というように最初のstepでパラメータを生成させて、それを利用させることができる。\n注意点としてパラメータのリストはJSONの形をしている必要がある。\nこの例ではscriptフィールドによってパラメータのリストを生成しているが、以下のようにコンテナ内のファイルについてループを回したいケースではbashでファイルのリストを生成して\u0026hellip;というやり方もできる。\nspec:serviceAccountName:argo-saentrypoint:sample-workflowtemplates:- name:sample-workflowsteps:# List tables- - name:tablestemplate:list-tables- - name:transformtemplate:transform-per-tablearguments:parameters:- name:messagevalue:\u0026#34;{{item}}\u0026#34;withParam:\u0026#34;{{steps.tables.outputs.result}}\u0026#34;- name:list-messagescontainer:image:image-name1command:[\u0026#34;/bin/bash\u0026#34;,\u0026#34;-c\u0026#34;]args:- |find ./sql -type f -name \u0026#34;*.sql\u0026#34; \\ | xargs -IFILENAME basename FILENAME .sql \\ | jq -R \\ | jq --slurp .- name:transform-per-tableinputs:parameters:- name:tablecontainer:image:image-name2command:[\u0026#34;./main.sh\u0026#34;]args:[\u0026#34;{{inputs.parameters.table}}\u0026#34;]引数にenumを使う 引数にはenumを指定することができ、\nspec:serviceAccountName:argo-saentrypoint:sample-workflowtemplates:- name:transform-per-tableinputs:parameters:- name:dbenum:- secure- normaldescription:\u0026#34;Select Database type\u0026#34;container:image:image-name2command:[\u0026#34;./main.sh\u0026#34;]args:[\u0026#34;{{inputs.parameters.db}}\u0026#34;]として引数のパターンを制限することでエラーケースを狭めることでテストを容易できる。\nif文 for文を実行できるので当然if文も使える。\nspec:serviceAccountName:argo-saentrypoint:sample-workflowtemplates:- name:sample-workflowsteps:# List tables- - name:tablestemplate:list-tables- - name:transformtemplate:transform-per-tablearguments:parameters:- name:messagevalue:\u0026#34;{{item}}\u0026#34;when:\u0026#34;{{inputs.parameters.tables}} =~ \u0026#39;^test_\u0026#39;\u0026#34;比較の部分については==といった等号判定や上記の例のように=~で正規表現を用いたパターンマッチもできる。\n環境変数 Argo Workflowsは本質的にKubernetesなので当然コンテナに環境変数を注入することもできる。\nspec:serviceAccountName:argo-saentrypoint:sample-workflowtemplates:- name:load-per-tableinputs:parameters:- name:dbenum:- secure- normaldescription:\u0026#34;Select Database type\u0026#34;container:image:image-namecommand:[\u0026#34;./main.sh\u0026#34;]args:[\u0026#34;{{inputs.parameters.db}}\u0026#34;]env:- name:ENVIRONMENTvalueFrom:configMapKeyRef:name:env-var-configkey:environment- name:AWS_ACCESS_KEY_IDvalueFrom:secretKeyRef:name:credentialskey:aws-access-key-id- name:AWS_SECRET_ACCESS_KEYvalueFrom:secretKeyRef:name:credentialskey:aws-secret-access-key- name:AWS_DEFAULT_REGIONvalue:ap-northeast-1中身としてはvalueで直接書き込むこともできるし、valueFrom.configMapKeyRefでConfigMapから読み取ったりvalueFrom.secretKeyRefでSecretから読み取ることもできる。\nこれで環境変数をコンテナ内に注入することができるが、もしargs:フィールド等でマニフェストとして利用する際は\ncontainer:image:image-namecommand:[\u0026#34;./main.sh\u0026#34;]args:[\u0026#34;$(ENVIRONMENT)\u0026#34;]env:- name:ENVIRONMENTvalueFrom:configMapKeyRef:name:env-var-configkey:environmentのように$(...)として丸括弧で括る必要があるので注意。\nSlack通知 ワークフローが落ちたときはSlack通知して欲しかったりする。\nそういうときはworkflow-controller-configmapに以下のデフォルトのワークフローの設定を追加すれば良い。\napiVersion:v1kind:ConfigMapmetadata:name:workflow-controller-configmapdata:workflowDefaults:|spec: onExit: exit-handler serviceAccountName: argo-sa templates: - name: exit-handler container: image: asia.gcr.io/my-repo/failure-alert:latest command: [ \u0026#34;bash\u0026#34;, \u0026#34;main.sh\u0026#34; ] env: - name: ENVIRONMENT valueFrom: configMapKeyRef: name: env-var-config key: environment - name: HOST valueFrom: configMapKeyRef: name: env-var-config key: host - name: WEBHOOK_URL valueFrom: secretKeyRef: name: credentials key: slack-webhook-url - name: WORKFLOW_STATUS value: \u0026#34;{{workflow.status}}\u0026#34; - name: WORKFLOW_NAME value: \u0026#34;{{workflow.name}}\u0026#34;この設定をすれば全ワークフローにこのテンプレートが追加され、onExitの条件からワークフローが終了した際はここで定義されたワークフローが実行される。\n実行されるスクリプトについては以下のようにSlack Webhook URLにcurlさせれば良い。\n#!/bin/bash  set -eu if [ \u0026#34;$ENVIRONMENT\u0026#34; = \u0026#34;dev\u0026#34; ]; then color=\u0026#34;good\u0026#34; elif [ \u0026#34;$ENVIRONMENT\u0026#34; = \u0026#34;stg\u0026#34; ]; then color=\u0026#34;warning\u0026#34; elif [ \u0026#34;$ENVIRONMENT\u0026#34; = \u0026#34;prd\u0026#34; ]; then color=\u0026#34;danger\u0026#34; else echo \u0026#34;Invalid value: ENVIRONMENT\u0026#34; exit 1 fi if [ \u0026#34;$WORKFLOW_STATUS\u0026#34; = \u0026#34;Succeeded\u0026#34; ]; then echo \u0026#34;Succeeded.\u0026#34; exit 0 fi curl \\  -X POST \\  -H \u0026#34;Content-type: application/json\u0026#34; \\  --data \\  \u0026#39;{ \u0026#34;attachments\u0026#34;: [ { \u0026#34;title\u0026#34;:\u0026#34;Workflow status: \u0026#39;$WORKFLOW_STATUS\u0026#39;\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;\u0026#39;$color\u0026#39;\u0026#34;, \u0026#34;fields\u0026#34;: [ { \u0026#34;title\u0026#34;: \u0026#34;Environment\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;\u0026#39;$ENVIRONMENT\u0026#39;\u0026#34;, \u0026#34;short\u0026#34;: false }, { \u0026#34;title\u0026#34;: \u0026#34;Workflow Name\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;\u0026#39;$WORKFLOW_NAME\u0026#39;\u0026#34;, \u0026#34;short\u0026#34;: true }, { \u0026#34;title\u0026#34;: \u0026#34;URL\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;https://\u0026#39;$HOST\u0026#39;/archived-workflows/argo/?phase=Failed\u0026#34;, \u0026#34;short\u0026#34;: false } ] } ] }\u0026#39; \\  \u0026#34;$WEBHOOK_URL\u0026#34; GKEでArgo Workflowsを利用する際の注意 Argo WorkflowsをGKEで利用する際、Workload Identityでサービスアカウント認証をしているケースで注意しておくことがある。\nそれは、GKEメタデータサーバーが新しく作成されたPodでリクエストの受信を開始できるようになるまでに数秒かかるため、そこでPodが作成されてからすぐだとGCP APIを使えない可能性がある。\nGKEでのWorkload Identityではサービスアカウントの認証は内部的に以下のようなエンドポイントに対してアクセストークンを払い出している。\ncurl -s \\  -H \u0026#39;Metadata-Flavor: Google\u0026#39; \\  \u0026#39;http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/token\u0026#39; Podが作成された直後はメタデータサーバーがそのPodを認識できないため、gcloudコマンドを叩いても認証エラーになるケースがあり、以下のようにinitContainersフィールドによってメタデータサーバーとの疎通を確認してからジョブを実行させると安定する。\napiVersion:argoproj.io/v1alpha1kind:WorkflowTemplatemetadata:name:foo-workflow-templatenamespace:argospec:serviceAccountName:argo-saentrypoint:foo-workflowtemplates:- name:hoge-workflow-load-per-tableinitContainers:- image:gcr.io/google.com/cloudsdktool/cloud-sdk:326.0.0-alpinename:workload-identity-initcontainercommand:- \u0026#39;/bin/bash\u0026#39;- \u0026#39;-c\u0026#39;- |curl -s -H \u0026#39;Metadata-Flavor:Google\u0026#39; \u0026#39;http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/token\u0026#39; --retry 30 --retry-connrefused --retry-max-time 30 \u0026gt; /dev/null || exit 1containers:- image:image-name...終わりに 今回書いた内容を押さえておけば恐らくArgo Workflowsは問題なく使えると思われる。\n今後どのワークフローエンジンが流行るのかわからないが、Argo Workflowsは極めて使いやすいため恐らく覇権を取れる気がする(?)\n","categories":["Tech"],"date":1641686400,"description":"データエンジニアリングの技術が成熟してきた中でまだポピュラーではないArgo Workflowsについてのちょっとした解説","permalink":"http://komi.dev/post/2022-01-09-introduction-to-argo-workflows/","publishdate":"2022-01-09T00:00:00Z","section":"post","tags":["Kubernetes","Argo Workflows"],"title":"Argo Workflowsの設定や文法","url":"/post/2022-01-09-introduction-to-argo-workflows/"},{"body":"Envoyとは EnvoyはL4/L7レイヤで動作するプロキシで、ロードバランスだったりネットワークとアプリケーションの分離なり、とても柔軟使えるOSS。 ネットワーク関係の色々困りごとを解消してくれる優れものだったりする。\n開発元はLyftで、急速に普及したマイクロサービスの分散システム構築・運用を安定させるため2015年5月から始まったプロジェクト。\n実装言語としてはC++が使われている。\n今回の記事では、そんなEnvoyをKubernetes上で動作するgRPCに対して適用させる。\ngRPCアプリとEnvoy gRPCとはHTTP/2上で動作するプロトコルで、JSONの強いバージョンみたいなもの。\nHTTP/2は普段慣れ親しんでいるHTTP/1.1と何が違うかというと\n バイナリベース ヘッダー圧縮 ストリーム  などの差分がある。\n1つ目のバイナリベースというのは、HTTP/1.1はテキストベースのプロトコルで各リクエストを受け取った際はテキストからバイナリへパースしてあげる必要があったのだけど、それが無駄ということでHTTP/2からはバイナリがデフォルトになり通信が高効率になった。\n2つ目のヘッダー圧縮というのは、ヘッダー情報にはどのHTTPメソッドを使っているかとかアクセスしているホストはどれだとか色々情報が格納されているのだけど、これを同じホストに対して複数回リクエストを飛ばすようなケース(Webサイトに対してHTMLファイルをリクエストしたあとCSSファイルをリクエストしたりする場合など)だとヘッダ情報には同じような情報ばかりでもう一度大量のヘッダ情報を送るのは無駄となってくる。 そのようなケースに対応するためにHTTP/2ではヘッダ情報には変更があった分だけ送るように変更される。\n3つ目のストリームは、もともとHTTP/1.1ではリクエストとレスポンスの組を1つずつしか同時に送受信できず、これがボトルネックとなっていたことからHTTP/2ではストリームという仮想的な双方向シーケンスを作り、それを多重化することで柔軟な通信が実現できるようになった。 ちなみにこの双方向シーケンスというとWebSocketにも同様の機能が提供されているのだけど(WebSocketの方がHTTP/2より簡単な実装になっている)、ここらへんの話は非常に長くなるのでまた別の機会に。\n今回出てくるgRPCはHTTP/2上で動作するプロトコルで、これは非常に高速で優秀であるが実はロードバランサと少々相性が悪い。 というのもHTTP/2の特徴としてストリームがあり、これはサーバーとクライアントの間のコネクション上にピタッと張られるもので、負荷が大きくなった際にサーバーを水平スケールさせるためには多少の工夫が必要となる。 つまり意図的にTLS終端を担ってくれるアプリケーションを中間に用意して別途アプリケーションへネットワークをリレーしてもらわないとHTTP/2の世界ではロードバランスできない。\nそこで今回出てくるのがEnvoyで、Serviceから飛んできたリクエストを一旦Envoyが受け取り、ロードバランスを考えてどのPodに受け渡すかを上手いことやってくれる。\n 実装する ということでマニフェストを眺めていく。\nまずEnvoyはDeploymentにてサイドカーとして立てるので、以下のように並べてあげる必要がある。\napiVersion:apps/v1kind:Deploymentmetadata:name:my-serverspec:selector:matchLabels:app:my-servertemplate:metadata:labels:app:my-serverspec:containers:- name:my-serverimage:gcr.io/my-app/some-image:latestargs:- /bin/lsports:- name:webcontainerPort:8888volumeMounts:- mountPath:/tmpname:tmp- name:envoyimage:envoyproxy/envoy:v1.20.0command:- \u0026#34;/usr/local/bin/envoy\u0026#34;args:- \u0026#34;--config-path /etc/envoy/envoy.yaml\u0026#34;resources:limits:memory:512Miports:- containerPort:15001name:app- containerPort:8001name:envoy-adminvolumeMounts:- name:envoymountPath:/etc/envoyvolumes:- name:envoyconfigMap:name:my-envoy-configmapポイントとしてEnvoyはAdmin用のポートとアプリケーションとしてのポートを別途開けておく必要がある。\nそしてEnvoyをどのように動作させるかはConfigMapに記述をする。\n以下がEnvoyのConfigMapとなる。\nちなみに以下の文法はEnvoyのv3 APIで、v1やv2とはやや異なることに注意。\napiVersion:v1kind:ConfigMapmetadata:name:my-envoy-configmapdata:# Adding new entries here will make them appear as files in the deployment.# Please update k8s.io/k8s.io/README.md when you update this fileenvoy.yaml:|static_resources: listeners: - address: socket_address: address: 0.0.0.0 port_value: 15001 filter_chains: - filters: - name: envoy.filters.network.http_connection_manager typed_config: \u0026#34;@type\u0026#34;: type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager codec_type: AUTO stat_prefix: ingress_http route_config: name: local_route virtual_hosts: - name: backend domains: - \u0026#34;*\u0026#34; routes: - match: prefix: \u0026#34;/\u0026#34; route: cluster: local_service http_filters: - name: envoy.filters.http.router typed_config: {} clusters: - name: local_service type: STRICT_DNS lb_policy: ROUND_ROBIN load_assignment: cluster_name: local_service endpoints: - lb_endpoints: - endpoint: address: socket_address: address: local_service port_value: 2746 admin: access_log_path: \u0026#34;/dev/null\u0026#34; address: socket_address: address: 0.0.0.0 port_value: 8001 layered_runtime: layers: - name: static_layer_0 static_layer: envoy: resource_limits: listener: example_listener_name: connection_limit: 10000だいたいは引数名を見ればどういう設定をしてるかがわかるが、listers内のフィルタ周りのところでどのドメインから来たリクエストをどのクラスタへルーティングする記述があり、ここで送るクラスタはclustersと同じ名前を設定する必要がある。\n終わりに 仕事でEnvoyを触る必要があり色々ググってみたところv3 APIの日本語記事が少なかったので書いてみた。\nここらへんの実装を終えてから実は要件としてEnvoyは必要がなかったということが発覚したのだけど、今回色々調査しながらEnvoyを触ったのでメモ。\n","categories":["Tech"],"date":1636934400,"description":"gRPCアプリケーションにてIngressからのリクエストに対してL7レイヤで動作するロードバランサを構築する","permalink":"http://komi.dev/post/2021-11-15-introduce-envoy/","publishdate":"2021-11-15T00:00:00Z","section":"post","tags":["Kubernetes","Envoy"],"title":"LoadBalancerとしてEnvoyを導入する","url":"/post/2021-11-15-introduce-envoy/"},{"body":"Cloud DNSとGoogle Domains、Cloud Domains Googleが提供しているDNS系のサービスとしてCloud DNSとGoogle Domains、Cloud Domainsの3つがある。 これらの違いは何かというと、\n    機能     Cloud DNS ゾーンとレコードの設定   Google Domains ドメインの取得、ネームサーバーの設定   Cloud Domains ドメインの取得、ネームサーバーの設定    となっている。 Google DomainsとCloud Domainsの機能はほぼ完全に被っているが、これはCloud Domainsが割と最近のサービスでGCPのコンソールからGoogle Domainsと同様のことができるようになったというのが理由となっている。 参考としてはCloud Domains のご紹介: カスタム ドメインの登録と管理を簡素化がちょうど良さそう。 なお、Cloud Domainsはこのドキュメントに書いてある通り、背後ではGoogle Domainsを登録事業者としているため、インターフェースの違いはあれど実質的に同じものと見て良い気がする。\nやってみる 今回の流れとして、何かしら自分のWebサイトにてドメインを当てたいケースを考える。 手元には複数サービスを立てたいため、example.com以外にfoo.example.comというようなサブドメインを作って各サービスを立てるものとする。 また、staging環境とproduction環境は分けたいため、staging環境ではhoge.staging.example.comというようなサブサブドメインで吸収する。\n以下、これをTerraformで実装していく。\nGoogle Domainsにてドメインを取得する これはサイトの通りに従って購入する。\nCloud DNSでゾーンを構成する 最初はProduction環境について。\nまず大元となるマネージドゾーンを構成する。\nresource \u0026#34;google_dns_managed_zone\u0026#34; \u0026#34;production\u0026#34; { name = \u0026#34;production\u0026#34; dns_name = \u0026#34;example.com.\u0026#34; description = \u0026#34;some description\u0026#34; } output \u0026#34;managed_zone\u0026#34; { description = \u0026lt;\u0026lt;DESC some description \u0026gt;\u0026gt; value = google_dns_managed_zone.production.name_servers } フィールドのdns_nameでは最後にピリオド.が必要だが、これはこれがドメインの末尾ですというのを示すために最後にピリオドをつける必要があり、注意。\nゾーンが構成されたら、立てたいサービスの分のグローバルIPを確保し、そのIPを用いてAレコードを構成する。\n// example.comに立てるサービス resource \u0026#34;google_compute_global_address\u0026#34; \u0026#34;service1_production\u0026#34; { name = \u0026#34;service1-production\u0026#34; } resource \u0026#34;google_dns_record_set\u0026#34; \u0026#34;service1\u0026#34; { name = google_dns_managed_zone.production.dns_name type = \u0026#34;A\u0026#34; ttl = 300 managed_zone = google_dns_managed_zone.production.name rrdatas = [google_compute_global_address.service1_production.address] }// service2.example.comに立てるサービス resource \u0026#34;google_compute_global_address\u0026#34; \u0026#34;service2_production\u0026#34; { name = \u0026#34;service2-production\u0026#34; } resource \u0026#34;google_dns_record_set\u0026#34; \u0026#34;service1\u0026#34; { name = \u0026#34;service2.${google_dns_managed_zone.production.dns_name}\u0026#34; type = \u0026#34;A\u0026#34; ttl = 300 managed_zone = google_dns_managed_zone.production.name rrdatas = [google_compute_global_address.service2_production.address] } さて、Production環境についてはこれでexample.comにservice1が、service2.example.comにservice2が立つようになった。\n次にStaging環境でこれを構成する。\n基本的には上記の通りIPを確保してAレコードを当てれば良いのだが、キーポイントとしてservice2.staging.example.comというようなサブドメインを駆使して環境差分(production/staging)を吸収するケースではstaging.example.comといった各環境ごとにゾーンを構成する方が構成として綺麗である。\n各環境ごとにゾーンを構成するためにはメインのゾーンから各環境を示すサブドメインに対してNSレコードを貼っておく必要がある。\n// NS record for staging resource \u0026#34;google_dns_record_set\u0026#34; \u0026#34;staging\u0026#34; { name = \u0026#34;staging.${google_dns_managed_zone.production.dns_name}\u0026#34; type = \u0026#34;NS\u0026#34; ttl = 300 managed_zone = google_dns_managed_zone.production.name rrdatas = google_dns_managed_zone.production.name_servers } この上で、ゾーンを構成し、各サービスについてのIPとレコードを構成する。\n// Staging Zone resource \u0026#34;google_dns_managed_zone\u0026#34; \u0026#34;staging\u0026#34; { name = \u0026#34;staging\u0026#34; dns_name = \u0026#34;example.com.\u0026#34; description = \u0026#34;some description\u0026#34; }// staging.example.comに立てるサービス resource \u0026#34;google_compute_global_address\u0026#34; \u0026#34;service1_staging\u0026#34; { name = \u0026#34;service1-staging\u0026#34; } resource \u0026#34;google_dns_record_set\u0026#34; \u0026#34;service1\u0026#34; { name = google_dns_managed_zone.staging.dns_name type = \u0026#34;A\u0026#34; ttl = 300 managed_zone = google_dns_managed_zone.staging.name rrdatas = [google_compute_global_address.service1.address] }// service2.staging.example.comに立てるサービス resource \u0026#34;google_compute_global_address\u0026#34; \u0026#34;service2_staging\u0026#34; { name = \u0026#34;service2-staging\u0026#34; } resource \u0026#34;google_dns_record_set\u0026#34; \u0026#34;service1\u0026#34; { name = \u0026#34;service2.${google_dns_managed_zone.staging.dns_name}\u0026#34; type = \u0026#34;A\u0026#34; ttl = 300 managed_zone = google_dns_managed_zone.staging.name rrdatas = [google_compute_global_address.service2.address] } Google Domainsにてネームサーバーを設定する ここまでできたらGoogle Domainsのカスタムネームサーバーにてゾーン構成時のネームサーバーを設定する。 ネームサーバーはgoogle_dns_managed_zoneリソースを実行した際にネームサーバーが自動的に設定される。\nまとめ 自分がこの作業をした際、staging.example.comのNSレコードを構成していなかったためstaging環境についてはドメインが無効で、これで数日溶かした。\nひとまずこれにて各環境差分を吸収しつつ複数サービスのドメインを設定できた。\n","categories":["Tech"],"date":1633996800,"description":"Cloud DNSでサブドメインを設定する際のマネージドゾーンなどについて","permalink":"http://komi.dev/post/2021-10-12-subdomain-with-cloud-dns/","publishdate":"2021-10-12T00:00:00Z","section":"post","tags":["DNS","Terraform","GCP"],"title":"Cloud DNSでのサブサブドメインの設定","url":"/post/2021-10-12-subdomain-with-cloud-dns/"},{"body":"Chromeでのみフォントが正しく読まれない問題 先日にブログを作り直し、現在はHugoを使ってGitHub Pages上でホスティングしている。 前までブログにははてなブログを利用していたのだが、広告が鬱陶しいと感じたため自分でホスティングし直すことにした。\nそんなわけでHugoのデザインテンプレートを利用したりして現在のブログがあるわけだけど、いつからかフォントが妙な動作をしていた。 というのも、SafariやiPhoneで見てみると正しく日本語のフォントが見えているが、なぜかChromeでのみフォントが中華フォントになっていた。\nコードを読み直してみてもカスタムCSSが適切に配置してある。 前まではChromeでもちゃんと動いていた気がするが、なにが起きていたのだろう。\n-apple-systemとBlinkMacSystemFont 使用していたデザインテンプレートのCSSではfont-familyに-apple-systemと書いてあった。 これをググってみると、どうやらSafariでは-apple-systemというのをfont-familyに指定しておけば英字書体にAppley用の英字フォント(San Francisco)が適用されるらしい。\nChromeでApple用英字フォントを使うにはBlinkMacSystemFontを指定する必要があるらしく、どうやらこれはWebkitから派生したレンダリングエンジン用フォントらしい。\nこれを適切に動作させるには-apple-systemと同時にBlinkMacSystemFontとも書いておく必要があったとのこと。\n結局どうしたか 特段フォントに対してこだわりはないので全て以下の通りに設定した。\nfont-family: Helvetica,\u0026#34;Sawarabi Gothic\u0026#34;,Meiryo,\u0026#34;メイリオ\u0026#34;,\u0026#34;Hiragino Kaku Gothic ProN\u0026#34;, \u0026#34;ヒラギノ角ゴ ProN\u0026#34;,YuGothic,\u0026#34;游ゴシック\u0026#34;,Arial,sans-serif; これでブラウザ依存の無いようにフォントが表示されるようになった。\n","categories":["Tech"],"date":1628640000,"description":"このブログで日本語フォントが中華フォントに化けてしまう問題とその直し方","permalink":"http://komi.dev/post/2021-08-11-font-in-chrome-and-safari/","publishdate":"2021-08-11T00:00:00Z","section":"post","tags":["Chrome","macOS","font"],"title":"Chromeでfont-familyを正しく設定する","url":"/post/2021-08-11-font-in-chrome-and-safari/"},{"body":"背景 先日なんとなくネットサーフィンしていたらターミナルアプリ一覧みたいな記事を見かけた。 自分は今まで惰性でmacOSでデフォルトでついているターミナルアプリを使っていて、特に不満はなかった。 範囲選択したときのハイライトが弱くて見にくかったというのはあるが\u0026hellip;.\nこの記事を見て色々試して、最初に紹介されていたAlacrittyというのを使ってみることにした。 どうやらRust製ということで速いらしい。\n早速試してみて、確かに速い。 ものすごく操作している感じが良く、URLをクリックするとブラウザに飛べるというありがたい機能も付いていた。\nしかし完璧ではなくて、日本語のIMEとあまり相性が良くなかった。 具体的にどういう症状があったかというと、\n 予測変換している段階だとターミナル上に字が出てこない 予測変換の際に候補を矢印キーで選択するとコマンドヒストリーが起動してしまう  などの問題があった。\nただ、自分は基本的にターミナルでは英語しか打ち込まないので問題ないと判断し、Alacriittyを普段使いに採用することにした。\nしかしやはり日本語入力が微妙なのは気になるもので、思い切って自分で直してみることにした。 気合を入れて本家のコードをforkしてきて「さあやってやるぞ」と手を入れ始めたのだが、これが地獄の入り口だった。\nObjective-C何もわからん問題 Alacrittyのコードを見てみると、GlutinというOpenGLユーティリティのようなクレートを使って画面を作ってるらしい。 つまりキー入力自体のハンドリングについては丸ごとそちら側に任せて、Alacritty自体はGlutinから受け取ったWindowEventをもとに表示をどうするかなどAPIを整えているという機能分割を行っていた。\nIssueを眺めていくとどうやらIMEの問題については既知だったらしく、いくつかIssueが立っていた(Cannot input japanese characters #1101, Support inline \u0026ldquo;input method\u0026rdquo; input #1613)\nディスカッションの様子を見ていると、どうやらAlacritty側に問題があるわけではなくWinitという低レベルOpenGLクレート側に問題があるらしい。\n依存関係としては Alacritty \u0026gt; Glutin \u0026gt; Winit となっているのだが、Glutinは内部で use winit::* ということをしていて実質的に何もしておらず、結論としてWinitを直せばAlacrittyが直るとのこと。(#comment)\nということでWinitの中身を見てみるが、やっていたことはObjective-Cのコードをひたすらラップしていたのである。 もちろん最終的には使いやすい形となるようWindowEvent関連の綺麗なstructやenumがまとまっているが、OSごとの差分をうまいこと吸収するために色々泥臭いことが行われており、そのうちmacOSの場合に行われていたのがObjective-Cのラップだった。\nちなみに最初のこの時点でIMEについては全く知らないしmacOSネイティブのアプリ開発の経験も無いからmacOSでのIME APIなんて何も知らない。 おかげさまで最初はWinitのコードを書いても何もわからなかった。\n調査を進めていく 何も知識が無くRustのコードが読み書きできる状態だったのでまずはコードを読んでわからない概念・単語を全てググっていく。\nNSViewとかNSTextView？てかNSって何の略？ コードを読んでいくとNSViewとかNSTextView、他にもNSRangeなどNSというPrefixがついた色々なものが出てくる。 もちろん知らない。\nググってみると以下の情報が出てきた。\n NeXTSTEP の権利がアップル社に移る時に開発言語のObjective-Cの権利もアップル社に移りました。そしてこのNeXTSTEPが現在のMac OS Xのベースになりました。また今から学習をはじめるObjective-Cには“NS”という文字で始まるクラスや関数が多数存在しています（クラスについては後の章で説明いたします）。このNSはNeXTSTEPの略称です。\n かつてAppleを追われたスティーブ・ジョブズはNeXTという会社を作ってNEXTSTEPというOSを販売していたが、Appleに吸収されその技術をベースに現在のmacOSができあがったため、NS〇〇というのはNeXT社の由来というものらしい。(引用元)\n逆に、今回Winitのデバッグで出てくるオブジェクトでNSというPrefixがついていればWinitではなくmacOS側のオブジェクトということになる。\nIMEを使うにはNSTextInputClientプロトコルを実装する(?) NSがmacOS側のオブジェクトというのはわかったが、ググってみるとNSTextInputClientプロトコルを実装すればIMEが機能するようになるらしい。\nプロトコルを実装するというのはピンとこなかったが、NSTextInputClientプロトコル内で使われるhasMarkedTextやselectedRange、insertTextなどの関数をアプリケーション内で動くように実装すればいいらしい。\n具体的に、例えば未確定文字列が存在するか確認するhasMarkedTextは以下のように実装する。\nextern\u0026#34;C\u0026#34;fn has_marked_text(this: \u0026amp;Object,_sel: Sel)-\u0026gt; BOOL{unsafe{trace!(\u0026#34;Triggered `hasMarkedText`\u0026#34;);letmarked_text: id=*this.get_ivar(\u0026#34;markedText\u0026#34;);trace!(\u0026#34;Completed `hasMarkedText`\u0026#34;);(marked_text.length()\u0026gt;0)asBOOL}}また、setMarkedTextは以下のようになる。\nextern\u0026#34;C\u0026#34;fn set_marked_text(this: \u0026amp;mutObject,_sel: Sel,string: id,_selected_range: NSRange,_replacement_range: NSRange,){trace!(\u0026#34;Triggered `setMarkedText`\u0026#34;);unsafe{letmarked_text_ref: \u0026amp;mutid=this.get_mut_ivar(\u0026#34;markedText\u0026#34;);let_: ()=msg_send![(*marked_text_ref),release];letmarked_text=NSMutableAttributedString::alloc(nil);lethas_attr=msg_send![string,isKindOfClass: class!(NSAttributedString)];ifhas_attr{marked_text.initWithAttributedString(string);}else{marked_text.initWithString(string);};*marked_text_ref=marked_text;}trace!(\u0026#34;Completed `setMarkedText`\u0026#34;);}この場合、事前にNSViewオブジェクト内にmarkedTextという変数を用意しておき、仮に日本語入力をしていて確定されてない文字列(未確定文字列、下線がついているやつ)があればOS側がsetMarkedTextを発火してこのmarkedTextに値を当て、hasMarkedTextはそれを参照する。\nNSTextInputClientとはこのようにキーを押したイベントに際して文字列入力の際の一連の処理を行ってくれる規則であり関数の発火を行ってくれるもので、プロトコルを実装するとは実際のアプリケーションでIMEを叩くために各関数の具体的な動作を定義する必要があるのである。\n試験的に動かす 今回Alacrittyを直すためだったが、修正に際して登場するクレートが3つもあるため、それぞれcloneしてくる。\nディレクトリの位置関係としては以下のようになる。\n. ├── alacritty/ │ ├── alacritty/ │ ├── alacritty_config_derive │ ├── alacritty_terminal │ ├── docs │ ├── extra ├── glutin │ ├── glutin │ ├── glutin_egl_sys │ ├── glutin_emscripten_sys │ ├── glutin_examples │ ├── glutin_gles2_sys │ ├── glutin_glx_sys │ └── glutin_wgl_sys └── winit ├── examples ├── src └── tests そしてAlacrittyをローカルで叩くが、依存するクレートをcrates.ioからとってくるのではなくローカルのものをとってきて欲しいのでCargo.tomlの依存クレートを以下のように直す。\nglutin = { version = \u0026quot;0.27.0\u0026quot;, default-features = false, features = [\u0026quot;serde\u0026quot;] } ↓ glutin = { path = \u0026quot;../../glutin/glutin\u0026quot;, version = \u0026quot;0.27.0\u0026quot;, default-features = false, features = [\u0026quot;serde\u0026quot;] } これでローカルのものを参照してくれる。 Glutinでも同様にローカルのWinitを参照するように直す。\nこれらをやった上でAlacrittyのリポジトリでcargo runをすればターミナルが立ち上がる。\nこれで準備OKになった。\nNSTextInputClientの挙動を修正する 下調べなどでものすごく時間がかかってしまったが、ようやく作業に取り掛かる。\nWinitではIMEの挙動を直すために色々structの仕様変更が入ったりしていたが、現在ではKeyboardInputというstructで未確定文字列の有無を格納するフィールドがある。 AlacrittyもWinitもIMEの修正に真っ最中らしく、Alacritty本体でもまだ未確定文字列の処理についてのハンドリングはfixされていない。(Alacrittyの中にskip_eventsという関数があり、その中にKeyboardInput { is_synthetic: true, ..}がある)\n今回動作確認するためにはまずAlacrittyがハンドリングするWindowEventで未確定文字列が存在する場合もキャッチして処理するようパターンマッチングの分岐条件を変更する。\nWindowEvent::KeyboardInput{input,is_synthetic: false,..}=\u0026gt;{processor.key_input(input);},↓WindowEvent::KeyboardInput{input,..}=\u0026gt;{processor.key_input(input);},次にWinitにて適切にKeyboardInputというstruct内にis_syntheticのboolが適切に入っているか確認する。\nが、見てみるとmacOSについてはまだ暫定的に全てfalseでは入るようになっている。 macOSについてはまだIME対応が完了していない中でstructの仕様を変更が入った経緯ということで、このようなコードになっていた。\n一旦これをいじって直して、早速実際のIMEのコードの修正に取り掛かる。\nsetMarkedTextとinsertTextとdoCommandBySelector IMEの修正にはmacOSのAPIを叩いているコードを障ればよく、Winitのsrc/platform_impl/macos/view.rsがそれに該当する。\nコードの見方として、中段くらいにあるlazy_static! { ... }の部分でクラスの宣言を行なっていてこの中にクラスメソッドや変数の宣言を行う。 宣言された関数についてはその後extern \u0026quot;C\u0026quot; fn ...のようにして具体的な関数の実装を行う。\n宣言されたクラスメソッドは色々あるが、この中でキー入力を担うのがsetMarkedTextとinsertTextとdoCommandBySelectorの3つで、それぞれの役割として\n   関数名 役割     setMarkedText 日本語などの入力の際に未確定の文字列をどう扱うかを決める。   insertText 確定文字列をフロントエンドに送る。英語入力の際はデフォルトでこれになる。   doCommandBySelector Cmd-sみたいなキーバインド。文字入力ではなくウィンドウ操作などが対象。    となっている。 文字列をフロントエンドに渡す操作はsetMarkedTextとinsertTextが担っている。\nsetMarkedTextでフロントに都度入力する フロントエンドに文字列を渡す方法として、以下のようにイベント情報のキューにpushしていく。\nletmutevents=VecDeque::with_capacity(characters.len());events.push_back(EventWrapper::StaticEvent(Event::WindowEvent{window_id: WindowId(get_window_id(state.ns_window)),event: WindowEvent::ReceivedCharacter(character),}));AppState::queue_events(events);この中のevent: WindowEvent::ReceivedCharacter(character)が肝で、insertTextではこのような操作を行なってくれているのだがsetMarkedTextはこの実装が行われていなかった。過去のログを探ってみたところ、どうやら実装者が英語圏の人でsetMarkedTextが何のためにあるのか知らなかったらしい。\nそんなわけでsetMarkedTextにも毎度フロントに文字列をpushするように変更。 setmarkedTextは各キー入力に対して毎回発火するので、全部入力するようにしているとねこと入力したらnねねkねこと何度も入力されまくることになる。 そのため毎回setMarkedTextが起動すると同時に直前の未確定文字列分だけDeleteキーを押す操作を擬似的に行わせる。\nこの操作として直前のカーソル位置の分だけまず全部削除して、その後新規の未確定文字列を全部入力させるという方針を取る。 つまり\nこんにちh ↓ (全部削除) ↓ こんにちは とした。 これで重複を無くすことができる。\n一つ要注意ポイントとして、Rustでは文字列型としてStringと\u0026amp;strがあるが、これらに対してtext.len()としてもUTF-8のデータ長が帰ってきてしまう。 つまり\u0026quot;こんにちは\u0026quot;.len()の値は15となってしまう。 そのため文字数をカウントする場合は\u0026quot;こんにちは\u0026quot;.chars().count()を使うのが正しい。\ninsertTextとsetMarkedTextの二重発火 これで完成かというとそうでもなく、macOSのAPIとして未確定文字列がある場合は毎回のキー入力に対してsetMarkedTextが起動するが、未確定文字列が確定された時はinsertTextが起動する。 つまりこのままだとこんにちはと入力した際にこんにちはこんにちはと2回入力される。 これを防ぐべく、isIMEActivatedという状態を示す変数をViewクラスに実装し、未確定文字列がある場合はtrueとなるようにした上で、これを起点にinsertTextの処理を適切にスキップさせれば良い。\n予測変換への対応 日本語入力を考えた時、漢字への変換などがある。 この変換は多くの場合はSpaceキーや矢印キーを用いて行われる(はず)なのだが、現状のままだと予測変換のためにSpaceキーを押したのに空白が入力されてしまったり、もしくは矢印キーを触ってコマンドヒストリーを取りに行ってしまったりする。\nそのため予測変換のためのキー操作をしているとき(未確定文字列が存在しているとき)、Spaceキーや矢印キーが押されたときは別の動作をさせる必要がある。 この処理はkeyDownの実装をいじれば良く、自前でis_arrow_or_space_keyのような関数を実装した上で、適切に処理をさせれば良い。\n以上でようやくmacOSにてAlacrittyでIMEが有効化されるようになった。\nまとめ 今回バグを直すためにIMEってナニソレ状態から調査を始めて、無事にバグを修正するところまで持っていけた。\nCocoaやAppkitの周辺の日本語情報はあまり転がっていなかったのでなかなか苦労したが、とても良い経験になった気がする。\n最後に出したPRはこちら。\n","categories":["Tech"],"date":1626739200,"description":"日本語のインライン入力を行うためのTextInputClientにおいて実装のメモ","permalink":"http://komi.dev/post/2021-07-20-enabling-ime-in-alacritty/","publishdate":"2021-07-20T00:00:00Z","section":"post","tags":["IME","macOS"],"title":"Alacrittyが日本語入力がおかしいのを直した","url":"/post/2021-07-20-enabling-ime-in-alacritty/"},{"body":"DigdagとGCP Digdagはワークフローエンジンとして有名なソフトで、複数個のタスク間の依存関係からなるワークフローを定義し、そのワークフローの実行及び管理を行う。\n具体的に、複数テーブルのインポートを行いたいとなったとき、それらに対して逐次的にEmbulkを手で叩くのではなく、DigdagがうまいことEmbulkを叩いてくれる。\n+some_job: sh\u0026gt;: embulk run some_table.yaml.liquid そんなDigdagであるが、バッチ処理に非常によく使われるため、GCPやAWSに対応したコマンドがDigdag側に用意されている。 これは本来ならば上記のようにsh\u0026gt;オペレータでシェルでコマンドを叩くが、BigQuery関係だとbq\u0026gt;とかbq_ddl\u0026gt;といったコマンドが用意されている。\n+some_bq_job: bq\u0026gt;: queries/step.sql destination_table: other_project:other_dataset.other_table これは実質的にsh\u0026gt;: bq ...コマンドの糖衣構文だけど、これは比較的便利なのでよく利用される。\nGKEでのクレデンシャルのセット Digdagの公式ドキュメントにはbq\u0026gt;オペレータを利用する際はDigdagのSecretsにサービスアカウントキーをセットするよう書いてある。\nDigdagが動いているコンテナ内で以下のコマンドを叩けば良い。\n$ digdag secret --project [YOUR_PROJECT_NAME] --set gcp.credential=@/path/to/sa_key.json こうするとbq\u0026gt;オペレータを叩く際にこのサービスアカウントとして実行される。\nしかし、ここでポイントとして、このクレデンシャルはコンテナ全体でサービスアカウントが有効化されているわけではない。\nGKEでポッドの中に入ってクレデンシャルを叩くと、GKEを動作しているサービスアカウントが出てくる。\n$ gcloud config list サービスアカウントの有効化 bq\u0026gt;オペレータやbq_ddl\u0026gt;オペレータでは微妙にやりきれない作業などはたまにあり、その際は直接シェルでbqを叩きたいケースがある。\n例えばテーブルのスキーマに説明を付与したくて、そのスキーマ情報はJSONで保存されているときなど。\nこうした際はSQLにCREATE TABLE文でやる方法もあるが、それよりもbq updateでテーブル情報をアップデートする方が簡単だったりする。\nこの場合、意図的にDigdag内でサービスアカウントを有効化させるジョブを挟み込む必要があり、\n+auth_sa: sh\u0026gt;: gcloud auth activate-service-account --key-file=/path/to/sa_key.json +some_job: sh\u0026gt;: bq update my_dataset.my_table schema/my_table.json というようにすればサービスアカウントで実行ができる。\n","categories":["Tech"],"date":1616284800,"description":"DigdagとEmbulkでBigQueryにデータを流す際にクレデンシャルのスイッチでハマったポイント","permalink":"http://komi.dev/post/2021-03-21-gcp-credential-in-digdag/","publishdate":"2021-03-21T00:00:00Z","section":"post","tags":["digdag","gcp"],"title":"GKEにおけるDigdagでのGCPのクレデンシャルの取り扱い","url":"/post/2021-03-21-gcp-credential-in-digdag/"},{"body":"GitHub ActionsとCloud Run CI/CDというと有名なのはCircle CIだろう。 他にはTravis CIやGitLab CIあたり？(Travisはなんかもうすぐ死ぬみたいなのを聞いたような気もするけど)\nそんな中、GitHubが公式に提供しているCI/CDツールとしてGitHub Actionsがある。\n今回行っていた作業はGitHub ActionsからCloud RunへのCD環境を整えることだったのだけど、その過程で色々落とし穴にハマった。\nこれらのCI/CDツールはそれぞれで文法が異なっていたりしたことや、Cloud Runのサービスアカウントのセットにミスったことなどたくさん学んだことがあったので今回はここでまとめておこうと思う。\n設定ファイル 最終的な設定ファイルとしてはこのようになっている。\nname:Deploy to Cloud Runon:push:branches:- masterenv:ENVIRONMENT:productionGCP_SA_KEY:${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}GCP_PROJECT_ID:${{ secrets.GCP_PROJECT_ID }}GCP_REGION:${{ secrets.GCP_REGION }}jobs:deploy:name:Setup ECruns-on:ubuntu-lateststeps:- name:Checkoutuses:actions/checkout@v2# gcloudコマンドの設定- name:Install gcloud command and configure credentialsuses:google-github-actions/setup-gcloud@v0.2.0with:service_account_key:${{ env.GCP_SA_KEY }}project_id:${{ env.GCP_PROJECT_ID }}# DockerにgcloudコマンドのCredentialを使わせる- name:Auth Docker with gcloud credentialsrun:|gcloud --quiet auth configure-docker# Dockerイメージを作成 (今回はとりあえずEcho Serverで)- name:Build Docker imagerun:|docker pull ealen/echo-server# DockerイメージをContainer RegistryにPush- name:Publish imagerun:|export IMAGE_NAME=${ENVIRONMENT}_server export DOCKER_TAG=asia.gcr.io/${GCP_PROJECT_ID}/${IMAGE_NAME}:${GITHUB_SHA::8} docker tag ealen/echo-server $DOCKER_TAG docker push $DOCKER_TAG- name:Deployrun:|gcloud run deploy sample-server \\ --image $DOCKER_TAG \\ --project $GCP_PROJECT_ID \\ --region $GCP_REGION \\ --platform managed \\ --quiet割と簡単な感じなのだけど地味にハマったポイントがいくつかあったのでまとめておく。\nDockerにCloud SDKのCredentialを使わせる 当初はGitHub Actionsでgcloudコマンドを使えれば良いと思っていて、google-github-actions/setup-gcloudのREADMEに書いてある通りのことだけを設定ファイルに記述していた。\nしかし、今回はCloud Runにデプロイする関係で一度コンテナをContainer Registryへとあげておかなければならない。\nそのためにdocker pushコマンドを叩くわけだけども、このコマンドを叩くにはdocker自体がCloud SDKのCredentialを把握しておく必要がある。\nこれは\n$ gcloud --quiet auth configure-docker で実現される。\n環境変数とGitHub Actionsの変数で文法が違う GitHub Actionsでは環境変数とワークフロー内での変数はレイヤーが異なる。\nワークフロー内のenvオブジェクトに環境変数が入り込むのである。\nワークフロー変数(GITHUB_SHAやenv.GCP_PROJECT_IDなど)を使うには${{ some_value }}として使い、環境変数を使うには${some_value}か${{ env.some_value }}とすれば良い。\nこれの何にハマったかというと、環境変数については${some_value}はオッケーだが${ some_value }はダメなのである。\n空白を入れてはいけないというルール。\n同様に、ワークフロー変数については${{ GITHUB_SHA }}はオッケーだが${{GITHUB_SHA}}はダメである。\nこれに気づかずCIを30回以上コケさせた。\nGCPでの設定 GCPではやるべきことは\n GitHub Actionsで動かす用にサービスアカウントを作成 Cloud RunとContainer Registryで使えるロールを付与  の2点だけ。\nロールの付与については\n Service Account User Cloud Run Admin Storage Admin  の3つ。\nこれも結構簡単なのだが結構ハマった。\nContainer Registryという名のCloud Storage Container Registryはコンテナのデータベースという感じでDocker Hubみたいなものだが、中身はCloud Storageである。\nそのためサービスアカウントにはCloud Storageの権限を与えれば良いが、Cloud Storageの権限は\n ストレージの中身の操作に関するもの(閲覧、作成と消去) 別のサービスへストレージの中身を転送するもの  の2つがある。\nセキュリティの観点から最小限の権利だけを与えようと思って1つ目のもののAdminだけを設定したのだが、ずっとPermission Deniedになってしまっていた。\ndenied: Token exchange failed for project '[project-id]'. Caller does not have permission 'storage.buckets.create'. To configure permissions, follow instructions at: https://cloud.google.com/container-registry/docs/access-control 色々試してみた結果、Storage全体のAdmin権限を渡したら動くようになった。\nまとめ GitHub ActionsとCloud Runはめちゃくちゃ便利だけど少し慣れていないと罠にハマるので気をつけたい。\n","categories":["Tech"],"date":1611014400,"description":"GitHub ActionsとCloud Runは便利だがCI/CDの設定で今回陥った罠についてツラツラと書く","permalink":"http://komi.dev/post/2021-01-19-cloud-run-from-github-actions/","publishdate":"2021-01-19T00:00:00Z","section":"post","tags":["GitHub Actions","CI","GCP"],"title":"GitHub ActionsからCloud Runを叩く","url":"/post/2021-01-19-cloud-run-from-github-actions/"},{"body":"モチベーション 最近はWebRTCにハマっていて、別に何か作りたいものがあったからというわけでは無いのだけど単純に面白いから見ており、それに際してその周辺技術にぼちぼちコミットしたりしている(こんな感じ)。\nただ実際のところは本当に趣味といった具合なので詳細な部分についてはまだまだ勉強中だったりする。\nそんなわけでこの記事はある程度理解が進んだSDPについての勉強メモみたいな感じ。\nSDPとは まず最初にSDPとググるとだいたいゼロトラストの方のSDPが出てくる。\nゼロトラストのSDPはSoftware Defined Perimeterの略語で、WebRTCのSDPとは全くの別物であることに注意(ただ、WebRTCはP2P通信でファイアウォールなどのネットワークの壁をどう越えるかみたいなところが結構大変で、そこらへんの概念にゼロトラストのSDPみたいな考え方が出てきたりするので無関係というわけではなさそうだけども\u0026hellip;)。\nとりあえず今回の記事ではSDPとはSession Description Protocolだと最初に断っておきたい。\nオファーアンサーモデル さて、WebRTCにおけるSDPの話というわけだけど、WebRTCはP2P通信で、クライアントとクライアントが通信することになる。\n何を通信するかというと、音声だったりテキストだったり画像とか動画。 ただ、前提として各クライアントがどのメディアを使えるかはお互いに確認してみないと分からないのである。\nそこでお互いが何のメディアを使えるかを伝え合う所作をオファーアンサーモデルという。\n具体的には\nアリス「こっち電話とビデオいけるけどそっちどうよ？」 ボブ「あーこっち電話しか使えないんだわ」 的なやり取りである。\n仕様を眺めてみる SDPがP2P通信においてお互いがどのメディアを使用可能か確認するお作法であることはわかったので、具体的にどのようにやっていくかを見ていく。\nクライアント間では以下のようなデータがやり取りされる。\nv=0 o=jdoe 2890844526 2890842807 IN IP4 10.47.16.5 s=SDP Seminar i=A Seminar on the session description protocol u=http://www.example.com/seminars/sdp.pdf e=j.doe@example.com (Jane Doe) c=IN IP4 224.2.17.12/127 t=2873397496 2873404696 a=recvonly m=audio 49170 RTP/AVP 0 m=video 51372 RTP/AVP 99 a=rtpmap:99 h263-1998/90000 このv=とかみたいなのはSDPにおけるDSLみたいなもので、それぞれがセッション情報だったり扱えるメディアについての情報、どのポート番号を解放するかなどを表している。\n簡単にいくと\n v= : セッションのバージョン番号。基本的に0で固定。 o= : 送信元の情報。 s= : セッション名。 i= : セッション情報。 u= : URI e= : メールアドレス。p=で電話番号が書かれることも。 c= : 接続データ。 b= : 帯域。 t= : タイミング、時間。スタートと終わりがUnixタイムで表現される。 r= : 繰り返し回数 z= : タイムゾーン k= : 暗号化キー a= : 属性情報、セッションの拡張情報 m= : メディア記述  という具合。\nこれらは全部が必須というわけではなくオプションのものもあるが、SDPの記述においてはいくつかの制約があったりする。\n具体的に言うと、例えばv=0などでは途中に空白を入れてはいけないことや、vやoなどの出現順序を間違えてはいけないことなどがある。\n詳しい話はこのSlideshareがめちゃくちゃわかりやすく解説してあるが、これの補足をいくつかしておく。\n m=行の数のオファーとアンサーで同一でなければいけないけど、互いに扱えるメディアの数が違う時はどうするの？  該当するメディアのポート番号を0として解放しない旨を示す   行の並びが指定されているけどm=が複数並んでる時は順序指定ってある？  audioを優先的に上にする。    ここら辺の仕様書は情報通信技術委員会が作ったものが参考になるので確認しよう。\nまた一番詳しいのはRFC4566なのでこれを読もう。\n","categories":["Tech"],"date":1609891200,"description":"WebRTCでは通信条件のネゴシエーションが必要だが、これを実現するためにSDPがある。ここではSDPがどのような形をしているかを見ていく。","permalink":"http://komi.dev/post/2021-01-06-about-sdp/","publishdate":"2021-01-06T00:00:00Z","section":"post","tags":["WebRTC","SDP"],"title":"WebRTCにおけるSDPを理解する","url":"/post/2021-01-06-about-sdp/"}]