[{"body":"","categories":null,"date":1687824000,"description":"","permalink":"http://komi.dev/post/","publishdate":"0001-01-01T00:00:00Z","section":"post","tags":null,"title":"Posts","url":"/post/"},{"body":"独立してから1年くらい経った 2022年の3月くらいにSTORESを退職して自営業に転じたわけだが、そこからだいたい1年以上経った。 1ヶ月だけフリーランスをやった後、Streetsを創業して取締役に就任して退任、現在はK Squadを専業としている。\n1年間を振り返ってみると本当に色んなことがあり、長かったようで短かったような、なんとも言えない思いがある。 本当に濃い1年間だった。\nK Squadも最初は1人で始めた会社だったが、気がついたら仲間も増えて7, 8人くらいのチームとなった。 大学の先輩や同期、後輩、これ以外にも飛び込みDMで来たやつ、紹介、ヘッドハンティングなど、色んな経緯で今のチームはできている。 奇しくも全員京大出身エンジニアという類は友を呼ぶ状態なのだが、一人一人を見てみると本当に個性豊かで得意分野も異なり、チームを組んで仕事をしてみると案外役割がダブること無く上手にワークしている。\nK Squadのメンバーは今のところ全員自立して仕事ができる人間であり、互いに信頼関係があることから仕事を任せまくっていて、特にマネジメントらしいことはしていないが仕事は回っている。 いわゆるティール組織っぽい感じになっているなと思う。\n仕事内容についても設立1年未満の零細企業とは思えないくらい大きなクライアントを複数抱えている。 設立当初は中小企業のクライアントをたくさん抱えていく方針を考えていたのだが、気がついたら顧客のほとんどが大企業となっている。 これについては少々誤算だった。 ただ、結果的に大きな仕事をさせてもらっているし様々な案件を任せてもらっていて、まだまだ大きなプロジェクトが複数動いており、人員ももっと必要なので今後は(仕事のクオリティを落とすことなく)組織を拡大させていきたい。\n会社の今後のことについてはよく考えているが、今回一応節目っぽいタイミングなのでこのエントリーでは過去1年間を振り返って得られた学びを簡単にまとめておこうと思う。\n学び 口約束は存在しないものだと思っておく 「そのうちメリットの大きい提案してあげるから！」「有力な大企業の担当者に繋げるから！」と言って実質的に何もしてくれない人間というは結構いる。 実際、過去を振り返ってみて「〇〇社の人紹介してあげるよ〜」と言って結果的に何もしてくれない人や、「御社の営業支援になるので協力お願いします！」と言って無償で手伝ったものの何も手応え無しだったり、そういう人間は結構いる。\nこのビジネスの世界というのは性善説で生きていると本当に痛い目を見る。 性根が腐ったクソ野郎だらけのこの世界では、実利的なメリットが無い提案は基本的に無視した方がいい。 正直者が馬鹿を見るというのはまさにこういうことなんだとこの1年で少なくとも5回はあった。 中には金を払うと言いながら一生払わず、最終的にこっち側が100万単位で損をするという事案もあった。\n取引をする際はまず最初にNDAを結んでから要件をヒアリングをし、その上で提案をして成約に至ったら契約書を巻く。 こういう正しいプロセスを経て初めて取引というのは行われる。\nただ実際問題、全ての案件をいちいち契約書を巻いてる暇はないというのはあると思う。 それでも個人的には契約書をちゃんと巻いてくれる人間以外は関わっちゃいけないと考えている。 契約書を巻く余裕がないからこそ、契約書は巻いた方がいい。 契約書というのはやばい状況にこそ有用だったりする。\n口約束だけで仕事を進めようとするヤツはさっさと関係を切った方が良い。\n顧客の言うことは2割くらい疑った方が良い いざ仕事を進めるにあたって、状況理解のために顧客に色々説明してもらうということはよくある話だが、ここの注意点として顧客の言っていることが必ずしも全て正しいとは限らない。 自分のほくろの位置を全部覚えていないように、顧客も自社のことを完全に把握できているわけではない。\n仕事を進める上で的確な進め方は、客観的な材料からロジックをもとにストーリー形成をし、顧客の言葉を検証していくこと。 話を聞いていて冷静に考えると顧客の言葉と状況が矛盾しているのはよくある。 場合によっては顧客自身よくわかっていない部分を推測でテキトーに喋っていたりする。\n言われたことを鵜呑みにせず頭を使って咀嚼していくことが本当に重要。\n心が貧乏な人間とは関わってはいけない 世の中、本当にどうしようもなく性根が貧乏な人間がいる。 これでもかと値切ってくる。\n基本的に貧乏人を相手していると本当に疲弊する。\n過去にあった案件として、Webサイトを作って欲しいと言われ、数十万円の見積もりを出したところ「3万円でやれ」と言われたことがある。 曰く、「既存サイトはホームページビルダーのようなものを使っており、これを使えば15分程度の作業で簡単に終わる。だからWebサイト制作にそこまで金を払う気はない」とのこと。 その案件については丁重に断りして連絡先をブロックした。\n貧乏人は往々にして安い支払いで多大な要求をしてくる。 一応これを捌いて儲けるという手段もあるが、これをするとメンバーが疲弊する。 K SquadみたいなITコンサルをやっている人間はこういう商売は絶対にやってはいけない。\nここで注意点なのは、我々が注意しなければいけないのは実際にお金を持っているかどうかではなく性根が貧乏であるかどうか。 お金は持っていないけどゆとりのある精神を持っている人は一定数いる。 そしてそういう人はだいたい出世する。\n値切ってくる人間には要注意しよう。\nマジメに生きていれば将来いつかプラスになる つい最近の出来事で、変なタイミングでK Squadに問い合わせをしてきてくれたお客さんがいた。 ここでいう変なタイミングとは、K Squadに問い合わせが入るタイミングというのは自分が登壇をしたりメディアに出たりしたときが普通で、それ以外のタイミングではあまり問い合わせは来ない。\n結果的にこのお客さんはかなり良い取引をさせてもらっているのだが、先日どういう経緯でK Squadに辿り着いたのか聞いたところ「小南が過去に強化学習の本を配っていたタイミングで知って、ふと思い出して声をかけさせてもらった」とのこと。\n自分は大学時代にスイスに留学をしていて、そこで奨学金をもらっていたのだが、この奨学金の給付がスイスに到着してから1ヶ月後であり現地での最初1ヶ月の生活費と航空券代は自費で用意しなければいけなかった。 当時は貧乏学生だったので当然そんな出費に耐えられず、自分で捻出する必要があった。 その当時では日立製作所で学生研究員をしていて強化学習に関する研究開発を行なっていたのだが、まだ強化学習について体系的にまとまった本が存在していなかったので自分が執筆して売ることにし、結果的に30万円ほど売り上げてスイス留学をやり切ったというエピソードがある。\nその時代の読者の一人がまさかの今の取引先で、過去の自分が一生懸命に生きていた結果こうして新たな仕事につながっている。 誰が見ているかわからないからこそ、常日頃からアウトプットをしつつ真面目に仕事をしておくもんだと思う。\n終わりに 改めて過去1年は事件もありつつ成長してきている。 事業家としてまだまだヒヨコであるが、これからもっと顧客にバリューを提供していき、更に成長できているように精進していきたい。\n","categories":["career"],"date":1687824000,"description":"仕事を進める上で、たくさんの出会いや失敗があり、そうした諸々について雑にまとめていく","permalink":"http://komi.dev/post/2023-06-27/","publishdate":"2023-06-27T00:00:00Z","section":"post","tags":["ksquad"],"title":"独立して1年ほど経って振り返り","url":"/post/2023-06-27/"},{"body":"ツイッターが死んでしまうという事実 去年イーロンマスクがツイッターを買収したのをきっかけとしてツイッターがいよいよ死にかけている。\n具体的に、APIが有料化されたことによって様々なサードパーティのアプリが使い物にならなくなったこと、140文字制限が撤廃されたこと、レコメンドアルゴリズムが変なこと。 他にも競合サービスの名前をツイートすると凍結されるなどかなり言論の自由が制限されている。\n色々あってもうツイッターは主要SNSとしてはもう限界が来ているらしい。\nツイッターの代替として今はBlueskyなりMisskeyなり色々サービスはあるが、どこが主要な移住先となるかは未だに不明。 ちなみに自分は今やBlueskyばかり見ている。\n自分はツイッターは高校生くらいに始めて、途中アカウント凍結に遭ったりして今使っているアカウントは6年くらいしか経っていないのだけど、それでもツイッターというサービスには長らくお世話になっていたから、このように自分が活発に活動していたプラットフォームが死ぬのはやはり厳しさを感じる。\nそのような郷愁は感じつつも、実利的な観点でツイッターが死ぬとケイスクワッド社として多少難しい状況となる。\n今回のエントリーではその点について思考整理していこうと思う。\nツイッターのフォロワーの多さで\u0026quot;スゴい人感\u0026quot;を演出していた 自分のツイッターアカウントはフォロワーが1.2万人ほどいる。 いわゆる万垢というやつだ。 そしてアカウントのブランディングとして\u0026quot;技術的知見がすごい若手\u0026quot;というような見られ方をしている。\nただ、ここは自分のブログなので正直なことを白状すると、自分は技術的に何か尖っているわけではないし(世間一般のエンジニアより優秀である自信はあるが)、そこまで面白いことを言っているわけではない。 実力以上に評価されてしまっている自覚がかなりある。 一応多少OSSにコミットしたりしていたが、それももう数年前の話でここ最近は全くOSSコミットをしていない。\nそんな自分でもエンジニア界隈・ビジネス界隈という結構狭いコミュニティの中でここまでフォロワー数を伸ばせたのは自分としても結構すごいと思う。 実際フォロワーが多いことから様々な取材を受けたり仕事をもらったり、結構なメリットを享受していた。\nそんな状況で今回ツイッターが死んでしまうのは自分としては少々の痛手となる。\nスタートアップは往々にして金もコネも無いのでなんとかして顧客と繋がる必要があり、自分はその起死回生の一打としてツイッターを利用していたのだが、これが絶たれることになってしまう。 ツイッターがサ終するかK Squadが十分な顧客基盤を作れるか、どちらが先か今かなり焦っている。\nYouTubeを始めた そんなわけで最近は第3の選択肢としてYouTubeを始めてみた。\nYouTube単体でマネタイズしようとは一切考えていないが、集客チャネルの1つとして育てていこうかなと考えている。\n自分がよく見ている税理士のチャンネルがあるのだが、そこでチャンネル解説から4ヶ月で登録者数が10万人を超え、問い合わせが毎日10件来るようになったと話していた。 若干数字を盛っているのかもしれないが、それでもある程度需要のあるコンテンツを発信していけば集客の一つの入り口になるらしい。\nK Squadでは技術顧問を今後メイン事業としていこうと考えており、そこで技術に関する雑多な話をYouTubeで展開していこうと考えている。 ちなみに今のところ技術顧問という単語ではチャンネルとしてYouTubeのSEOで一位を取れている。\n技術に関するトピックならそうそう簡単にはネタは尽きないはずなので、徐々にアカウントを育てていこうと思う。\n技術顧問という市場の開拓 ところで技術顧問というのを事業として真っ当に行っている会社はどうやら多くないらしい。\n一部ではコンサルティングという名の元に技術顧問をやっている会社はあるが、一般にITコンサルティングというのはプロジェクトありきで発注されるものなので、税理士のように定常的に頼むものではない。 技術顧問はITコンサルティングとは違ってプロジェクトが発生する前から会社と関わり、伴走形でITに関するセカンドオピニオンとして機能する。\n技術顧問とは経験値として以下のような企業には本当によく刺さるサービスらしい。\nエンジニアを雇うほどではないがITに関して助言をもらえる体制が欲しいという中小企業 ジュニアレベルのエンジニアはいるがシニアクラスのエンジニアがいない 今後これを幅広く展開していこうと考えていて、技術顧問という存在が税理士といった士業のようにポピュラーな存在になれば良いかなと考えている。\n終わりに ツイッターが死につつあるという時代の変化に対してK Squadも対応していかなければいけないが、今回YouTubeを始めるという投資が今後プラスに働いていけば良いかなと考えている。\n今後も頑張っていきたい。\n","categories":["career"],"date":1683504000,"description":"今までTwitterでのフォロワーの多さによって目立つことができていたが、Twitterが死につつあることで戦略を考えなければいけない","permalink":"http://komi.dev/post/2023-05-08/","publishdate":"2023-05-08T00:00:00Z","section":"post","tags":["ksquad","pr"],"title":"SNSとメディア露出、PR戦略","url":"/post/2023-05-08/"},{"body":"ケイスクワッドの動きが多少変わってきた 3月になり、花粉症がひどくなってきた。 ずっと市販薬でなんとかしていたが、先日とうとう意を決して耳鼻科に行って花粉症の薬を処方してもらったところ、劇的に改善した。 今はもうマスクせずとも平気で外を歩ける。 本当に調子が良いので花粉症に困っている人は全員耳鼻科行った方がいい。\nさて、花粉症の到来とともに春の訪れを感じるわけだけど、ケイスクワッドでも新しく案件が動き始め、これまでとはまた異なった動き方が出てきた。\n新しい仕事 内容としては京都に京都に週2, 3日滞在してオフィスに常駐する仕事が始まったこと、新しい環境で業務委託エンジニアとして働き始めたことの2つ。\n京都での仕事 元々技術顧問として開発周りだったり諸々を手伝わせていただいたお客さんから提案があり、3月から15人日/月オフィスに滞在して対面で仕事し始めた。 それまでは基本的にリモートで技術支援という形で携わっていたのだが、そこのチームの状況もあってリモートでは限界を感じていたところだったので、真にお客さんに貢献できるのであれば良い試みだと感じている。\n最近では障害対応のサポートに入って原因調査にかなり寄与したし、組織マネジメント手法としてグレード制度の提案など、様々なことを行えている。 主に任されている仕事が\n社内でも特殊な位置付けのプロジェクトの推進 現在のチームのサポーターとして各種アドバイザリー業務 新規事業提案 etc という具合で、雑多だが大きな仕事を任せてもらえているのは本当に感謝。\n始まってから2, 3週間くらいだが、明らかにリモート時代よりも様々な意思決定に携わることができておりケイスクワッドとしても成果を出せていると感じているので、引き続き続けていきたい。\nところで京都での仕事が始まってからでふと気づいたことなのだけど、リモートという働き方は相手にロジックを通すことはできてもエモ(=感情)は動かせないということ。 世の中は思ってたよりエモで動いている。 これは人間という生き物というか社会においてそういう感覚が一般的で、改めてソフトウェアエンジニアという生き物がいかに特殊であるかというのを京都で仕事を始めてからヒシヒシと感じている。\n新しい会社で業務委託 これに加え、最近は新しい会社で業務委託エンジニアをやっている。\n先日のエントリーの通り、ケイスクワッドはまだまだ創業から1年も経っておらず借入等も行なっていないので資金があまり無く、何かしら受託開発するにも自分が資金を稼いでこないとメンバーに渡す報酬が尽きて即資金ショートという状況である。 経営者としてこの状況があまり良くないことは理解しているが、一応今年はかなりの利益を積み上げられそうなので、コツコツ利益を上げていこうと考えている。\nさて、そんなことを先月くらいまで考えていたのだがこれまでの業務委託先から契約解除を言い渡されてしまったので、3月から新しい会社で業務委託エンジニアをやっている。 自分としてあまり強みと言えない技術スタックなのだが、爆速でキャッチアップして早速Issueをつぶしに行っているので4月からはかなり安定して良いパフォーマンスが出せるのではないかと感じている。\nかれこれエンジニアとしてある程度経験を積んできたのでだいたい新技術への取り組み方というのが自分の中で定式化できていて、なので今まであまり触れてこなかった技術だが今回割とすんなりインプットできているのは自分の成長だと思う。 ただ自分のパフォーマンスがチームにとって望ましいレベルかというのはよくよく意識しておかないといけないと感じていて、今後も緊張感を持ってやっていきたい。 ちなみにチームメンバーはかなり優秀な方なので、もっと頑張らなければと結構焦っている。\n友人からの経営アドバイス 新しい会社で業務委託を始める前後で野村證券に勤めている友人に仕事をもらえそうな人を紹介して欲しいと相談したところ、彼の顧客(=主に経営者)にITに強い人間の需要があるということを教えてもらった。 その話をする中で、ケイスクワッドは今後どのような取り組みをすべきかというのを相談してみた。\n今のケイスクワッドの課題としてあるのが、現状の顧客がTier1, Tier2クラスの大きい会社ばかりで中小企業のクライアントというのがほとんどいないこと。 一応現状でも資金繰りはある程度できているし利益も上がるのだが、この体制のまずいところは既存顧客から契約を切られると会社として急に窮地に陥ってしまうところ。 安定性が非常に低いのである。\nよく経営者向けのアドバイスとして言われるのが「収入源を1箇所に絞るのは危険、最低でも5箇所は確保しろ」というもので、現状ケイスクワッドの売上のほとんどを1つのクライアントに依存していて非常に良くない。 こうした状況を打開すべくSMB(=年商が数億円程度のクラス)にアプローチしたいのだが、アプローチ手段がわからない。\nこのことについて友人にアドバイスを求めたところ、結論から言うとWeb広告の出稿代行をやれば？とのこと。 今のケイスクワッドの見た目(技術顧問事業やデータ基盤構築などができるというアピール戦略)は少々とっつきづらく、Web技術などに理解が深くない人間にとっては要件定義とか言われてもフワッとよくわからんという具合なので、ぶっちゃけLPを見たところで相談しようとは思いづらいとのこと。 Web技術に全く強くない証券マンの彼がそう言うということはそうなのだろう。\n受託開発は一発の費用が数百万にもなるものなので気軽に相談できるものでもなく、もっと顧客が気軽に相談できるような糸口を作るべきだという指摘を受けた。 これが彼の提案するWeb広告で、少額から顧客との関わりを作れるような形を作り、そこで業務内容を聞いてITコンサル等へアップセルさせるというのが良いのではないかと提案してくれた。\n目から鱗だった。 散々周りに顧客志向で物事を考えろなんて言ってたのだが、自分が全く顧客の視点に立てていなかったことに気がついた。 自分は今まで関わっていたクライアントは、たしかにプログラミングこそできずともWeb技術にある程度の理解がある人だったのだ。 世の中にはWebサイトとネイティブアプリの区別がつかない人がかなりの数いるというのを認識から抜けていた。\nそこでWeb広告をケイスクワッドの事業の一つとして据えてみたところ、彼の紹介で早速仕事を1ついただけそう。 今回の案件が少々特殊なコミュニティなのだけど、ここを紹介で積み上げるだけで恐らく数年後には数億円とかになるかもしれないので、ケイスクワッドとして今後このような攻め方はありかもしれない。\nビジネスマッチングサービスを使いかけた 先述の通りSMBへのアプローチをどうするかというので、一旦ビジネスマッチングプラットフォームというやつを使ってみることにしてみた。\n1, 2回その手のサービスをやっている会社の営業から話を聞いてみたが、料金的に微妙だったりそこで得られる案件がどのくらいちゃんとしているかというのが確証が持てず、現状特に何か特定のサービスを使うには至っていない。\n自分の場合、野村證券の知り合いなど周りに仕事を回してくれそうな友人がまだまだいるので一旦は使わなくても良いのかも。 ただ来年以降で更に規模の拡大を見据えたときにもう一度検討しても良いかもしれない。\n今後の自分自身の身の振り方 3月から本格的に仕事が始まってケイスクワッドとして大きな仕事をできるようになった。 今まで会社の収入は自分が業務委託として稼いできた分だけだったので、今回法人として仕事を契約してまともに収入が得るのは実は今回が初めてなんじゃないかと思う(結局自分が稼働してるけども)。\nまだまだ起業してから半年。 反省点ばかりだがどんどんできることが広がってきた気がする。\nただ、ここでそろそろ自分も身の振り方というか自分の時間の使い方を考えた方が良いような気がしてきた。 具体的に、自分が業務委託エンジニアで稼いでくるという形をどこまで続けるかということ。\nお世話になっている先輩経営者(エンジニア出身)と食事に行った際、「自分がコード書いたらマジでスケールしないからコードは書けても書いちゃダメ」と言われた記憶がある。 アレはどういう文脈だったか覚えていないが、今のケイスクワッドはまさにそういうところがある気がしている。\n当面の資金確保のために今の業務委託先はしばらくは続けようと考えているが、どうするかは悩み中。 「収入を5箇所以上に分散させる」というやつが実現したときにまた考えようと思う。\n考えることが本当に多いし悩むこともあるが、選択肢はたくさんあるので実行あるのみ。\n","categories":["career"],"date":1679011200,"description":"会社として収支を安定させるためにも顧客数を増やすことが大切だと気づいた最近","permalink":"http://komi.dev/post/2023-03-17/","publishdate":"2023-03-17T00:00:00Z","section":"post","tags":["ksquad","life"],"title":"顧客数と社内リソースのスケーリング","url":"/post/2023-03-17/"},{"body":"会社として走り出した 2023年は頑張るぞと意気込みをまとめたエントリーを書いたのが1ヶ月前。\n現状どうなっているかというと資金ショートギリギリのラインを歩いている。\n状況を箇条書きにまとめると\n会社の口座残高は2023年2月末着地で130万円程度 来月は20万円程度赤字が発生する 自分の給料は当然未払い という体たらく。\nもう本当に死ぬかどうかみたいなラインを生きていて、なんなら来月の振り込みタイミングとかを勘案すると本当に一瞬残高が足りなくなる可能性がある。 何回か計算したところ一応生き残れそうではあるが、イレギュラーな出費が重なると本当に終わる。\nなんでこんなことになっているかというと、端的に言えばシステム発注から報酬振り込みまでが長いというのが全て。\nただ今の状況が最悪というわけではなくて、2023年からちゃんと会社の看板で仕事を受けられるようになっていて、去年までの自分一人で完結していた状況からチームでアウトプットを出すという形になってきているので、そこはある程度成長している。\nただこの変化のフェーズにおいて扱う金額というのが一気に変わってしまい、そこに対応しきれず死にかけている。\nソフトウェア開発プロジェクトのお金の動き 通常、システム開発というと数ヶ月単位のスパンでプロジェクトは進んでいく。 発注にかかる金額は開発するシステムやアプリケーションの規模次第ではあるが、多くの場合300万円〜1000万円といったところだろうか。\nこの規模感のプロジェクトをうちの場合は3, 4人程度のメンバーで回しているので、一見すると一人あたりすごく儲かってハッピーのような感じに思える。\nただここは罠があって、もらえる金額というのはシステムを無事に納品しきってもらえる金額なので、納品までのエンジニアの給料などは手持ちのキャッシュから捻出しないといけない。 プロジェクト期間中は給料などで赤字を掘りつつ、プロジェクト終了後に掘った赤字以上に回収して会社は儲かるという流れになっている。\nうちの会社はあまりに若くて借り入れ等も行なっていないので自己資金が非常に小さく、こういう感じの会社がこの手の開発プロジェクトを受けるとプロジェクト期間中にキャッシュが尽きかける。 一応対策として着手金としてプロジェクト開始時に100万円、プロジェクト終了後に残額を支払いという形式を取ることもできる。 しかし、自分が今回見通しが甘かったのもあり今回このような状況に陥ってしまい、非常に反省している。\n今の会社のチームは元々友人関係で手伝ってくれているというような状況で全員業務委託契約なので、先日報酬の支払いが遅れる可能性があると伝えたところまあ次からは頑張っていこうとポジティブな捉え方をしてくれているので本当に人に恵まれたと感じている。 しかし金の切れ目は縁の切れ目なので、メンバーにちゃんと報酬を払うのを最優先事項として、自分の給料は未払いにしてでもここは死守していこうという覚悟。\nプロジェクト完了に向けて こんな具合でプロジェクト期間中は資金ショートしかける。 自分の場合今までこれをどうやりくりしていたかというと、自分自身が業務委託で働いて報酬を会社に入れていた。 だいたい毎月100万円くらい。\nなのだが、先日その業務委託先から事情により契約更新できないと言われてしまい、コンスタントに会社に入ってくるお金がなくなってしまった。 すぐに別の仕事をいただけたのでなんとか食いつなげそうだが、諸々の関係で報酬が50万円程度に落ちる見込み。\n現在のプロジェクトが完了して支払いが走るのが4, 5月頃で、今年の夏あたりには会社の状況はかなり好転していると思われるが、本当にここ数ヶ月が正念場となる。\nこの地獄の谷を越えた先に安寧が待っている思うので、しばらく耐えていきたい。\n最悪の場合、役員借入をする。\n法人は死にそうだが個人は元気 役員借入は本当に最後の手段だが、実際のところここまでは法人の口座残高がやばいという話で個人資産というのは割とある。 大金持ちというわけではないけど、世間的な26歳平均に対して結構持っている方だと思う。\nなので生活が終わってしまうわけではなく、結構耐えている。\nただやはり法人も実質的に自分が管理しているので、こっちがカツカツだと本当に自分まで惨めな気持ちになる。 やはり改めてお金の余裕は心の余裕だと感じた。 早く4, 5月になってほしい。\n終わりに 会社の方は現在結構シビアな状況だが、きっと創業当初なんてそんなもんなんだろう。\n幸いなことに自分たちはソフトウェア開発というマーケット的にレアなスキルを持っているので受託という食い繋ぎ方ができるが、もしこういうわかりやすいハードスキルが無い起業家は資金調達するしか無いのだろう。 受託が今の自分たちができるビジネスでありミニマルエコノミーなので、ここは淡々と積み重ねていきたい。\nしかし本当に縁には恵まれたもので、今のところ様々な会社からお仕事や相談をいただけているので、これらが結実すれば2023年の終わりにはかなり会社の状況は安定していると思われる。\nきっとこういうハードな状況は今後何回かくるのかもしれない。 過去にソフトバンクを辞めるとき、このまま想像できる未来を歩んで「自分の人生の仕上がりはこんなもんか」と思えてしまうことが一番の恐怖 と考えていたが、この手のヒヤヒヤするような状況こそ自分が欲しかった予測できない将来というヤツなので、しっかり楽しんでいきたい。\n","categories":["career"],"date":1677456000,"description":"システム屋は発注から納品、報酬振込までが長いのでキャッシュフローの管理がかなりむずい","permalink":"http://komi.dev/post/2023-02-27-cash-flow/","publishdate":"2023-02-27T00:00:00Z","section":"post","tags":["ksquad","life"],"title":"システム屋の資金繰り","url":"/post/2023-02-27-cash-flow/"},{"body":"新年早々めっちゃ忙しかった もう2023年が始まってから1ヶ月経とうとしているが、今になってようやく今後どうするかみたいなのがフワッと見えてきたので今回文章に起こしておこうと思う。\nとにかく今年入ってからやばいくらいに忙しかった。\n背景として、去年の12月くらいにかなり悩んでいた(病んでいた)のもありながらK Squadを今後どう活動させていくかというのを考えており、その中でK Squadを育てていこうと思って去年のうちに結構種まきしていたのがかなり芽が出てきたのである。\nまた、病んでいた原因を断ったというのもあり今はめちゃくちゃ元気。\nひとまずそこらへんについてざっとまとめておこうと思う。\nStreetsの取締役CTOを退任 前回のエントリーでStreetsのモチベーションがなかなかにしんどいという話を書いたが、結果としてメンバーと話して取締役CTOを降りることにした。 2023年1月31日で退任となる。\n理由は前回のエントリーでだいぶ匂わせていたが、やはり自分として愛が持てるドメインでないと収益性の担保されない仕事はモチベーションが湧かなかった。\n自分が仕事に求めることは何かというと\nお金が稼げて自身の生活が満たされること 自分の周りの人間が満たされること の2点。\nスタートアップがうまくいくためには初期で (エクイティやデットで)資金調達がうまくいく か 売上が立つ(利益が出る) のどちらかが必須で、つまり金がないとスタートアップというのは生き永らえることができない。 そして同時にこの上でチームメンバーのモチベーションをどこまで高くキープできているかというのが重要だと個人的に考えている。\n自分は上記の自身の生活が満たされることが極めて重要な人間なので、Streetsにフルコミットする状況は金銭的、精神的な観点で正直とても厳しいものがあった。\nあまりここで詳細なことを書くと怒られそうなのでこれから言及することはそのうち消えるかもしれないが、Streetsメンバーは皆何かしら本業を持っていて副業っぽいノリでStreets事業を手伝うという形をとっている。 これはビジネスメンバーもエンジニアも等しくそういう形となっている。\nもちろんこの部分は非常に理解ができる部分で、スタートアップというのはとにかく金がないのでその事業だけで食っていくことはかなり無理がある。 さもなくば貧しい生活を覚悟しなければいけない。\n今になってようやく言語化できるが、自分が一番モヤモヤしていた(去年病んでいた)のがこの副業スタイルという点で、ビジネスメンバーとエンジニアの間に非対称性が存在していること。\nソフトウェアエンジニアという職務はどうしても人月商売であるという本質を持っていて、費やした時間の分だけ成果は出てくる。 一方でビジネスサイドにおいてはぶっちゃけ時間を費やさなくともステークホルダーの人物に狙いを定めて数時間ミーティングをしたりメール、会食するだけで成果というのは出てくる。\nつまり何が言いたいかというと、数人のメンバーの中で自分が一番割を食っていて、自分が最も自身の本業を犠牲にする必要があった。 自分が稼働しないとこの事業は進展がないというのは事実だが、これは自分にとっては極めて大きなプレッシャーで、結論としてとても大きな時間を割かなければいけなかった。\nピーク時は1週間で100時間くらい稼働していたが、これで役員報酬が月額40万というのはあまりにも安すぎた。 時給に直すと都内のコンビニバイトと同じくらいだろうか。\nただ金銭的なインセンティブが全てでもなくて、これで事業が進展するなら良かったのだが、ピボットほどではないもののコア機能がどんどん移り変わっていった。 PMFしてないので仕方ないが、ここまで時間を費やしてその上で度重なる方針転換はメンタル的に結構しんどかった。 生株をビジネスメンバーに比べて多少多めにもらってはいたが、スタートアップの株なんてのはただの紙切れ同然で、株式を多少多めに配分されてるとはいえかなりの忍耐が必要だった。\nまあ長々と書いたが、要するにシンプルに疲れた。 もうしばらくはガチのスタートアップで自社サービスやりたくない。やるとしてもシリーズA, B以降のPMFが見えて1→10フェーズのところでいい。\n別に事業が悪いというわけではないし、メンバーに誰か嫌な感情を持ったというわけではない。 構造としてただただNot For Meだった。\n数ヶ月前にエンジニア出身の経営者の友人と鳥貴族で飲んできたときもしCTOやるんだったら最初期から入らずにある程度事業に芽が出てるシリーズA, BあたりのところにCTOとして入るのがマジでコスパ良いという話になったのだが、改めて身をもってこれを痛感した。\n専業でプロダクトがPMFしてないスタートアップに入り、自分がオーナーじゃない場合は本当に疲弊する。 そしてその事業ドメインに自分が愛を持っていないと憂き目に遭う。\nただ、今回の1年ばかりで得られたこの経験はなかなか貴重なので、今後起業を志すエンジニアの友人にはしっかりフィードバックしていこうと思う。 また、ビジネスサイドにスペシャリティを持つ起業家へのメッセージとして最初期にエンジニアを抱えて安心したいのは理解できるが、同時にそのエンジニアをケアすることも大切だよというのは伝えておきたい。\nStreetsの取締役CTOは退任となるが、流石に自分がいきなり消えるとプロダクトとしてかなりマズいので今後は技術アドバイザーという形で保守メインでちょっとだけ開発するという方針。\nK Squadを育てることにした Streetsの進退を考えていながらK Squadを今後どうするかというのを考えていたが、色々な人と会っていく中で仕事をいくつかいただけることとなった。 そんなこんなで年初にして数千万円の売上が確約されたので、せっかくだしK Squadを育てていこうと思っている。\n先日某大企業の社長と食事に行ってきたのだが、現在K Squadはコンサルティングとか技術支援がメインだが何も自社プロダクトを持っておらず、それで良いのだろうかと相談してみたところ、コミちゃんの強みはコミュニケーション能力が高くて人に相談してもらえる空気感を持っているところだから変にビジョナリーになる必要はないとアドバイスしてもらった。\n自分自身のスペシャリティはソフトウェアエンジニアリングではなく技術に理解がありながら人とコミュニケーションが取れることだと最近は認識し始めていたので、これは結構目から鱗だった。 人が喜ぶ仕事ができればそのアプローチは何でも良いとも思っていたので、今後K Squadはコンサルティングをメイン軸としてやっていこうかなと考えている。 変に自社プロダクトを持つと地獄を見るのは薄々感じていたので、確かにこれで良い気がしている。\nそんなこんなで仕事をいただいたのだが、今回の仕事の発注は自分が昔から関わらせていただいているところだったので、やはり縁というのは大切にしなければいけないと思った。\n自分がK Squad作ったのはつい最近で、自分自身まだ26歳という若さでゴリゴリのZ世代なわけだが、縁を大切にしているのであえて昭和スタイルで営業しようと考えている。 IT系の人間なので効率化とかスマートにやるのはいくらでもできるが、やはり最後は営業力で、IT系の技術わかる人間がちゃんと営業すればしっかり仕事は取れる。\nただこのやり方をK Squadメンバー全員に強要する訳にはいかないので、一応職責としてパートナーとソフトウェアエンジニアで分けることにした。 ソフトウェアエンジニアはエンジニアリングに本職を持つ人で、パートナーは開発の知識を持ちながら積極的にお客さんとの折衝に出てもらう人という方針にしている。\n最近は後輩を積極的にお客さんとのミーティングの場に連れていっているが、良い感じに経験を積んでもらっているので徐々にメンバーに成長してもらいながらK Squadを大きくしていければ良いかなと考えている。 K Squadは無借金経営なので特に焦ることもないので、今は着実にやっていこうと思う。\n最近は京大にアルバイト募集の広告も出したので、今後の動きに乞うご期待といったところ。\n今後京都に定期的に通うことになった K Squadの仕事の都合だが、3月から週2,3日京都に滞在することになった。\n現在は東京に住んでいるので当然京都に毎週行くことになるのだが、結構滞在するのでビジネスホテルではなく京都で家を借りようと考えている。 ビジネスホテルより家を用意した方が荷物の管理も楽で、あと気が休まる。\n大学の頃は京都については なんて退屈な街なんだ\u0026hellip;早く東京行きたい\u0026hellip; なんて考えていたのだけれど、いざ東京に住み始めた現在は 街が騒がしすぎる\u0026hellip;京都っていい街だったな\u0026hellip; と思っている。\n多分一生隣の芝生は青いので今回デュアルライフを実現することになり結構ウキウキしている。 元々2拠点生活には憧れていて、かつ東京と京都は移動が極めて楽(新幹線で2時間くらい)なのでお金が許す限り本当に最高の組み合わせだと思っている。\n今回はちゃんと仕事が理由なのでしっかり経費で落とせるし、ワンルームではなく1LDKくらいの物件を取ろうと考えている。 ただ、早くしないと受験生のブームに巻き込まれて引っ越し周りが大変なことになってしまうので2月はバタバタする予感。\n奥さんに聞いてみたところ合法的に京都旅行行けるし関西エリアのラーメン食べに行こうと割とノリノリなので、毎回京都についてくるわけではなさそうだが奥さんのGoサインも出ていて安心。\n終わりに 2022年は会社を辞めるという大きなイベントがありそこから色々あったが、今年もすでに予定がたくさん詰まっているので引き続き頑張っていきたい。\nK Squadは今年の売上は5,000万円あたりだと読んでいる。 設立から2期目にしてこれはだいぶ頑張っている方だと思う。 ひょっとしたらどこかで確変が起きて1億を超えるかもしれないので、採用やマーケティングを頑張りつつ日々誠実にビジネスをやっていこうと思う。(絶対に情報商材には手を出さないよ)\nK Squadはめっちゃ人材募集しているので是非とも。\nそれでは。\n","categories":["career"],"date":1674691200,"description":"新年に入ってから色々イベントが起きているのでそのまとめと今後の抱負","permalink":"http://komi.dev/post/2023-01-26-start-new-year/","publishdate":"2023-01-26T00:00:00Z","section":"post","tags":["life","streets","ksquad"],"title":"2023年は何をしていくか","url":"/post/2023-01-26-start-new-year/"},{"body":"はじめに 今年は色々あったが、まず何よりも最初に浮かぶのは2022年は後半全くこのサイトを更新しなかったということ。 シンプルに仕事やプライベートが忙しかったというのはあるし、オープンにしていいネタがそこまで多くないなど色々要因はある。\nもう少し何か書けばいいかなとは思っていたが、まあそんな肩肘張らずのんびり更新する感じでもいいのかなって気もしている。 こんなペースだと来年とかは更新するのが3, 4回になりそうだが。\nさて、今年は本当に人生的に大きな動きがたくさんあったと思う。 主にやったこととしては\n(2月) 正社員を辞めてフリーランスになった (3月) 結婚 (4月) Streetsを創業 (8月) K Squadを創業 といったところ。\nやはり結婚したというのは大きいし、あと会社を2つ作ったというのも非常に人生的に大きな出来事だと思う。\nここらへんについてのんびり振り返っていきながら今年の結びにいい感じに持っていきたい。\n結婚 去年(2021年)の6月頃から今の奥さんとは同棲をしていたのだが、今年の3月に正式にプロポーズして3月22日に籍を入れた。\n元々同棲していたというのもあってそこまで大きな生活の変化は無いが、前に比べて奥さんの実家に行く(ご飯を振舞ってもらう)頻度が結構多くなった気がする。 多分一ヶ月に一回くらい。\n周りから「夫婦円満か」とか「順調なのか」などと色々茶化されることはあるけど、今のところ不満は無いという表現が妥当だと思う。\n家事の負担は基本的に自分がほとんどやっていて、自分がまだやっていない作業を奥さんが補完的にやるという方針。 自分としては家事をすることにそこまで抵抗感は無く(むしろ好きでやってる部分もある)、ここらへんについては特に問題ないと思っている。\n2023年2月に結婚式を挙げる予定ではあるが、ここについては未だにモヤモヤしてるところはある。 個人的に結婚式を挙げる意味がわからないし、あまり人前に出て自分が注目される状況というのは好きではなく(フォロワー1万人超えてるやつが何言ってんだという感じだが)、一方で奥さんは結婚式をどうしてもやりたいと言っていたのでここは本当に揉めた。 結果的にこっちが根負けして結婚式を挙げることになったが、未だに納得してないしこれに数百万も飛ばすなんて今でも考えたくない。 しんどい。\nStreets創業 4月には地域情報流通活性化事業としてStreetsという会社を立ち上げた。 ここは前のエントリーでも言及した気がするが、主にインスタみたいなアプリを作って中小の店舗が簡単に地元のユーザーにリーチできるようなインターフェースを用意しようというのが今回の試み。\n今年の4月あたりから開発に着手して7月だか8月くらいにリリースし、色々機能開発とかもやっていって、創業から半年ちょっとだがかなりのスピード感で走ってきた感はある。\n採用してる技術として、今回はWebアプリではなくモバイルアプリとして開発するということで自分が全く触ったことのなかったFlutterを使い始め、サーバーサイドは自分のわがままでRustを採用し、色々好きにやってる感じはある。 サーバーサイドとインフラ、DB設計等については元々自分の主戦場だったというのもあり、今のところ安定的に稼働している感触はある。 実際に(まだユーザー数がそこまで多くはないが)今までヤバい障害みたいなのは起きていない。\n一方でフロントエンド(Flutter)についてはやはりベストプラクティスを知らない\u0026amp;\u0026amp;そこまで経験値が溜まっていなかったなどの理由で結構苦戦してるところ。 特に状態管理のアプローチについては迷走していて、今まではFlutterエンジンが提供してるStatefulWidgetをメインに使っていたが、直近は可能な限りRiverpod側に寄せる方針に切り替えていて、コードの中身が結構ゴチャゴチャしている。 プロダクトの性質としてサーバーサイドは透過的なDBのインターフェースでしかなく、フロントエンドが諸々ボトルネックになってくるのでここを上手にやれてないのは後悔というか反省している部分ではある。 ただReactを元々触っていたというのもあり、そこまで違和感なく開発に入れて、今年は爆速でリリースまで持っていけたというのは収穫ではあると思う。\n技術的なこと以外として、Streetsのおかげで今までの自分じゃ絶対に関わることは無さそうな人々と付き合いを持てたというのは本当に良かったと思う。 自分はやはりITベンチャー業界に生きる普通のソフトウェアエンジニアだったので、もし今回起業していなかったらずっと渋谷ベンチャー界隈の反復横跳びして過ごしていったのかもしれない。 それが地方の商店街だったりテレビ局、役所など色々関わることができているので非常にエキゾチックな感覚ではある。\nそんなこんなだが、Streetsについてどんな感情を持っているかというと、最初の方はすごく楽しかったけど今は正直なところツラい感情の方が大きくなってきている。 プロダクトは伸びているのかというと正直まだ全然だし、もちろん全く黒字化しておらず、今のところこのプロダクトが世間に広がる未来が全く見えない。 コンセプト自体は非常に良いのだけど、結局のところ現状インスタやGoogleマップの下位互換でしかない。 先日CEOと話してこの事業はプロダクトではなく課題解決で勝負する的なことを言われたが、一方でプロダクトありきの事業なので結構難しい状況だと思っている。\nプロダクトの質としてはどうかというと、結局フルタイムで責任持って管理しているのが自分しかいないというのはかなり厳しい。 一応業務委託等で手伝ってくれてる人はいるけど、お手伝いと管理者では障害等のインシデントに対して主体的に向き合えるかどうかに圧倒的な違いがあると思っていて、要するにプロダクトに関しては全責任が自分に降りかかっていることがかなりストレスになっている。 同時にこの状況下に置かれながら頑張るインセンティブがそこまで大きくないので本当にしんどい。\nそんなこんなで今年の夏過ぎくらいまでは楽しく仕事ができていて土日も深夜も適宜作業に時間を充てていたのだけど、今はただただストレスでここ1, 2ヶ月はもう平日の日中以外の時間にSlackを開かなくなった。 モチベーションとしてもかなりしんどくなってきて、CEOに相談して今年は残り2週間半ほどだが休みをもらうことにした。\n来年以降もうどこまで頑張れるかわからないが、少しペースを落としてのんびりやっていこうと思う。 ひょっとしたら来年は手のひら返して事業楽しいなんてやってる未来もありえるかもしれないが、そこはご愛嬌。 ひとまず今めっちゃツラい。 誰か助けて。\nK Squad創業 今年の8月にStreetsとは別で個人用の会社を作った。 設立の経緯として、今までも紹介で色んな人とお話をすることがあったが個人事業主より法人格の方が仕事を頼みやすいと言われることが多々あったことから設立するに至った。\n名前の由来として、kはkomiのkから取り、squadというのは英単語でマイメンというか仲良いダチって感覚のスラングで、今まで色々仕事してきてこれからは自分の好きな人とだけ仕事していきたいなと思いを込めてK Squadとした。 あと自分がジャズとかインスト系の音楽をよく聴くのだけど、ジャズバンドのJ-Squadから転じてというのもある。\nこっちの方はとにかく仕事が楽しくて仕方ない。 自分が主体となってお客さんにコンサルティングして、困っていることがあったら適宜コード書いてあげたりと顔の見えるお客さんのために仕事をしているという感覚が強くあって本当に良い。 あとお金という観点でも、Streetsはコードをいくら書けど一銭にもならないけど、K Squadで受けている仕事は本当にコードが如実に価値を生んでいるのがわかる。\nK Squadでは変にtoBマーケティングみたいなのはやらず完全紹介性で仕事をしているのだが、当初の好きな人とだけ仕事したいという思いから基本的にぼったくりのような仕事をしないという方針にしており、自分達がめちゃくちゃ儲かっているわけではないが本当にやりがいのある仕事をしているという感覚がある。 自分がやりたい仕事はこういうことだったんだなと最近強く思う。\nメンバーは今のところ4人で、全員コードが書けるし、コミュニケーション能力も高いので適宜営業サイドにも回れるというのはかなり強い。 なのでお客さん側からすると営業で見かけたやつが直接コードを書くということになるのでプロダクト設計について意思疎通がとりやすいし、何より稼働する人間が最低限になるのでとにかく人件費が安くなる。 ここはそこらへんの受託開発企業とは大きく異なるところだと思う。\n将来的にはK Squadのチームも大きくしてより大きな仕事に取りかかれれば良いかなと夢想している。 今のところ自分の大学時代の友人を引き込んで彼らには業務委託として仕事を手伝ってもらう形式にしているが、こういったメンバーをどんどん増やしていきたい。\nその他 仕事とかの話は本当に悩みがつきものだが、趣味などについては今年は色々充実したのでそれも色々。\n筋トレ 去年の夏あたりからジム通いを始めて、今年はベンチプレスが大台の100kgを超えた。 現在のMAXは110kg。\n流石にこのくらいちゃんと筋トレやってればジム通いも趣味として言えるだろうと思い、もう少し課金してクオリティを上げることにしてジムも新しいところに行き始めた。 今まで行ってたジムは区営の1回2時間550円のところを使っていたが、近さやスケジュール等を考えて近場の月6000円くらいの行き放題のところに変えた。 おかげさまで非常に近くで気軽に行きやすくなり、かつトレーニングルームも広くなって混雑に悩まされることは無くなったので非常に満足している。\n来年はもうあまり重量を上げることは考えず、少し体を絞って良い体を作っていく予定。 実際に現在すでにバーベル系のメニューはダンベルでフォームを気にするようにし始めた。\n特にボディービルディングのコンテストに出ることは考えていないが、せっかく筋トレを頑張っているので何かしら挑戦でもしてみようか悩み中。\nランニング ランニングもちょこちょこやっていて、去年Apple Watchを買ったタイミングでタイムを測るようになった。 家の周辺を走っているのだが、ちょうどよく5kmジャストのコースを見つけたのでここをタイム測る基準として使っている。\n去年までは1km5分切るかどうかみたいなラインだったのだけど今は1km4分40秒くらいで気軽に走れるようになっていて成長を感じる。 そのうちマラソン大会にも出てみようか考え中。\nただ今のところ10kmくらいしか最大で走らないので42.195kmを走って耐えられるのかはわからないから練習する必要があると感じる。\nそれはそうと皇居とかみなとみらいとかランニングの聖地と言われいるところも2023年にはチャレンジしてみたい。\nPS5 今年の夏あたりにヨドバシを歩いていたらPS5が売られているのを発見し、とうとう我が家にPS5が生えた。\nもともとゲームはすごい好きだったのだけど非常に時間を食うため意図的にゲームは買わないようにしていたのだけど、今回いざ買ってみたらやはり楽しい。 買った直後とかは6時間くらい平気でぶっ通しでやってしまい、ワクワクしながら買ったラチェット\u0026amp;クランクを3日でクリアしてしまった(レベル上げ、トロフィー集めなど全て完了)。\n今は別のゲームをやっているが、やはりゲームは楽しい。 仕事柄かなり稼働時間に融通が効くので奥さんの仕事の邪魔にならない範囲で平日の昼間にもやっていることもあるが、ちゃんと仕事と両立できているのでこれも良い趣味かなと今はプラスに捉えている。\nお金 2022年は特にお金が貯まった1年だったと思う。 2021年の時点で引っ越しは終えて家具や家電等は揃い、今年は結婚指輪等を買った以外は特に大きな出費はなかったので平均すると毎月60万くらい貯金できてたんじゃないかと思う。\nいわゆる30歳までに貯金1000万を貯めよう的な言説があるけど、今25歳(今月末で26歳)だが恐らく来年の春くらいには貯まってると思われる。 その前に確定申告を乗り切らないといけないが。 今年は正社員辞めてフリーランスになり会社役員になったので収入源が本当にめちゃくちゃ。\nそんなお金貯めてどうするのかと聞かれたことがあるが、ぶっちゃけ特に目的は無くて口座にお金が貯まっていく様子を見るのが好きなだけなのでこれといった目的意識はない。 趣味についてはも上述の通りめっちゃお金がかかる趣味を持っていないので、本当になんでこんな金を欲しがってるんだという感じではある。\nところで今欲しいものは車とデカい一軒家くらいで、車は置いておいて注文住宅となると軽く億が必要になり、本当に気が遠くなるのでここはFPとかに相談しようと思ってる。 宝くじ当たって欲しい。非課税で10億欲しい。やっぱり会社売却しか有効手段はない気がする。\nK Squadの方は今年8月に創業して役員報酬は0円に設定しているが、来年は色々計算しながら役員報酬は決めていく予定。 税金対策ということで住んでる家を社宅化したりと経費にできそうな部分は色々工夫してるので今後役員報酬で入れる分は丸ごと貯金になるイメージ。 多分役員報酬は月30万円くらいにするつもり。あとで電卓叩いてみる。\nまあ基本的には会社にある程度お金を残してチームメンバーに分配していくつもりで、そっちの方が今後より大きなお金を作れると思うのでここは今後要検討。\n終わりに 2022年は色々あった。\nそういえば自分のコアバリューというか何に価値を感じるかについて、今までは余裕を持つの一点張りだったけど、今は余裕を持ちながら自分の身の回りの人を幸せにしたいに価値観が変遷してきた。 まだまだ全然自分も余裕じゃないけど、そういう風にありたいって思えるようになってきたのはある種で成長なのかもしれない。\n充実はしてるが悩みはつきものだし、全然順風満帆じゃない。 ただ徐々に自分がやりたかったことが明確になりその道のりが見えてきて景色も良くなってきたので、2023年も足掻いていこうと思う。\n","categories":["career"],"date":1670976000,"description":"2022年は結婚して起業して個人の会社も作って色々やった","permalink":"http://komi.dev/post/2022-12-14-summary/","publishdate":"2022-12-14T00:00:00Z","section":"post","tags":["life","streets","ksquad"],"title":"2022年のまとめ","url":"/post/2022-12-14-summary/"},{"body":"プロダクトをリリースした 2022年になったとき「これからは毎月1本はブログを更新しよう！」と決めていたのだが、あまりにも忙しすぎて前回更新から2ヶ月も経ってしまった。 スタートアップというのは状況が目まぐるしく変わるもので、基本的に忙しいものなのでしょうがない気もする。\nさて、前回までの更新で「色々落ち着いたらちゃんとリリースを打ちたいと思う」なんてことを書いた記憶があるのだけれど、無事にリリースが打てた。\n現在すでにApp StoreやGoogle Play Storeにアプリが並んでおり、誰でもアプリがインストールできる。\nプロダクトのコンセプトとしては「デジタル商店街」をテーマにしており、インターネットを通して地域の商店街の盛り上がりや購買意欲の向上を体験できるアプリとなっている。 まあ本質的にはお店だけが投稿するインスタみたいな感じなのだけど、他のプロダクトだと営業時間の変更やタイムセールの通知などが簡単に行えず、かつ一般ユーザーは事前に店舗アカウントをフォローしておく必要などがあり、これらの課題を一気に解決するプロダクトとなっている。\n一般ユーザーとしてはアプリを入れておくだけでセール通知などが来て、アプリを通して知らない地元のお店について知ることができる。 同時にお店としてはフォロワー稼ぎを頑張ることなく自動的に地元のユーザーにリーチできるようになっている。\n一般ユーザーにとってお店を認知すること、お店にとっての集客はそれぞれリアルな商店街ならものすごく簡単なものであるはずなのに、これがデジタルとなると途端に難しくなる。 事実としてインスタのアカウントを運用している店舗のほとんどがフォロワー数が伸び悩んでおり、同時にプラットフォームの分断の問題もあるのでFacebookユーザーやTwitterユーザーに届くようそれぞれのSNSでも投稿を頑張らなければいけない。\n今回のプロダクトはデジタルでの活動をなるべく簡単にできるように考えており、将来的にはクロス投稿でStreetsに投稿するだけでFacebookやインスタ、Twitterにも投稿できるような機能を足そうと考えている。\nそんなこんなで今後も開発は続けていこうと思う。\n実はある程度動くものが5月の時点にはあった ここまでの書き方だとようやく最近開発が落ち着いたような感じが出ているが、実は最低限の機能を持ったものについては5月の頭にはあったのである。 なんならその時点で業務提携先にデモを見せたりしていた。\nではなぜそのタイミングからここまで時間差があるかというと、お察しの通りものすごい量の改修作業と安定化が図られたからである。 git rev-list development --since=\u0026quot;20220-05-01\u0026quot; --countで数えてみたら1018コミットされていた。 ちなみに開発メンバーは基本的に自分で、CEOがデザイン系の改修、あと業務委託でちょっと作業してもらってるのが1人いるので、かなりのスピード感で作業をしていたのがわかる。\nAPIを安定化させたりID認証の部分のセキュリティを改善したりデザインを直したり、とにかく色々変更した。 またリリース直前になってApp Storeに並べるためにはAppleでサインインの機能をつけなければいけないことが発覚したり、リリースの2週間前にアプリ内でアカウント削除機能をつけることが義務化されていたことが発覚したり、とにかくバタバタしていた。\nエンジニアを採用したい そんなこんなでリリースまで漕ぎ着けて忙しさのピークは一旦落ち着いたのだけど、とにかくここまで大変だった。 朝から夜中まで開発してたし休日も結構な時間開発に割いてて、直し方の見当がつかないバグにぶつかるたびに「マジでもう2度と起業しねえ」なんて奥さんに愚痴ってたりしていた。\n自分はもともとサーバーサイドからインフラ周りをメインにやるエンジニアだったので(たまにReact書いてたけど)、今回モバイルアプリを初めて担当して全く知らないドメインと格闘したのもなかなかにしんどかった。 今は色々格闘してググりまくった結果いろんな知識がついたけど、もう2度としんどい思いはしたくないなーと今は思っている。\nそんなわけで自分はモバイルアプリについてはプロフェッショナルではないので今後本格的にFlutterエンジニアを採用したいと考えている。 自分がいればかなりの速度感で開発できるけど、これが持続的な体制かと言われると微妙だし本来考えるべきことややるべきことはたくさんあるので(各種設計とか)、そろそろ他のエンジニアへ知識伝播させていくタイミングだと思う。 あと実は知らないうちにFlutter開発におけるアンチパターンを踏み抜いてるかもしれない。\nエンジニア採用について、現在周りの友人を誘って副業という形で入ってもらおうと思いつつ、正社員としての採用は来年以降で資金調達をしたタイミングでやろうと思っている。 資金調達とか経営的な話についてはまたそのうち。\nまとめ そんなこんなで今回プロダクト開発まで持っていけたので、今後とも新規機能開発を続けていこうと思う。\n","categories":["career"],"date":1659571200,"description":"半年ほど前から開発にあたっていたプロダクトがリリースされ、一旦これまでの振り返りと今後の展望についてまとめる","permalink":"http://komi.dev/post/2022-08-04-launch-product/","publishdate":"2022-08-04T00:00:00Z","section":"post","tags":["streets"],"title":"起業して開発していたプロダクトをリリースした","url":"/post/2022-08-04-launch-product/"},{"body":"sqlx::types::Uuid vs uuid::Uuid RustでDBに接続するための有用なクレートとしてSQLxがある。 かつてはDieselが有名だったが、async対応ができてないなどの理由から新興のSQLxの方が今は人気がある。\nそんなSQLxだが、SQLxクレートがDBに対応した型を一部提供してくれている。その中にUuid型があるのだが、これが結構クセモノだったりする。\nというのも、Webアプリケーションを作成するときはDBから得られたUuid型のデータをJSONとして変換してクライアント側に返却するというのはよくあることだが、SQLxが提供するUuid型はSerializeが実装されていないので構造体をそのままJSONに変換することができない。\n以下のコードを考えてみる。\nuse anyhow::{Context, Result}; use serde::{Deserialize, Serialize}; use sqlx::{postgres::PgRow, Pool, Postgres, Row}; //use uuid::Uuid; #[derive(Debug, Deserialize, Serialize, sqlx::FromRow)] pub struct UserAccessToken { pub user_id: i64, pub access_token: sqlx::types::Uuid, } pub fn register_user(id: i64) -\u0026gt; Result\u0026lt;UserAccessToken\u0026gt; { sqlx::query( r#\u0026#34; INSERT INTO users (id) VALUES ($1) RETURNING id, access_token \u0026#34;#, ) .bind(some_id) .map(|row: PgRow| UserAccessToken { user_id: row.get(0), //access_token: Uuid::from_u128(row.get::\u0026lt;sqlx::types::Uuid, _\u0026gt;(1).as_u128()), access_token: row.get(1), }) .fetch_one(pool) .await .context(\u0026#34;Creating user\u0026#34;) } SQLxでクエリを発行する際はquery_asが有用だが、今回は明示的に型変換を行うためqueryを使っている。\nこのコードで肝となるのは.map(|row| UserAccessToken { ... })の部分で、構造体としてaccess_tokenフィールドはsqlx::types::Uuid型を指定している。\nこのコードはコンパイルは通らず、エラーメッセージは\nthe trait bound `sqlx::types::Uuid: Deserialize\u0026lt;\u0026#39;_\u0026gt;` is not satisfied the trait `Deserialize\u0026lt;\u0026#39;_\u0026gt;` is not implemented for `sqlx::types::Uuid` を吐く。 これはsqlx::types::UuidはSerialize/Deserializeを実装していないからである。\nではaccess_tokenフィールドの型をuuid::Uuidとし、.map(...)の中はそのままにしてみる。 このときuuidクレートのfeaturesにserdeを入れるのを忘れずに。\n#[derive(Debug, Deserialize, Serialize, sqlx::FromRow)] pub struct UserAccessToken { pub user_id: i64, pub access_token: uuid::Uuid, } pub fn register_user(id: i64) -\u0026gt; Result\u0026lt;UserAccessToken\u0026gt; { sqlx::query( r#\u0026#34; INSERT INTO users (id) VALUES ($1) RETURNING id, access_token \u0026#34;#, ) .bind(some_id) .map(|row: PgRow| UserAccessToken { user_id: row.get(0), //access_token: Uuid::from_u128(row.get::\u0026lt;sqlx::types::Uuid, _\u0026gt;(1).as_u128()), access_token: row.get(1), }) .fetch_one(pool) .await .context(\u0026#34;Creating user\u0026#34;) } これはどうなるかというと、これもコンパイルが通らない。 エラーメッセージは以下の通り。\nthe trait bound `uuid::Uuid: sqlx::Decode\u0026lt;\u0026#39;_, Postgres\u0026gt;` is not satisfied the trait `sqlx::Decode\u0026lt;\u0026#39;_, Postgres\u0026gt;` is not implemented for `uuid::Uuid` uuidクレートのUuid型はSQLxが提供するDecodeを実装してないためである。\nJSONにデシリアライズすることはできてもDBからデータを構造体にシリアライズできない。\nということで折衷案として以下のように、DBからデータの受け渡しはsqlx::types::Uuidで受け、それを一度u128に変換し、これをuuid::Uuidに持っていく必要がある。\n#[derive(Debug, Deserialize, Serialize, sqlx::FromRow)] pub struct UserAccessToken { pub user_id: i64, pub access_token: uuid::Uuid, } pub fn register_user(id: i64) -\u0026gt; Result\u0026lt;UserAccessToken\u0026gt; { sqlx::query( r#\u0026#34; INSERT INTO users (id) VALUES ($1) RETURNING id, access_token \u0026#34;#, ) .bind(some_id) .map(|row: PgRow| UserAccessToken { user_id: row.get(0), access_token: uuid::Uuid::from_u128(row.get::\u0026lt;sqlx::types::Uuid, _\u0026gt;(1).as_u128()), }) .fetch_one(pool) .await .context(\u0026#34;Creating user\u0026#34;) } 本来ならもっと上手いやり方がありそうな気もするのだが、今のところはこのような方法で乗り切っている。\n","categories":["tech"],"date":1652745600,"description":"SQLxにてUuid型を使いたい場合はuuid型を使ってうまいことハンドリングしてあげる必要がある","permalink":"http://komi.dev/post/2022-05-17-uuid-in-sqlx/","publishdate":"2022-05-17T00:00:00Z","section":"post","tags":["rust"],"title":"SQLxのUuid型はSerializeできない","url":"/post/2022-05-17-uuid-in-sqlx/"},{"body":"Cloud Runからプライベート環境のCloud SQLに繋ぐ Cloud SQLインスタンスを立てる際、パブリックIPを付与するかVPC内に立ててプライベートIPを付与するか、またはその両方を設定することができる。\nパブリックIPの場合は簡単にホスト名にIPを当てればいいのだが、プライベートIPの場合はVPC内に通信できるようVPCコネクタを用意する必要がある。\nCloud RunはVPC内に立てるということができないので、このVPCコネクタを使うのが有効となる。\nresource \u0026#34;google_compute_network\u0026#34; \u0026#34;vpc\u0026#34; { name = \u0026#34;vpc\u0026#34; auto_create_subnetworks = false } resource \u0026#34;google_compute_subnetwork\u0026#34; \u0026#34;vpc\u0026#34; { name = \u0026#34;vpc\u0026#34; ip_cidr_range = \u0026#34;10.0.0.0/16\u0026#34; network = google_compute_network.vpc.self_link region = var.region private_ip_google_access = true } resource \u0026#34;google_vpc_access_connector\u0026#34; \u0026#34;connector\u0026#34; { provider = google-beta name = \u0026#34;vpc-connector\u0026#34; region = var.region ip_cidr_range = \u0026#34;10.8.0.0/28\u0026#34; network = google_compute_network.vpc.name } resource \u0026#34;google_compute_router\u0026#34; \u0026#34;router\u0026#34; { provider = google-beta name = \u0026#34;vpc-router\u0026#34; region = var.region network = google_compute_network.vpc.id } resource \u0026#34;google_compute_router_nat\u0026#34; \u0026#34;router_nat\u0026#34; { provider = google-beta name = \u0026#34;vpc-nat\u0026#34; region = var.region router = google_compute_router.router.name source_subnetwork_ip_ranges_to_nat = \u0026#34;ALL_SUBNETWORKS_ALL_IP_RANGES\u0026#34; nat_ip_allocate_option = \u0026#34;AUTO_ONLY\u0026#34; } VPCコネクタは上記のような具合で作れる。\nCIDRの指定について、VPCコネクタが使用する内部IPは他のVPC内のリソースと被ってはいけないため、例えばCloud SQLの内部IPが10.60.0.0のときにVPCコネクタのCIDRに10.60.0.0/28などとするのは無理となる。\nVPCコネクションにあたって該当IPをサービスと連携させておく必要があるため、以下のようにIPを固定した上でそれをservicenetworking.googleapis.comと紐付ける。\nresource \u0026#34;google_compute_global_address\u0026#34; \u0026#34;private_ip_address\u0026#34; { provider = google-beta name = \u0026#34;vpc-private-ip-address\u0026#34; purpose = \u0026#34;VPC_PEERING\u0026#34; address_type = \u0026#34;INTERNAL\u0026#34; prefix_length = 16 network = google_compute_network.vpc.id } resource \u0026#34;google_service_networking_connection\u0026#34; \u0026#34;private_vpc_connection\u0026#34; { provider = google-beta network = google_compute_network.vpc.id service = \u0026#34;servicenetworking.googleapis.com\u0026#34; reserved_peering_ranges = [google_compute_global_address.private_ip_address.name] } あとはCloud SQLを立てる際にこのVPCを指定する。\nresource \u0026#34;google_sql_database_instance\u0026#34; \u0026#34;app\u0026#34; { name = \u0026#34;app-db\u0026#34; database_version = \u0026#34;POSTGRES_14\u0026#34; region = var.region settings { tier = \u0026#34;db-f1-micro\u0026#34; disk_autoresize = true availability_type = \u0026#34;REGIONAL\u0026#34; backup_configuration { enabled = true point_in_time_recovery_enabled = true } ip_configuration { ipv4_enabled = false private_network = var.vpc_id // Specify VPC name } } deletion_protection = false } そして同様にCloud Runでマニフェスト内の.metadata.annotations内に\u0026quot;run.googleapis.com/vpc-access-connectorに値をセットしてVPCコネクタを使用するよう設定する。\nresource \u0026#34;google_cloud_run_service\u0026#34; \u0026#34;api\u0026#34; { name = \u0026#34;my-service\u0026#34; location = var.location template { spec { service_account_name = var.service_account_name containers { image = var.image ports { container_port = 3000 } env { name = \u0026#34;DATABASE_USER\u0026#34; value = var.database_user } env { name = \u0026#34;DATABASE_PASS\u0026#34; value_from { secret_key_ref { key = \u0026#34;latest\u0026#34; name = google_secret_manager_secret.db_password.secret_id } } } env { name = \u0026#34;DATABASE_NAME\u0026#34; value = var.database_name } env { name = \u0026#34;DATABASE_HOSTS\u0026#34; value = \u0026#34;${var.db_ip_primary},${var.db_ip_read}\u0026#34; } env { name = \u0026#34;DATABASE_PORT\u0026#34; value = var.database_port } } } metadata { annotations = { # Use the VPC Connector \u0026#34;run.googleapis.com/vpc-access-connector\u0026#34; = var.vpc_connector_name // Specify VPC connector # all egress from the service should go through the VPC Connector \u0026#34;run.googleapis.com/vpc-access-egress\u0026#34; = \u0026#34;all\u0026#34; # If this resource is created by gcloud, this client-name will be gcloud \u0026#34;run.googleapis.com/client-name\u0026#34; = \u0026#34;terraform\u0026#34; # Disallow direct access from IP \u0026#34;run.googleapis.com/ingress\u0026#34; = \u0026#34;internal-and-cloud-load-balancing\u0026#34; } } } traffic { percent = 100 latest_revision = true } lifecycle { ignore_changes = [ # For update of gcloud cli version template[0].metadata[0].annotations[\u0026#34;run.googleapis.com/client-version\u0026#34;] ] } autogenerate_revision_name = true } これでCloud SQLに繋ぐ際はホスト名に内部IPを指定してあげれば通信が成立する。\nこのホスト名の指定でGCPの公式ドキュメントが本当に分かりにくくて苦労した。\nというのもサンプルコードにてホスト名の例が127.0.0.1としてあり、本来127.0.0.1はループバックアドレスで内部IPの定義外なのだが、本来10.60.0.0のような内部IPを指定すれば良いのにも関わらずここで例として内部IP以外の値が出てきているせいで結局ホスト名に何を指定すれば良いのか全くわからなかったのである。\n実際、現在組んでいるアプリケーションではAPIによってプライマリDBかリードレプリカかを使い分けており、127.0.0.1宛ての通信だとポート番号で通信先を変える必要があるのだが、Cloud Runではサイドカーパターンはサポートしていない(コンテナは1つしか指定できない)ためCloud SQL Auth Proxyが使えない。\n結局Cloud SQLに繋ぎこむだけの作業で3日ほど潰したのは結構痛かった。\nホスト名が内部IPとなる際はrustlsではなくnative-tlsを使う必要がある 上記の通り適切にホスト名を指定すれば通信はできるのだが、今回の落とし穴としてTLSクレートとしてrustlsを使っていたというのもあった。\nこちらのブログに助けてもらい、native-tlsに差し替えることでサクッと疎通が確認できた。\n","categories":["tech"],"date":1651622400,"description":"Cloud SQLをVPC内でホスティングしてCloud Runから接続する際、rustlsではなくnative-tlsを使う必要がある","permalink":"http://komi.dev/post/2022-05-04-rust-from-cloud-run/","publishdate":"2022-05-04T00:00:00Z","section":"post","tags":["rust","gcp"],"title":"RustアプリをCloud RunとCloud SQLで動かす","url":"/post/2022-05-04-rust-from-cloud-run/"},{"body":"CDNの構築は意外とめんどい CDNは画像等の静的ファイルを流すためのネットワークで、アーキテクチャとしては単純なのだが準備することが地味に多く結構めんどくさかったりする。 やるべきこととしては以下の通りなのだが、意外と大変。\nHTTPSのプロキシを作成する フォワーディングルールを用意してプロキシと紐付ける URLマッパーを実装する バックエンドバケットを用意する(キャッシュ用) (任意) CDN用のサブドメインを用意する これらをコンソール画面でぽちぽち手でやってると確実にミスが発生するし、本番環境とは別でステージング、開発環境も同様にすると尚更厄介で、なので今回はTerraformで用意する。\nコードと説明 まずCDN用のサブドメインを用意する。\nresource \u0026#34;google_dns_managed_zone\u0026#34; \u0026#34;cdn\u0026#34; { name = \u0026#34;cdn-managed-zone\u0026#34; dns_name = \u0026#34;cdn.${var.domain}\u0026#34; description = \u0026#34;Managed Zone for cdn.${var.domain}\u0026#34; dnssec_config { state = \u0026#34;on\u0026#34; non_existence = \u0026#34;nsec3\u0026#34; } } resource \u0026#34;google_compute_global_address\u0026#34; \u0026#34;cdn\u0026#34; { name = \u0026#34;cdn-ip\u0026#34; } resource \u0026#34;google_dns_record_set\u0026#34; \u0026#34;cdn_a\u0026#34; { name = google_dns_managed_zone.cdn.dns_name type = \u0026#34;A\u0026#34; ttl = 300 managed_zone = google_dns_managed_zone.cdn.name rrdatas = [google_compute_global_address.cdn.address] } // 任意 resource \u0026#34;google_dns_record_set\u0026#34; \u0026#34;cdn_ns\u0026#34; { name = google_dns_managed_zone.cdn.dns_name type = \u0026#34;NS\u0026#34; ttl = 300 managed_zone = google_dns_managed_zone.origin.name // FIX ME rrdatas = google_dns_managed_zone.cdn.name_servers } これで cdn.example.com 的な感じのサブドメインが作れる。 最後の部分はexample.comを管理してるマネージドゾーンにcdn.example.comのサブドメインへNSレコードを貼る役割。\n次に、もちろんマネージド証明書もセットアップする。\nresource \u0026#34;google_compute_managed_ssl_certificate\u0026#34; \u0026#34;cdn\u0026#34; { name = \u0026#34;cdn-certificate\u0026#34; managed { domains = [google_dns_managed_zone.cdn.dns_name] } } これにてドメイン関連は終わり。\n次にフォワーディングルールとHTTPSプロキシ、URLマップを作る。\nresource \u0026#34;google_compute_target_https_proxy\u0026#34; \u0026#34;cdn\u0026#34; { name = \u0026#34;cdn-https-proxy\u0026#34; url_map = google_compute_url_map.cdn.self_link ssl_certificates = [google_compute_managed_ssl_certificate.cdn.self_link] ssl_policy = google_compute_ssl_policy.ssl_policy.name } resource \u0026#34;google_compute_global_forwarding_rule\u0026#34; \u0026#34;cdn\u0026#34; { name = \u0026#34;cdn-forwarding-rule\u0026#34; target = google_compute_target_https_proxy.cdn.self_link port_range = \u0026#34;443\u0026#34; ip_address = google_compute_global_address.cdn.address } resource \u0026#34;google_compute_url_map\u0026#34; \u0026#34;cdn\u0026#34; { name = \u0026#34;cdn-url-map\u0026#34; default_service = google_compute_backend_bucket.cdn.id project = var.project } resource \u0026#34;google_compute_ssl_policy\u0026#34; \u0026#34;ssl_policy\u0026#34; { name = \u0026#34;streets-ssl-policy\u0026#34; profile = \u0026#34;MODERN\u0026#34; min_tls_version = \u0026#34;TLS_1_2\u0026#34; } セキュリティのためにSSLポリシーを作っておいた。 これでTLSのバージョンが1.1以下の通信はお断りできる。\n最後にバックエンドバケットを設定する。 これは静的ファイルのキャッシュ等に使える。\nresource \u0026#34;google_compute_backend_bucket\u0026#34; \u0026#34;cdn\u0026#34; { name = \u0026#34;cdn-backend-bucket\u0026#34; description = \u0026#34;Backend bucket for serving static content through CDN\u0026#34; bucket_name = google_storage_bucket.cdn.name enable_cdn = true } bucket_nameにはCDN用のCloud Storageのバケットの名前を当てる。\nresource \u0026#34;google_storage_bucket\u0026#34; \u0026#34;cdn\u0026#34; { name = \u0026#34;foo-bar-piyo-cdn-${terraform.workspace}\u0026#34; location = var.location } resource \u0026#34;google_storage_bucket_iam_member\u0026#34; \u0026#34;cdn\u0026#34; { bucket = google_storage_bucket.cdn.name role = \u0026#34;roles/storage.legacyObjectReader\u0026#34; member = \u0026#34;allUsers\u0026#34; } 全員がバケットの中身が見れるよう権限をallUsersに与えたおいた。\nここで注意なのが、Cloud Storageのバケット名は全世界のGCPプロジェクトでユニークである必要があるのでcdn-bucketみたいなありきたりな名前はエラーになる。\nドメインを新しく作らないパターン 上記の例ではcdn.example.comというサブドメインでCDN用のトラフィックが流れるようにしたが、別のパターンとしてapi.example.comにアクセスポイントは集中させて/static/というパスの場合は静的ファイルが流れるようにしたいというケースもあるだろう。\nその場合はURLマップを少しいじって以下の通りにすれば良い。\nresource \u0026#34;google_compute_url_map\u0026#34; \u0026#34;api\u0026#34; { name = \u0026#34;my-url-map\u0026#34; default_service = google_compute_backend_service.api.id project = var.project host_rule { hosts = [\u0026#34;*\u0026#34;] path_matcher = \u0026#34;allpaths\u0026#34; } path_matcher { name = \u0026#34;allpaths\u0026#34; default_service = google_compute_backend_service.api.id path_rule { paths = [\u0026#34;/static\u0026#34;, \u0026#34;/static/*\u0026#34;] service = google_compute_backend_bucket.cdn.id } } } アクセスはapi.example.comのサブドメインで受け、基本的にはバックエンドサービス(Cloud RunやApp Engineなど)に流すが、パスが/static/の場合にのみCDNに流すという設定がこれでできる。\n注意なのがパスの構成はCDNにも伝播するのでバケットの第一階層にstaticという名前のディレクトリを作り、その中にsample.jpgなどの画像を置く必要がある。 そこでようやくapi.example.com/static/sample.jpgというURLにアクセスしてデータを参照できる。\n受けたパス階層から別のパスにリライトする設定も可能なのだが、/staticを/にリライトするものはデフォルトサービスとぶつかってしまうためできない。 そのためバケットの第一階層がstaticというフォルダを置くしかないのが気持ち悪いと感じる場合は大人しくCDN用にサブドメインを切るのが懸命。\n","categories":["tech"],"date":1650412800,"description":"GCPでTerraformを使ってCDNを構築する方法についてまとめる","permalink":"http://komi.dev/post/2022-04-21-axum-and-sqlx/","publishdate":"2022-04-20T00:00:00Z","section":"post","tags":["terraform","gcp"],"title":"GCPでCDNをTerraformで実装する","url":"/post/2022-04-21-axum-and-sqlx/"},{"body":"スマホアプリ開発は全く難しくない 前回のエントリーで起業した旨について書いたのだが、事業のコアとなるアプリケーションはWebサイトとしては展開せずスマホアプリに絞ることとなった。 今の会社はエンジニアは自分一人なので当然開発も自分しかやる人間がおらず(CEOはかなりテックがわかる人間だがデザインだけ手伝ってもらっている)、そんなこんなで現在はスマホ向けアプリ開発としてFlutterを書いている。\n自分の今までの開発スキルとしてはWebフロントエンド(React)、バックエンド(Python, Rust, etc\u0026hellip;)、 インフラ周り(Kubernetes、含む)、データ基盤といった具合でかなり広い分野をカバーしているのだが、実はスマホアプリというのは経験がなかった。 なので今回スマホ向けに展開していくという話を聞いたときは正直「(自分の未経験分野なんだよな\u0026hellip;)」と身構えていたところがあった。\nただ完全に未経験ということは無くて、OSSでターミナルエミュレータの開発だったりグラフプロットライブラリだったりとOSなどのシステムプログラミングに近い分野を経験していたので、なんとなくの感覚はわかってはいるつもりだった。\nただ、今回触ってみての感想だが、とにかく簡単。 書いているときの感覚はReactと同じで、宣言的UIでパーツを作って組み合わせる。 宣言的UIということでReactと同様に状態管理をどうする的な問題は出てくるのだけど、これの解決方法としてはコンポーネント間で状態管理バケツリレーをするかReduxのような外部で状態管理してくれるライブラリを利用するかといった具合となる。\nReactよりも簡単だと思ったのはCSSと格闘しなくて良い点で、Flutterにはデフォルトでマテリアルデザインに準じたコンポーネントが用意されているので、これを場所と大きさを指定して配置するだけのパズルとなる。\nとにかくこれは本当にソフトウェアエンジニアリングなのかと思う。 マインクラフトの方が難しい気がする。\n界隈の人間が信じられなくなった 数年前の話だが新卒就活をしていたとき、当時の自分は機械学習に詳しい若手というような売り込み方で就活をしていた。 同時に新卒800万芸という「新卒でもスキルある若手なんだから年収800万よこせ」という芸風もやっていた。 思い返してみれば2020年頃はAIがバズワードとなっていた時代で(その中では終末期であったが)、少し理論的に機械学習がわかるというだけで結構需要がある時代だった。 そういった背景から年収800万くらいは貰えてもおかしくない、たしかに妥当な数字であったと思う。 余談だが自分は現在はほとんど機械学習をやっていない。\nその頃に同世代でAndroidエンジニアのヤツと繋がったのだが、そいつは「Android開発は特殊スキルだから初任給はそれなりに期待するわ」といった旨の発言をしていた記憶がある。 当時は自分もスマホ向けアプリの知識がなかったので「まあきっと特殊なスキルなんだろうな」くらいの認識だった。 実際、ツイッターではスマホ向けアプリ開発は一部の人間にしかできないんだぞー的な空気感を一部の人間が出していた気がする。\nそんなわけだが、先述した通り今回自分で開発してみて全くスキルの特殊性が感じなかった。 一体なんだったんだろう。 結局ブランディングだったのだろうか。 もちろん当時はFlutterは無かったのだろうけど、それでもそれに相当するインターフェースをiOSもAndroidも持っていたはずなので適切に開発作業を行えば問題なくこなせそうではある。\nスマホ向けアプリ開発は特殊スキルなのか スマホ向けアプリは開発エコシステムが過度に発達した結果、誰でも開発できるようになっている。 しかもそれなりの水準のものが。\nどうやら世の中にはFlutterに特化したエンジニア向けオンラインサロンがあるらしい。 なんだかそこまでスキル的に尖ってなくてもポジショニングだけ上手にやって情弱を食い物にする構図がスマホアプリ開発界隈にはあるような気がしている。\n(ピュアにFlutter\u0026quot;自体\u0026quot;のコミッターは除き)Flutter界隈には近づかない方が良い気がしている、というのが今回Flutterを使えるようになっての学びだと思う。\n","categories":["tech"],"date":1647820800,"description":"スマホ向けネイティブアプリの開発は思っていたより簡単で、特にこれらの分野のスキルの特殊性は無いとわかった","permalink":"http://komi.dev/post/2022-03-21-flutter-is-easy/","publishdate":"2022-03-21T00:00:00Z","section":"post","tags":["flutter"],"title":"Flutterは全く難しくない","url":"/post/2022-03-21-flutter-is-easy/"},{"body":"起業することにした かなり唐突だが、起業をすることにした。 どんなことをやるかというと、地域特化型のニュースアプリといったようなものを作る。 まだほやほやの起業したてで、LPすらまだ無いので特に何か紹介ができるわけでもないので、会社についての紹介はまた追って別のエントリーでやりたいなと思う。 以下では今回の起業に際して自分がどんなことを考えていたか、背景や今後の展望について備忘録としてまとめていく。\n背景 これまでの自分の働き方はどうだったかというと、一応heyで正社員をしていたのだが、それとは別で副業で業務委託として仕事を受けたりしていた。 業務委託の内容としては技術顧問としてコンサルティングやアーキテクチャリング、または技術サポートとしてスタートアップで開発のお手伝いだったりデータ基盤の整備など、技術畑の人間としてかなり雑多なことをしていた。\nなので今までも半分正社員で半分フリーランスというような感じで、正直なところ経済的にはそれなりに余裕はあったし稼働時間や忙しさといったところもそこまで大変という感覚はなかった。 実際、収入としては毎月100万円を下回ることは無かったし、今は家賃24万円の家に住みながら貯金も毎月40万円程度できている。 24, 25歳にしてはだいぶちゃんとしてる方だという自覚はある。\nではそのような状況下でどうして今回の起業したかというと、経済的にも忙しさ的にも大変さは無くてもやはり仕事に対して情熱を感じたかったというのが大きい。 逆に、今のままでも別に収入などは安定していて生きていくことは全然問題なかったのだろうけど、5年もすれば自分の心は確実に死んでいただろう。\nかなり鬱屈していた日々を過ごしていたのだが、そんなタイミングに元同僚から声をかけてもらい、これは自分にとって最大のチャンスなんだろうと感じて起業に踏み切った。 元々自分は起業したい欲というのがあり、ただそれをいつ実行に移すのか、タイミングについてはずっと伺っていた。 ただ、考えていた流れとしてはheyというスタートアップから次はFAANGやMSといった外資系に行き、そこで多少働いてから起業するというのがいい感じにネームバリューをつけつつ起業に持っていく流れかなと想像していた。\nこのような具合でいつ起業するのかというのは考えていたが、一方で誰と起業するかというのも結構重要な気がしていた。 タイミングは上記のようにするとしても誰と起業するかというのは見えていなかった。 今回声をかけてくれて一緒に起業する人は自分の元同僚で、エンジニアリングがわかるデータアナリストなのだが、一緒のチームで働いていたので極めて優秀だというのはわかっており、この人とならやっていけるという確信があったので誘いに乗ることにした。\n今回起業したのは全く自分にとって予期していたことではなく、偶然タイミングが来たからというのが本音だろう。\n自社プロダクトのコードから学ぶことはない 最近はプログラミングスクールが跋扈して駆け出しエンジニアが量産されているのだが、そのようなビギナーはどうやら自社プロダクトを持っている会社で働きたいという考えを持っているらしい。 曰く、やはりSESという人売りビジネスで鉄砲玉として扱われるくらいなら自身が主体性を持って取り組める何かが欲しいというようなことらしい。\nそんなわけで自社プロダクトが開発できるポジションは人気なわけだが、個人的にはこれには全く賛成できない。 というのも(主語が大きくなって恐縮だが)自社プロダクトのコードは品質が低いのが普通だから。 ここでいうコードの品質とは、いわゆるリーダブルコードに書いてあるような変数命名だったりディレクトリ構成デザイン、データベース設計、CI/CDなどモダンな開発環境など。 実際、飛ぶ鳥を落とす勢いのベンチャーと言われているところでさえも、もう時代は令和だというのにプロダクション環境に一切Dockerを使わず生のEC2にデプロイしてアクセスがスパイクするときは手で頑張ってインスタンスを増やして水平スケールさせる、みたいなことをしていたりする。 せっかくAWSを使っているのだからECSなりフルマネージドのサービスを使った方が運用負荷も低減できるのではないかと聞いてみたらこっちの方が慣れているし簡単という回答が返ってくる。 つまりそういうレベルなのだ。\n一方で、自分はたまにOSSにコミットしていたりするのだけど、イケてるOSSのメンテナーは本当にレベルが高くて、自分がこれで良いだろうと思ったコードがレビューして修正してもらうと更に良いものになったりする。 スケーラブルで良い設計と良い実装が行われる場所、それがOSSなんじゃないかと思う。 自分が過去にAlacrittyのIME周りのPRを出した際は、ライブラリとしての機能のジェネリック性をどう担保するかについてかなり深い議論がなされた。 ソフトウェアエンジニアリングやコンピュータサイエンスの実務的応用がここにあるのだと強く感じた。\nそういったところをここのところ反復横跳びしていて、一旦もう正社員はいいかなという風に感じ、技術的に面白い部分はOSSで十分だろうと自分の中で線引きがつくようになった。 ということでOSS以外ではもっと自分を有効活用してくれるところに身を置くのが良いと判断し、そこで正社員エンジニアはもう辞めてフリーランスとして技術マネジメントやアーキテクチャリングに全振りすることにした。 そちらの方が報酬は高いので、正社員エンジニアとして働くことにあまり意義を感じなくなったというのが正確かもしれない。\n今後はどうするか 一旦は共同創業者としてプロダクト開発にリソースを割きつつ、もともと個人で受けていた技術顧問業や会社経由で得たコンサルティング業務にあたろうと考えている。\nただ、スタートアップを創業するといっても1年後には撤退している可能性も普通にあるので、その際はまた気分次第だが何かしら動いているだろう。 先日結婚したが、恐らく1,2年後に子供を持つ想定なので、育休を取るためにどこかの正社員になっている可能性もある。 1年後が自分が何をしているかは全然想像がつかないのだけれども。\nそれにしても、新卒でソフトバンクに入ったときはこのままぼーっとしてれば普通にある程度の給料が貰えて安定だなーなんて思っていたけれど、本当に2年前の自分からは想像できないところにきた気がする。 予想不可能な人生だけれども、これからもやれることはやっていきたい。\n","categories":["Career"],"date":1646006400,"description":"会社員をしつつ副業で業務委託をしていく中で、独立することが自分の中で良い選択であるという判断になった","permalink":"http://komi.dev/post/2022-02-28-be-entrepreneur/","publishdate":"2022-02-28T00:00:00Z","section":"post","tags":["startup"],"title":"起業してCTOになる","url":"/post/2022-02-28-be-entrepreneur/"},{"body":"Cocoaとは CocoaとはmacOSのAPI群の総称で、macOSに関する様々な機能がまとめてある。 例えば画面にウィンドウを描画するNSViewだったりOSのバージョンを出してくれるNSOperatingSystemVersionなどがある。 macOSは基本的にObjective-Cで実装されており、オブジェクト指向な設計となっているので自分たちでAPIを利用したアプリケーションを作る際は特定のクラスからサブクラスを作成して機能群を追加していくような具合となる。\nこのライブラリ系はmacOSでは/Library/Developer/CommandLineTools/SDKs/MacOSX11.1.sdk/System/Library/Frameworks/を見てみると様々なframeworkが入っている。ここでframeworkとは動的共有ライブラリや nibファイル、imageファイル、ローカライズファイル、ヘッダファイル、ドキュメント等のリソースファイルを１つのパッケージにまとめたディレクトリ。\nRustから触る Rustはlinkアトリビュートを持っており、これを以下のように用いることで使える。\n#[link(name = \u0026#34;AppKit\u0026#34;, kind = \u0026#34;framework\u0026#34;)] extern \u0026#34;C\u0026#34; {} このコードではAppKitというframeworkを利用する際の宣言で、これによりobjcクレートを用いて\nuse objc; fn main() { let cls = unsafe { objc::class!(NSView) }; } として使える。\nちなみにlinkアトリビュートはexternとセットじゃないと意味がないらしく、\nuse objc; #[link(name = \u0026#34;AppKit\u0026#34;, kind = \u0026#34;framework\u0026#34;)] fn main() { let cls = unsafe { objc::class!(NSView) }; } というコードではエラーを吐いてしまう。\nobjc::class!マクロは内部的に\n#[macro_export] macro_rules! class { ($name:ident) =\u0026gt; ({ #[allow(deprecated)] #[inline(always)] fn get_class(name: \u0026amp;str) -\u0026gt; Option\u0026lt;\u0026amp;\u0026#39;static $crate::runtime::Class\u0026gt; { unsafe { #[cfg_attr(feature = \u0026#34;cargo-clippy\u0026#34;, allow(replace_consts))] static CLASS: ::std::sync::atomic::AtomicUsize = ::std::sync::atomic::ATOMIC_USIZE_INIT; // `Relaxed` should be fine since `objc_getClass` is thread-safe. let ptr = CLASS.load(::std::sync::atomic::Ordering::Relaxed) as *const $crate::runtime::Class; if ptr.is_null() { let cls = $crate::runtime::objc_getClass(name.as_ptr() as *const _); CLASS.store(cls as usize, ::std::sync::atomic::Ordering::Relaxed); if cls.is_null() { None } else { Some(\u0026amp;*cls) } } else { Some(\u0026amp;*ptr) } } } match get_class(concat!(stringify!($name), \u0026#39;\\0\u0026#39;)) { Some(cls) =\u0026gt; cls, None =\u0026gt; panic!(\u0026#34;Class with name {} could not be found\u0026#34;, stringify!($name)), } }) } という具合でobjc::runtime::objc_getClass()という関数を叩いてクラスを呼び出しており、この関数自体は\n/// A marker type to be embedded into other types just so that they cannot be /// constructed externally. type PrivateMarker = [u8; 0]; /// A type that represents an Objective-C class. #[repr(C)] pub struct Class { _priv: PrivateMarker, } #[link(name = \u0026#34;objc\u0026#34;, kind = \u0026#34;dylib\u0026#34;)] extern \u0026#34;C\u0026#34; { ... pub fn objc_getClass(name: *const c_char) -\u0026gt; *const Class; ... } というようにObjective-Cの関数となっている。\nこれらを用いてmacOSの機能を利用することができ、RustからMetalを触ることなどができる。\n終わりに ここ数日AlacrittyのIME対応のPRを出してやり取りしているのだけど、この実装の中でmacOSのクレート周りが非常に使いづらいことに気がつき、試験的に自分でmacOSのAPIラッパーを書けるか試していた。 そんな中で今回Rustのリンカー周りの挙動が気になったので調べてみた次第。\n","categories":["Tech"],"date":1643155200,"description":"RustからmacOSのAPIであるCocoaを触る際、どのようにリンクが行われるかについて見ていく","permalink":"http://komi.dev/post/2022-01-26-objc-from-rust/","publishdate":"2022-01-26T00:00:00Z","section":"post","tags":["Rust","macOS"],"title":"RustからCocoaを触る","url":"/post/2022-01-26-objc-from-rust/"},{"body":"はじめに 最近はデータに基づいた意思決定が云々ということで多くの組織でデータ基盤を整備する流れがある。\nデータ基盤の主要となるコンポーネントは何かというと、\nコンポーネント 役割 例 BIツール データの可視化、ダッシュボードの構築 ReDash、Looker、Metabase データウェアハウス 整備済みのデータを蓄積する場所 BigQuery, Redshift データパイプライン アプリケーションDBからデータウェアハウスへデータを加工・転送するための基盤 Airflow, Luigi, Kubeflow, Argo Workflows、Digdag というような感じになっていて、目的や供与可能なコスト分を考えながらここらへんをうまいこと組み合わせてデータ基盤というのは構築される。\n最近では多くの企業でデータエンジニアというポジションが募集されており、データエンジニアは何をしているかというとここらへんの構築・整備を行う。\n正直なところデータエンジニアの仕事というのはエンジニアリング的に難しいことは何もなくて、基本的に社内政治に振り回されながら泥臭い作業を行うだけの妖怪になるという悲しい役割に終始するのだけれど、ひとまず業務としてはワークフローエンジンの整備を行う。\nワークフローエンジンに何を使うかについては結構トレンドがあり、少し前(だいたい5年前とか？)はDigdagを使うのが主流だったのだけれど最近はユーザーも離れてしまいあまり開発も活発ではなくなってしまっており(DigdagはJavaで作られているのだが最近のLog4jの問題が発覚した際も関連Issueが全く立っていない)、今の流行りはAirflowあたりな気がしている。\nただ、最近AirflowからArgo Workflowsへ乗り換えようと検討するケースがたくさんあり、今後はArgo Workflowsがブームになりそうであるため、今回の記事ではArgo Workflowsについての基礎的な文法や色々についてまとめておこうと思う。\nArgo Workflowsについて Argo Workflowsは要するにただのワークフローエンジンなのだけれど、なぜAirflowなどと比較して良いとされているかというと以下のようなポイントがある。\nKubernetesネイティブな設計となっており、ジョブごとにPodに切り分けて実行してくれるためコンピューティングリソースを有効活用できる ワークフロー定義などはKubernetesのマニフェストとなっていて、ワークフローの定義と各タスクにおけるロジックの関心が分離できる Airflowと同様のことができ、よりジェネラルなワークフローエンジンとなっている AirflowやLuigiはPythonによってワークフローを記述していくが、Argo Workflowsはワークフロー自体はyamlで記述して各タスクについてはDockerイメージを実行するという機構になっているので、かなりジェネリックにタスクを投げることができる。\nデータエンジニアリングは基本的に付加的に要件が増えて様々なケースに対応する必要があり、差分デプロイが用意な機構となっているArgo Workflowsはデータエンジニアリングと非常に相性がいいのである。\nこうした点から最近はArgo Workflowsが使われるケースが増えている。\nということでArgo Workflowsについて簡単な解説をしようと思うのだけれど、日本ではArgo Workflowsを使っているケースがまだまだ少なく日本語の解説記事も少ないのでちょっとしたまとめを書いておこうと思う。\n環境構築 Argo Workflowsを使うにあたってまず準備する必要がある。\n本家のドキュメントを見てみるとQuick Startはあるようだけど、実際にプロダクション環境で使うにはどのようなマニフェストになるかについては詳しく書いてない(なんでやねん)\nということで基本的にQuick Startのやつを分解してプロダクション向けにカスタマイズしまくるのだけど、詳しいセットアップについては以下の記事を書いたので参照していただきたい。\nArgo Workflowsをセットアップする\n(会社のブログじゃなくてこっちのブログで書けばよかったな\u0026hellip;)\nArgo Workflowsのコンポーネント Argo Workflowsでは以下の概念がある。\n概念 解説 Workflow 実行されるワークフローのこと WorkflowTemplate 再利用性のあるワークフローで、ライブラリのように使える。他のWorkflowTemplateを参照でき、これをSubmitすることでWorkflowが実行される。 CronWorkflow Cronジョブで、WorkflowTemplateを指定する 例えばWorkflowの定義は以下のようになる。\napiVersion: argoproj.io/v1alpha1 kind: Workflow metadata: generateName: hello- namespace: argo spec: entrypoint: example serviceAccountName: argo-sa templates: - name: example steps: - - name: print-message template: whalesay arguments: parameters: - name: message value: \u0026#34;{{item}}\u0026#34; withItems: - hello world - goodbye world - name: whalesay inputs: parameters: - name: message container: image: docker/whalesay:latest command: [cowsay] args: [\u0026#34;{{inputs.parameters.message}}\u0026#34;] 上記のマニフェストではtemplatesフィールドでWorkflowTemplateのリストが格納されており、それぞれにどのようなタスクをこなさせるかが記述される。\n見ての通りtemplate: whalesayとして他のWorkflowTemplateを呼び出しており、感覚として関数定義とその呼び出しに近い。\n一部で\u0026quot;{{...}}\u0026quot;という記述があるが、これはGoテンプレートの特徴で(ArgoはGoで開発されている)、ここにメタ的に変数を格納することができる。\n注意点としてserviceAccountNameというフィールドがあり、ここでどのKubernetesサービスアカウントを使うかを指定する必要がある(これを指定していないとデフォルトのサービスアカウントが使用され権限エラーでPodを作成することができなかったりする)\nfor文 loop系の処理をどのようにさせるかというと2通りのやり方があり、withItemsとwithSequence、withParamがある。\nwithItemsについては上記の例の通りでArray\u0026lt;String\u0026gt;の値として入れることによってその中身でループさせることができる。\nなお、ループで入る一時変数は\u0026quot;{{item}}\u0026quot;で受け取れる。\nwithSequenceについてはPythonでいるfor i in range(10, 20)のようなノリで、\n- name: sequence-start-end template: echo withSequence: start: \u0026#34;100\u0026#34; end: \u0026#34;105\u0026#34; というように使える。\nまた、withSequenceの中身は\n- name: sequence-start-end template: echo withSequence: count: \u0026#34;5\u0026#34; というようにcountを使っても良い。\nどのような範囲でループさせるかを動的に決定したい場合はwithParamを使えば良く、\nspec: entrypoint: loop-param-result-example templates: - name: loop-param-result-example steps: - - name: generate template: gen-number-list - - name: sleep template: sleep-n-sec arguments: parameters: - name: seconds value: \u0026#34;{{item}}\u0026#34; withParam: \u0026#34;{{steps.generate.outputs.result}}\u0026#34; - name: gen-number-list script: image: python:alpine3.6 command: [python] source: | import json import sys json.dump([i for i in range(20, 31)], sys.stdout) - name: sleep-n-sec inputs: parameters: - name: seconds container: image: alpine:latest command: [sh, -c] args: [\u0026#34;echo sleeping for {{inputs.parameters.seconds}} seconds; sleep {{inputs.parameters.seconds}}; echo done\u0026#34;] というように最初のstepでパラメータを生成させて、それを利用させることができる。\n注意点としてパラメータのリストはJSONの形をしている必要がある。\nこの例ではscriptフィールドによってパラメータのリストを生成しているが、以下のようにコンテナ内のファイルについてループを回したいケースではbashでファイルのリストを生成して\u0026hellip;というやり方もできる。\nspec: serviceAccountName: argo-sa entrypoint: sample-workflow templates: - name: sample-workflow steps: # List tables - - name: tables template: list-tables - - name: transform template: transform-per-table arguments: parameters: - name: message value: \u0026#34;{{item}}\u0026#34; withParam: \u0026#34;{{steps.tables.outputs.result}}\u0026#34; - name: list-messages container: image: image-name1 command: [\u0026#34;/bin/bash\u0026#34;, \u0026#34;-c\u0026#34;] args: - | find ./sql -type f -name \u0026#34;*.sql\u0026#34; \\ | xargs -IFILENAME basename FILENAME .sql \\ | jq -R \\ | jq --slurp . - name: transform-per-table inputs: parameters: - name: table container: image: image-name2 command: [\u0026#34;./main.sh\u0026#34;] args: [\u0026#34;{{inputs.parameters.table}}\u0026#34;] 引数にenumを使う 引数にはenumを指定することができ、\nspec: serviceAccountName: argo-sa entrypoint: sample-workflow templates: - name: transform-per-table inputs: parameters: - name: db enum: - secure - normal description: \u0026#34;Select Database type\u0026#34; container: image: image-name2 command: [\u0026#34;./main.sh\u0026#34;] args: [\u0026#34;{{inputs.parameters.db}}\u0026#34;] として引数のパターンを制限することでエラーケースを狭めることでテストを容易できる。\nif文 for文を実行できるので当然if文も使える。\nspec: serviceAccountName: argo-sa entrypoint: sample-workflow templates: - name: sample-workflow steps: # List tables - - name: tables template: list-tables - - name: transform template: transform-per-table arguments: parameters: - name: message value: \u0026#34;{{item}}\u0026#34; when: \u0026#34;{{inputs.parameters.tables}} =~ \u0026#39;^test_\u0026#39;\u0026#34; 比較の部分については==といった等号判定や上記の例のように=~で正規表現を用いたパターンマッチもできる。\n環境変数 Argo Workflowsは本質的にKubernetesなので当然コンテナに環境変数を注入することもできる。\nspec: serviceAccountName: argo-sa entrypoint: sample-workflow templates: - name: load-per-table inputs: parameters: - name: db enum: - secure - normal description: \u0026#34;Select Database type\u0026#34; container: image: image-name command: [\u0026#34;./main.sh\u0026#34;] args: [\u0026#34;{{inputs.parameters.db}}\u0026#34;] env: - name: ENVIRONMENT valueFrom: configMapKeyRef: name: env-var-config key: environment - name: AWS_ACCESS_KEY_ID valueFrom: secretKeyRef: name: credentials key: aws-access-key-id - name: AWS_SECRET_ACCESS_KEY valueFrom: secretKeyRef: name: credentials key: aws-secret-access-key - name: AWS_DEFAULT_REGION value: ap-northeast-1 中身としてはvalueで直接書き込むこともできるし、valueFrom.configMapKeyRefでConfigMapから読み取ったりvalueFrom.secretKeyRefでSecretから読み取ることもできる。\nこれで環境変数をコンテナ内に注入することができるが、もしargs:フィールド等でマニフェストとして利用する際は\ncontainer: image: image-name command: [\u0026#34;./main.sh\u0026#34;] args: [\u0026#34;$(ENVIRONMENT)\u0026#34;] env: - name: ENVIRONMENT valueFrom: configMapKeyRef: name: env-var-config key: environment のように$(...)として丸括弧で括る必要があるので注意。\nSlack通知 ワークフローが落ちたときはSlack通知して欲しかったりする。\nそういうときはworkflow-controller-configmapに以下のデフォルトのワークフローの設定を追加すれば良い。\napiVersion: v1 kind: ConfigMap metadata: name: workflow-controller-configmap data: workflowDefaults: | spec: onExit: exit-handler serviceAccountName: argo-sa templates: - name: exit-handler container: image: asia.gcr.io/my-repo/failure-alert:latest command: [ \u0026#34;bash\u0026#34;, \u0026#34;main.sh\u0026#34; ] env: - name: ENVIRONMENT valueFrom: configMapKeyRef: name: env-var-config key: environment - name: HOST valueFrom: configMapKeyRef: name: env-var-config key: host - name: WEBHOOK_URL valueFrom: secretKeyRef: name: credentials key: slack-webhook-url - name: WORKFLOW_STATUS value: \u0026#34;{{workflow.status}}\u0026#34; - name: WORKFLOW_NAME value: \u0026#34;{{workflow.name}}\u0026#34; この設定をすれば全ワークフローにこのテンプレートが追加され、onExitの条件からワークフローが終了した際はここで定義されたワークフローが実行される。\n実行されるスクリプトについては以下のようにSlack Webhook URLにcurlさせれば良い。\n#!/bin/bash set -eu if [ \u0026#34;$ENVIRONMENT\u0026#34; = \u0026#34;dev\u0026#34; ]; then color=\u0026#34;good\u0026#34; elif [ \u0026#34;$ENVIRONMENT\u0026#34; = \u0026#34;stg\u0026#34; ]; then color=\u0026#34;warning\u0026#34; elif [ \u0026#34;$ENVIRONMENT\u0026#34; = \u0026#34;prd\u0026#34; ]; then color=\u0026#34;danger\u0026#34; else echo \u0026#34;Invalid value: ENVIRONMENT\u0026#34; exit 1 fi if [ \u0026#34;$WORKFLOW_STATUS\u0026#34; = \u0026#34;Succeeded\u0026#34; ]; then echo \u0026#34;Succeeded.\u0026#34; exit 0 fi curl \\ -X POST \\ -H \u0026#34;Content-type: application/json\u0026#34; \\ --data \\ \u0026#39;{ \u0026#34;attachments\u0026#34;: [ { \u0026#34;title\u0026#34;:\u0026#34;Workflow status: \u0026#39;$WORKFLOW_STATUS\u0026#39;\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;\u0026#39;$color\u0026#39;\u0026#34;, \u0026#34;fields\u0026#34;: [ { \u0026#34;title\u0026#34;: \u0026#34;Environment\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;\u0026#39;$ENVIRONMENT\u0026#39;\u0026#34;, \u0026#34;short\u0026#34;: false }, { \u0026#34;title\u0026#34;: \u0026#34;Workflow Name\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;\u0026#39;$WORKFLOW_NAME\u0026#39;\u0026#34;, \u0026#34;short\u0026#34;: true }, { \u0026#34;title\u0026#34;: \u0026#34;URL\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;https://\u0026#39;$HOST\u0026#39;/archived-workflows/argo/?phase=Failed\u0026#34;, \u0026#34;short\u0026#34;: false } ] } ] }\u0026#39; \\ \u0026#34;$WEBHOOK_URL\u0026#34; GKEでArgo Workflowsを利用する際の注意 Argo WorkflowsをGKEで利用する際、Workload Identityでサービスアカウント認証をしているケースで注意しておくことがある。\nそれは、GKEメタデータサーバーが新しく作成されたPodでリクエストの受信を開始できるようになるまでに数秒かかるため、そこでPodが作成されてからすぐだとGCP APIを使えない可能性がある。\nGKEでのWorkload Identityではサービスアカウントの認証は内部的に以下のようなエンドポイントに対してアクセストークンを払い出している。\ncurl -s \\ -H \u0026#39;Metadata-Flavor: Google\u0026#39; \\ \u0026#39;http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/token\u0026#39; Podが作成された直後はメタデータサーバーがそのPodを認識できないため、gcloudコマンドを叩いても認証エラーになるケースがあり、以下のようにinitContainersフィールドによってメタデータサーバーとの疎通を確認してからジョブを実行させると安定する。\napiVersion: argoproj.io/v1alpha1 kind: WorkflowTemplate metadata: name: foo-workflow-template namespace: argo spec: serviceAccountName: argo-sa entrypoint: foo-workflow templates: - name: hoge-workflow-load-per-table initContainers: - image: gcr.io/google.com/cloudsdktool/cloud-sdk:326.0.0-alpine name: workload-identity-initcontainer command: - \u0026#39;/bin/bash\u0026#39; - \u0026#39;-c\u0026#39; - | curl -s -H \u0026#39;Metadata-Flavor: Google\u0026#39; \u0026#39;http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/token\u0026#39; --retry 30 --retry-connrefused --retry-max-time 30 \u0026gt; /dev/null || exit 1 containers: - image: image-name ... 終わりに 今回書いた内容を押さえておけば恐らくArgo Workflowsは問題なく使えると思われる。\n今後どのワークフローエンジンが流行るのかわからないが、Argo Workflowsは極めて使いやすいため恐らく覇権を取れる気がする(?)\n","categories":["Tech"],"date":1641686400,"description":"データエンジニアリングの技術が成熟してきた中でまだポピュラーではないArgo Workflowsについてのちょっとした解説","permalink":"http://komi.dev/post/2022-01-09-introduction-to-argo-workflows/","publishdate":"2022-01-09T00:00:00Z","section":"post","tags":["Kubernetes","Argo Workflows"],"title":"Argo Workflowsの設定や文法","url":"/post/2022-01-09-introduction-to-argo-workflows/"},{"body":"Envoyとは EnvoyはL4/L7レイヤで動作するプロキシで、ロードバランスだったりネットワークとアプリケーションの分離なり、とても柔軟使えるOSS。 ネットワーク関係の色々困りごとを解消してくれる優れものだったりする。\n開発元はLyftで、急速に普及したマイクロサービスの分散システム構築・運用を安定させるため2015年5月から始まったプロジェクト。\n実装言語としてはC++が使われている。\n今回の記事では、そんなEnvoyをKubernetes上で動作するgRPCに対して適用させる。\ngRPCアプリとEnvoy gRPCとはHTTP/2上で動作するプロトコルで、JSONの強いバージョンみたいなもの。\nHTTP/2は普段慣れ親しんでいるHTTP/1.1と何が違うかというと\nバイナリベース ヘッダー圧縮 ストリーム などの差分がある。\n1つ目のバイナリベースというのは、HTTP/1.1はテキストベースのプロトコルで各リクエストを受け取った際はテキストからバイナリへパースしてあげる必要があったのだけど、それが無駄ということでHTTP/2からはバイナリがデフォルトになり通信が高効率になった。\n2つ目のヘッダー圧縮というのは、ヘッダー情報にはどのHTTPメソッドを使っているかとかアクセスしているホストはどれだとか色々情報が格納されているのだけど、これを同じホストに対して複数回リクエストを飛ばすようなケース(Webサイトに対してHTMLファイルをリクエストしたあとCSSファイルをリクエストしたりする場合など)だとヘッダ情報には同じような情報ばかりでもう一度大量のヘッダ情報を送るのは無駄となってくる。 そのようなケースに対応するためにHTTP/2ではヘッダ情報には変更があった分だけ送るように変更される。\n3つ目のストリームは、もともとHTTP/1.1ではリクエストとレスポンスの組を1つずつしか同時に送受信できず、これがボトルネックとなっていたことからHTTP/2ではストリームという仮想的な双方向シーケンスを作り、それを多重化することで柔軟な通信が実現できるようになった。 ちなみにこの双方向シーケンスというとWebSocketにも同様の機能が提供されているのだけど(WebSocketの方がHTTP/2より簡単な実装になっている)、ここらへんの話は非常に長くなるのでまた別の機会に。\n今回出てくるgRPCはHTTP/2上で動作するプロトコルで、これは非常に高速で優秀であるが実はロードバランサと少々相性が悪い。 というのもHTTP/2の特徴としてストリームがあり、これはサーバーとクライアントの間のコネクション上にピタッと張られるもので、負荷が大きくなった際にサーバーを水平スケールさせるためには多少の工夫が必要となる。 つまり意図的にTLS終端を担ってくれるアプリケーションを中間に用意して別途アプリケーションへネットワークをリレーしてもらわないとHTTP/2の世界ではロードバランスできない。\nそこで今回出てくるのがEnvoyで、Serviceから飛んできたリクエストを一旦Envoyが受け取り、ロードバランスを考えてどのPodに受け渡すかを上手いことやってくれる。\n実装する ということでマニフェストを眺めていく。\nまずEnvoyはDeploymentにてサイドカーとして立てるので、以下のように並べてあげる必要がある。\napiVersion: apps/v1 kind: Deployment metadata: name: my-server spec: selector: matchLabels: app: my-server template: metadata: labels: app: my-server spec: containers: - name: my-server image: gcr.io/my-app/some-image:latest args: - /bin/ls ports: - name: web containerPort: 8888 volumeMounts: - mountPath: /tmp name: tmp - name: envoy image: envoyproxy/envoy:v1.20.0 command: - \u0026#34;/usr/local/bin/envoy\u0026#34; args: - \u0026#34;--config-path /etc/envoy/envoy.yaml\u0026#34; resources: limits: memory: 512Mi ports: - containerPort: 15001 name: app - containerPort: 8001 name: envoy-admin volumeMounts: - name: envoy mountPath: /etc/envoy volumes: - name: envoy configMap: name: my-envoy-configmap ポイントとしてEnvoyはAdmin用のポートとアプリケーションとしてのポートを別途開けておく必要がある。\nそしてEnvoyをどのように動作させるかはConfigMapに記述をする。\n以下がEnvoyのConfigMapとなる。\nちなみに以下の文法はEnvoyのv3 APIで、v1やv2とはやや異なることに注意。\napiVersion: v1 kind: ConfigMap metadata: name: my-envoy-configmap data: # Adding new entries here will make them appear as files in the deployment. # Please update k8s.io/k8s.io/README.md when you update this file envoy.yaml: | static_resources: listeners: - address: socket_address: address: 0.0.0.0 port_value: 15001 filter_chains: - filters: - name: envoy.filters.network.http_connection_manager typed_config: \u0026#34;@type\u0026#34;: type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager codec_type: AUTO stat_prefix: ingress_http route_config: name: local_route virtual_hosts: - name: backend domains: - \u0026#34;*\u0026#34; routes: - match: prefix: \u0026#34;/\u0026#34; route: cluster: local_service http_filters: - name: envoy.filters.http.router typed_config: {} clusters: - name: local_service type: STRICT_DNS lb_policy: ROUND_ROBIN load_assignment: cluster_name: local_service endpoints: - lb_endpoints: - endpoint: address: socket_address: address: local_service port_value: 2746 admin: access_log_path: \u0026#34;/dev/null\u0026#34; address: socket_address: address: 0.0.0.0 port_value: 8001 layered_runtime: layers: - name: static_layer_0 static_layer: envoy: resource_limits: listener: example_listener_name: connection_limit: 10000 だいたいは引数名を見ればどういう設定をしてるかがわかるが、listers内のフィルタ周りのところでどのドメインから来たリクエストをどのクラスタへルーティングする記述があり、ここで送るクラスタはclustersと同じ名前を設定する必要がある。\n終わりに 仕事でEnvoyを触る必要があり色々ググってみたところv3 APIの日本語記事が少なかったので書いてみた。\nここらへんの実装を終えてから実は要件としてEnvoyは必要がなかったということが発覚したのだけど、今回色々調査しながらEnvoyを触ったのでメモ。\n","categories":["Tech"],"date":1636934400,"description":"gRPCアプリケーションにてIngressからのリクエストに対してL7レイヤで動作するロードバランサを構築する","permalink":"http://komi.dev/post/2021-11-15-introduce-envoy/","publishdate":"2021-11-15T00:00:00Z","section":"post","tags":["Kubernetes","Envoy"],"title":"LoadBalancerとしてEnvoyを導入する","url":"/post/2021-11-15-introduce-envoy/"},{"body":"Cloud DNSとGoogle Domains、Cloud Domains Googleが提供しているDNS系のサービスとしてCloud DNSとGoogle Domains、Cloud Domainsの3つがある。 これらの違いは何かというと、\n機能 Cloud DNS ゾーンとレコードの設定 Google Domains ドメインの取得、ネームサーバーの設定 Cloud Domains ドメインの取得、ネームサーバーの設定 となっている。 Google DomainsとCloud Domainsの機能はほぼ完全に被っているが、これはCloud Domainsが割と最近のサービスでGCPのコンソールからGoogle Domainsと同様のことができるようになったというのが理由となっている。 参考としてはCloud Domains のご紹介: カスタム ドメインの登録と管理を簡素化がちょうど良さそう。 なお、Cloud Domainsはこのドキュメントに書いてある通り、背後ではGoogle Domainsを登録事業者としているため、インターフェースの違いはあれど実質的に同じものと見て良い気がする。\nやってみる 今回の流れとして、何かしら自分のWebサイトにてドメインを当てたいケースを考える。 手元には複数サービスを立てたいため、example.com以外にfoo.example.comというようなサブドメインを作って各サービスを立てるものとする。 また、staging環境とproduction環境は分けたいため、staging環境ではhoge.staging.example.comというようなサブサブドメインで吸収する。\n以下、これをTerraformで実装していく。\nGoogle Domainsにてドメインを取得する これはサイトの通りに従って購入する。\nCloud DNSでゾーンを構成する 最初はProduction環境について。\nまず大元となるマネージドゾーンを構成する。\nresource \u0026#34;google_dns_managed_zone\u0026#34; \u0026#34;production\u0026#34; { name = \u0026#34;production\u0026#34; dns_name = \u0026#34;example.com.\u0026#34; description = \u0026#34;some description\u0026#34; } output \u0026#34;managed_zone\u0026#34; { description = \u0026lt;\u0026lt;DESC some description \u0026gt;\u0026gt; value = google_dns_managed_zone.production.name_servers } フィールドのdns_nameでは最後にピリオド.が必要だが、これはこれがドメインの末尾ですというのを示すために最後にピリオドをつける必要があり、注意。\nゾーンが構成されたら、立てたいサービスの分のグローバルIPを確保し、そのIPを用いてAレコードを構成する。\n// example.comに立てるサービス resource \u0026#34;google_compute_global_address\u0026#34; \u0026#34;service1_production\u0026#34; { name = \u0026#34;service1-production\u0026#34; } resource \u0026#34;google_dns_record_set\u0026#34; \u0026#34;service1\u0026#34; { name = google_dns_managed_zone.production.dns_name type = \u0026#34;A\u0026#34; ttl = 300 managed_zone = google_dns_managed_zone.production.name rrdatas = [google_compute_global_address.service1_production.address] } // service2.example.comに立てるサービス resource \u0026#34;google_compute_global_address\u0026#34; \u0026#34;service2_production\u0026#34; { name = \u0026#34;service2-production\u0026#34; } resource \u0026#34;google_dns_record_set\u0026#34; \u0026#34;service1\u0026#34; { name = \u0026#34;service2.${google_dns_managed_zone.production.dns_name}\u0026#34; type = \u0026#34;A\u0026#34; ttl = 300 managed_zone = google_dns_managed_zone.production.name rrdatas = [google_compute_global_address.service2_production.address] } さて、Production環境についてはこれでexample.comにservice1が、service2.example.comにservice2が立つようになった。\n次にStaging環境でこれを構成する。\n基本的には上記の通りIPを確保してAレコードを当てれば良いのだが、キーポイントとしてservice2.staging.example.comというようなサブドメインを駆使して環境差分(production/staging)を吸収するケースではstaging.example.comといった各環境ごとにゾーンを構成する方が構成として綺麗である。\n各環境ごとにゾーンを構成するためにはメインのゾーンから各環境を示すサブドメインに対してNSレコードを貼っておく必要がある。\n// NS record for staging resource \u0026#34;google_dns_record_set\u0026#34; \u0026#34;staging\u0026#34; { name = \u0026#34;staging.${google_dns_managed_zone.production.dns_name}\u0026#34; type = \u0026#34;NS\u0026#34; ttl = 300 managed_zone = google_dns_managed_zone.production.name rrdatas = google_dns_managed_zone.production.name_servers } この上で、ゾーンを構成し、各サービスについてのIPとレコードを構成する。\n// Staging Zone resource \u0026#34;google_dns_managed_zone\u0026#34; \u0026#34;staging\u0026#34; { name = \u0026#34;staging\u0026#34; dns_name = \u0026#34;example.com.\u0026#34; description = \u0026#34;some description\u0026#34; } // staging.example.comに立てるサービス resource \u0026#34;google_compute_global_address\u0026#34; \u0026#34;service1_staging\u0026#34; { name = \u0026#34;service1-staging\u0026#34; } resource \u0026#34;google_dns_record_set\u0026#34; \u0026#34;service1\u0026#34; { name = google_dns_managed_zone.staging.dns_name type = \u0026#34;A\u0026#34; ttl = 300 managed_zone = google_dns_managed_zone.staging.name rrdatas = [google_compute_global_address.service1.address] } // service2.staging.example.comに立てるサービス resource \u0026#34;google_compute_global_address\u0026#34; \u0026#34;service2_staging\u0026#34; { name = \u0026#34;service2-staging\u0026#34; } resource \u0026#34;google_dns_record_set\u0026#34; \u0026#34;service1\u0026#34; { name = \u0026#34;service2.${google_dns_managed_zone.staging.dns_name}\u0026#34; type = \u0026#34;A\u0026#34; ttl = 300 managed_zone = google_dns_managed_zone.staging.name rrdatas = [google_compute_global_address.service2.address] } Google Domainsにてネームサーバーを設定する ここまでできたらGoogle Domainsのカスタムネームサーバーにてゾーン構成時のネームサーバーを設定する。 ネームサーバーはgoogle_dns_managed_zoneリソースを実行した際にネームサーバーが自動的に設定される。\nまとめ 自分がこの作業をした際、staging.example.comのNSレコードを構成していなかったためstaging環境についてはドメインが無効で、これで数日溶かした。\nひとまずこれにて各環境差分を吸収しつつ複数サービスのドメインを設定できた。\n","categories":["Tech"],"date":1633996800,"description":"Cloud DNSでサブドメインを設定する際のマネージドゾーンなどについて","permalink":"http://komi.dev/post/2021-10-12-subdomain-with-cloud-dns/","publishdate":"2021-10-12T00:00:00Z","section":"post","tags":["DNS","Terraform","GCP"],"title":"Cloud DNSでのサブサブドメインの設定","url":"/post/2021-10-12-subdomain-with-cloud-dns/"},{"body":"Chromeでのみフォントが正しく読まれない問題 先日にブログを作り直し、現在はHugoを使ってGitHub Pages上でホスティングしている。 前までブログにははてなブログを利用していたのだが、広告が鬱陶しいと感じたため自分でホスティングし直すことにした。\nそんなわけでHugoのデザインテンプレートを利用したりして現在のブログがあるわけだけど、いつからかフォントが妙な動作をしていた。 というのも、SafariやiPhoneで見てみると正しく日本語のフォントが見えているが、なぜかChromeでのみフォントが中華フォントになっていた。\nコードを読み直してみてもカスタムCSSが適切に配置してある。 前まではChromeでもちゃんと動いていた気がするが、なにが起きていたのだろう。\n-apple-systemとBlinkMacSystemFont 使用していたデザインテンプレートのCSSではfont-familyに-apple-systemと書いてあった。 これをググってみると、どうやらSafariでは-apple-systemというのをfont-familyに指定しておけば英字書体にAppley用の英字フォント(San Francisco)が適用されるらしい。\nChromeでApple用英字フォントを使うにはBlinkMacSystemFontを指定する必要があるらしく、どうやらこれはWebkitから派生したレンダリングエンジン用フォントらしい。\nこれを適切に動作させるには-apple-systemと同時にBlinkMacSystemFontとも書いておく必要があったとのこと。\n結局どうしたか 特段フォントに対してこだわりはないので全て以下の通りに設定した。\nfont-family: Helvetica,\u0026#34;Sawarabi Gothic\u0026#34;,Meiryo,\u0026#34;メイリオ\u0026#34;,\u0026#34;Hiragino Kaku Gothic ProN\u0026#34;, \u0026#34;ヒラギノ角ゴ ProN\u0026#34;,YuGothic,\u0026#34;游ゴシック\u0026#34;,Arial,sans-serif; これでブラウザ依存の無いようにフォントが表示されるようになった。\n","categories":["Tech"],"date":1628640000,"description":"このブログで日本語フォントが中華フォントに化けてしまう問題とその直し方","permalink":"http://komi.dev/post/2021-08-11-font-in-chrome-and-safari/","publishdate":"2021-08-11T00:00:00Z","section":"post","tags":["Chrome","macOS","font"],"title":"Chromeでfont-familyを正しく設定する","url":"/post/2021-08-11-font-in-chrome-and-safari/"},{"body":"背景 先日なんとなくネットサーフィンしていたらターミナルアプリ一覧みたいな記事を見かけた。 自分は今まで惰性でmacOSでデフォルトでついているターミナルアプリを使っていて、特に不満はなかった。 範囲選択したときのハイライトが弱くて見にくかったというのはあるが\u0026hellip;.\nこの記事を見て色々試して、最初に紹介されていたAlacrittyというのを使ってみることにした。 どうやらRust製ということで速いらしい。\n早速試してみて、確かに速い。 ものすごく操作している感じが良く、URLをクリックするとブラウザに飛べるというありがたい機能も付いていた。\nしかし完璧ではなくて、日本語のIMEとあまり相性が良くなかった。 具体的にどういう症状があったかというと、\n予測変換している段階だとターミナル上に字が出てこない 予測変換の際に候補を矢印キーで選択するとコマンドヒストリーが起動してしまう などの問題があった。\nただ、自分は基本的にターミナルでは英語しか打ち込まないので問題ないと判断し、Alacriittyを普段使いに採用することにした。\nしかしやはり日本語入力が微妙なのは気になるもので、思い切って自分で直してみることにした。 気合を入れて本家のコードをforkしてきて「さあやってやるぞ」と手を入れ始めたのだが、これが地獄の入り口だった。\nObjective-C何もわからん問題 Alacrittyのコードを見てみると、GlutinというOpenGLユーティリティのようなクレートを使って画面を作ってるらしい。 つまりキー入力自体のハンドリングについては丸ごとそちら側に任せて、Alacritty自体はGlutinから受け取ったWindowEventをもとに表示をどうするかなどAPIを整えているという機能分割を行っていた。\nIssueを眺めていくとどうやらIMEの問題については既知だったらしく、いくつかIssueが立っていた(Cannot input japanese characters #1101, Support inline \u0026ldquo;input method\u0026rdquo; input #1613)\nディスカッションの様子を見ていると、どうやらAlacritty側に問題があるわけではなくWinitという低レベルOpenGLクレート側に問題があるらしい。\n依存関係としては Alacritty \u0026gt; Glutin \u0026gt; Winit となっているのだが、Glutinは内部で use winit::* ということをしていて実質的に何もしておらず、結論としてWinitを直せばAlacrittyが直るとのこと。(#comment)\nということでWinitの中身を見てみるが、やっていたことはObjective-Cのコードをひたすらラップしていたのである。 もちろん最終的には使いやすい形となるようWindowEvent関連の綺麗なstructやenumがまとまっているが、OSごとの差分をうまいこと吸収するために色々泥臭いことが行われており、そのうちmacOSの場合に行われていたのがObjective-Cのラップだった。\nちなみに最初のこの時点でIMEについては全く知らないしmacOSネイティブのアプリ開発の経験も無いからmacOSでのIME APIなんて何も知らない。 おかげさまで最初はWinitのコードを書いても何もわからなかった。\n調査を進めていく 何も知識が無くRustのコードが読み書きできる状態だったのでまずはコードを読んでわからない概念・単語を全てググっていく。\nNSViewとかNSTextView？てかNSって何の略？ コードを読んでいくとNSViewとかNSTextView、他にもNSRangeなどNSというPrefixがついた色々なものが出てくる。 もちろん知らない。\nググってみると以下の情報が出てきた。\nNeXTSTEP の権利がアップル社に移る時に開発言語のObjective-Cの権利もアップル社に移りました。そしてこのNeXTSTEPが現在のMac OS Xのベースになりました。また今から学習をはじめるObjective-Cには“NS”という文字で始まるクラスや関数が多数存在しています（クラスについては後の章で説明いたします）。このNSはNeXTSTEPの略称です。\nかつてAppleを追われたスティーブ・ジョブズはNeXTという会社を作ってNEXTSTEPというOSを販売していたが、Appleに吸収されその技術をベースに現在のmacOSができあがったため、NS〇〇というのはNeXT社の由来というものらしい。(引用元)\n逆に、今回Winitのデバッグで出てくるオブジェクトでNSというPrefixがついていればWinitではなくmacOS側のオブジェクトということになる。\nIMEを使うにはNSTextInputClientプロトコルを実装する(?) NSがmacOS側のオブジェクトというのはわかったが、ググってみるとNSTextInputClientプロトコルを実装すればIMEが機能するようになるらしい。\nプロトコルを実装するというのはピンとこなかったが、NSTextInputClientプロトコル内で使われるhasMarkedTextやselectedRange、insertTextなどの関数をアプリケーション内で動くように実装すればいいらしい。\n具体的に、例えば未確定文字列が存在するか確認するhasMarkedTextは以下のように実装する。\nextern \u0026#34;C\u0026#34; fn has_marked_text(this: \u0026amp;Object, _sel: Sel) -\u0026gt; BOOL { unsafe { trace!(\u0026#34;Triggered `hasMarkedText`\u0026#34;); let marked_text: id = *this.get_ivar(\u0026#34;markedText\u0026#34;); trace!(\u0026#34;Completed `hasMarkedText`\u0026#34;); (marked_text.length() \u0026gt; 0) as BOOL } } また、setMarkedTextは以下のようになる。\nextern \u0026#34;C\u0026#34; fn set_marked_text( this: \u0026amp;mut Object, _sel: Sel, string: id, _selected_range: NSRange, _replacement_range: NSRange, ) { trace!(\u0026#34;Triggered `setMarkedText`\u0026#34;); unsafe { let marked_text_ref: \u0026amp;mut id = this.get_mut_ivar(\u0026#34;markedText\u0026#34;); let _: () = msg_send![(*marked_text_ref), release]; let marked_text = NSMutableAttributedString::alloc(nil); let has_attr = msg_send![string, isKindOfClass: class!(NSAttributedString)]; if has_attr { marked_text.initWithAttributedString(string); } else { marked_text.initWithString(string); }; *marked_text_ref = marked_text; } trace!(\u0026#34;Completed `setMarkedText`\u0026#34;); } この場合、事前にNSViewオブジェクト内にmarkedTextという変数を用意しておき、仮に日本語入力をしていて確定されてない文字列(未確定文字列、下線がついているやつ)があればOS側がsetMarkedTextを発火してこのmarkedTextに値を当て、hasMarkedTextはそれを参照する。\nNSTextInputClientとはこのようにキーを押したイベントに際して文字列入力の際の一連の処理を行ってくれる規則であり関数の発火を行ってくれるもので、プロトコルを実装するとは実際のアプリケーションでIMEを叩くために各関数の具体的な動作を定義する必要があるのである。\n試験的に動かす 今回Alacrittyを直すためだったが、修正に際して登場するクレートが3つもあるため、それぞれcloneしてくる。\nディレクトリの位置関係としては以下のようになる。\n. ├── alacritty/ │ ├── alacritty/ │ ├── alacritty_config_derive │ ├── alacritty_terminal │ ├── docs │ ├── extra ├── glutin │ ├── glutin │ ├── glutin_egl_sys │ ├── glutin_emscripten_sys │ ├── glutin_examples │ ├── glutin_gles2_sys │ ├── glutin_glx_sys │ └── glutin_wgl_sys └── winit ├── examples ├── src └── tests そしてAlacrittyをローカルで叩くが、依存するクレートをcrates.ioからとってくるのではなくローカルのものをとってきて欲しいのでCargo.tomlの依存クレートを以下のように直す。\nglutin = { version = \u0026#34;0.27.0\u0026#34;, default-features = false, features = [\u0026#34;serde\u0026#34;] } ↓ glutin = { path = \u0026#34;../../glutin/glutin\u0026#34;, version = \u0026#34;0.27.0\u0026#34;, default-features = false, features = [\u0026#34;serde\u0026#34;] } これでローカルのものを参照してくれる。 Glutinでも同様にローカルのWinitを参照するように直す。\nこれらをやった上でAlacrittyのリポジトリでcargo runをすればターミナルが立ち上がる。\nこれで準備OKになった。\nNSTextInputClientの挙動を修正する 下調べなどでものすごく時間がかかってしまったが、ようやく作業に取り掛かる。\nWinitではIMEの挙動を直すために色々structの仕様変更が入ったりしていたが、現在ではKeyboardInputというstructで未確定文字列の有無を格納するフィールドがある。 AlacrittyもWinitもIMEの修正に真っ最中らしく、Alacritty本体でもまだ未確定文字列の処理についてのハンドリングはfixされていない。(Alacrittyの中にskip_eventsという関数があり、その中にKeyboardInput { is_synthetic: true, ..}がある)\n今回動作確認するためにはまずAlacrittyがハンドリングするWindowEventで未確定文字列が存在する場合もキャッチして処理するようパターンマッチングの分岐条件を変更する。\nWindowEvent::KeyboardInput { input, is_synthetic: false, .. } =\u0026gt; { processor.key_input(input); }, ↓ WindowEvent::KeyboardInput { input, .. } =\u0026gt; { processor.key_input(input); }, 次にWinitにて適切にKeyboardInputというstruct内にis_syntheticのboolが適切に入っているか確認する。\nが、見てみるとmacOSについてはまだ暫定的に全てfalseでは入るようになっている。 macOSについてはまだIME対応が完了していない中でstructの仕様を変更が入った経緯ということで、このようなコードになっていた。\n一旦これをいじって直して、早速実際のIMEのコードの修正に取り掛かる。\nsetMarkedTextとinsertTextとdoCommandBySelector IMEの修正にはmacOSのAPIを叩いているコードを障ればよく、Winitのsrc/platform_impl/macos/view.rsがそれに該当する。\nコードの見方として、中段くらいにあるlazy_static! { ... }の部分でクラスの宣言を行なっていてこの中にクラスメソッドや変数の宣言を行う。 宣言された関数についてはその後extern \u0026quot;C\u0026quot; fn ...のようにして具体的な関数の実装を行う。\n宣言されたクラスメソッドは色々あるが、この中でキー入力を担うのがsetMarkedTextとinsertTextとdoCommandBySelectorの3つで、それぞれの役割として\n関数名 役割 setMarkedText 日本語などの入力の際に未確定の文字列をどう扱うかを決める。 insertText 確定文字列をフロントエンドに送る。英語入力の際はデフォルトでこれになる。 doCommandBySelector Cmd-sみたいなキーバインド。文字入力ではなくウィンドウ操作などが対象。 となっている。 文字列をフロントエンドに渡す操作はsetMarkedTextとinsertTextが担っている。\nsetMarkedTextでフロントに都度入力する フロントエンドに文字列を渡す方法として、以下のようにイベント情報のキューにpushしていく。\nlet mut events = VecDeque::with_capacity(characters.len()); events.push_back(EventWrapper::StaticEvent(Event::WindowEvent { window_id: WindowId(get_window_id(state.ns_window)), event: WindowEvent::ReceivedCharacter(character), })); AppState::queue_events(events); この中のevent: WindowEvent::ReceivedCharacter(character)が肝で、insertTextではこのような操作を行なってくれているのだがsetMarkedTextはこの実装が行われていなかった。過去のログを探ってみたところ、どうやら実装者が英語圏の人でsetMarkedTextが何のためにあるのか知らなかったらしい。\nそんなわけでsetMarkedTextにも毎度フロントに文字列をpushするように変更。 setmarkedTextは各キー入力に対して毎回発火するので、全部入力するようにしているとねこと入力したらnねねkねこと何度も入力されまくることになる。 そのため毎回setMarkedTextが起動すると同時に直前の未確定文字列分だけDeleteキーを押す操作を擬似的に行わせる。\nこの操作として直前のカーソル位置の分だけまず全部削除して、その後新規の未確定文字列を全部入力させるという方針を取る。 つまり\nこんにちh ↓ (全部削除) ↓ こんにちは とした。 これで重複を無くすことができる。\n一つ要注意ポイントとして、Rustでは文字列型としてStringと\u0026amp;strがあるが、これらに対してtext.len()としてもUTF-8のデータ長が帰ってきてしまう。 つまり\u0026quot;こんにちは\u0026quot;.len()の値は15となってしまう。 そのため文字数をカウントする場合は\u0026quot;こんにちは\u0026quot;.chars().count()を使うのが正しい。\ninsertTextとsetMarkedTextの二重発火 これで完成かというとそうでもなく、macOSのAPIとして未確定文字列がある場合は毎回のキー入力に対してsetMarkedTextが起動するが、未確定文字列が確定された時はinsertTextが起動する。 つまりこのままだとこんにちはと入力した際にこんにちはこんにちはと2回入力される。 これを防ぐべく、isIMEActivatedという状態を示す変数をViewクラスに実装し、未確定文字列がある場合はtrueとなるようにした上で、これを起点にinsertTextの処理を適切にスキップさせれば良い。\n予測変換への対応 日本語入力を考えた時、漢字への変換などがある。 この変換は多くの場合はSpaceキーや矢印キーを用いて行われる(はず)なのだが、現状のままだと予測変換のためにSpaceキーを押したのに空白が入力されてしまったり、もしくは矢印キーを触ってコマンドヒストリーを取りに行ってしまったりする。\nそのため予測変換のためのキー操作をしているとき(未確定文字列が存在しているとき)、Spaceキーや矢印キーが押されたときは別の動作をさせる必要がある。 この処理はkeyDownの実装をいじれば良く、自前でis_arrow_or_space_keyのような関数を実装した上で、適切に処理をさせれば良い。\n以上でようやくmacOSにてAlacrittyでIMEが有効化されるようになった。\nまとめ 今回バグを直すためにIMEってナニソレ状態から調査を始めて、無事にバグを修正するところまで持っていけた。\nCocoaやAppkitの周辺の日本語情報はあまり転がっていなかったのでなかなか苦労したが、とても良い経験になった気がする。\n最後に出したPRはこちら。\n","categories":["Tech"],"date":1626739200,"description":"日本語のインライン入力を行うためのTextInputClientにおいて実装のメモ","permalink":"http://komi.dev/post/2021-07-20-enabling-ime-in-alacritty/","publishdate":"2021-07-20T00:00:00Z","section":"post","tags":["IME","macOS"],"title":"Alacrittyが日本語入力がおかしいのを直した","url":"/post/2021-07-20-enabling-ime-in-alacritty/"},{"body":"DigdagとGCP Digdagはワークフローエンジンとして有名なソフトで、複数個のタスク間の依存関係からなるワークフローを定義し、そのワークフローの実行及び管理を行う。\n具体的に、複数テーブルのインポートを行いたいとなったとき、それらに対して逐次的にEmbulkを手で叩くのではなく、DigdagがうまいことEmbulkを叩いてくれる。\n+some_job: sh\u0026gt;: embulk run some_table.yaml.liquid そんなDigdagであるが、バッチ処理に非常によく使われるため、GCPやAWSに対応したコマンドがDigdag側に用意されている。 これは本来ならば上記のようにsh\u0026gt;オペレータでシェルでコマンドを叩くが、BigQuery関係だとbq\u0026gt;とかbq_ddl\u0026gt;といったコマンドが用意されている。\n+some_bq_job: bq\u0026gt;: queries/step.sql destination_table: other_project:other_dataset.other_table これは実質的にsh\u0026gt;: bq ...コマンドの糖衣構文だけど、これは比較的便利なのでよく利用される。\nGKEでのクレデンシャルのセット Digdagの公式ドキュメントにはbq\u0026gt;オペレータを利用する際はDigdagのSecretsにサービスアカウントキーをセットするよう書いてある。\nDigdagが動いているコンテナ内で以下のコマンドを叩けば良い。\n$ digdag secret --project [YOUR_PROJECT_NAME] --set gcp.credential=@/path/to/sa_key.json こうするとbq\u0026gt;オペレータを叩く際にこのサービスアカウントとして実行される。\nしかし、ここでポイントとして、このクレデンシャルはコンテナ全体でサービスアカウントが有効化されているわけではない。\nGKEでポッドの中に入ってクレデンシャルを叩くと、GKEを動作しているサービスアカウントが出てくる。\n$ gcloud config list サービスアカウントの有効化 bq\u0026gt;オペレータやbq_ddl\u0026gt;オペレータでは微妙にやりきれない作業などはたまにあり、その際は直接シェルでbqを叩きたいケースがある。\n例えばテーブルのスキーマに説明を付与したくて、そのスキーマ情報はJSONで保存されているときなど。\nこうした際はSQLにCREATE TABLE文でやる方法もあるが、それよりもbq updateでテーブル情報をアップデートする方が簡単だったりする。\nこの場合、意図的にDigdag内でサービスアカウントを有効化させるジョブを挟み込む必要があり、\n+auth_sa: sh\u0026gt;: gcloud auth activate-service-account --key-file=/path/to/sa_key.json +some_job: sh\u0026gt;: bq update my_dataset.my_table schema/my_table.json というようにすればサービスアカウントで実行ができる。\n","categories":["Tech"],"date":1616284800,"description":"DigdagとEmbulkでBigQueryにデータを流す際にクレデンシャルのスイッチでハマったポイント","permalink":"http://komi.dev/post/2021-03-21-gcp-credential-in-digdag/","publishdate":"2021-03-21T00:00:00Z","section":"post","tags":["digdag","gcp"],"title":"GKEにおけるDigdagでのGCPのクレデンシャルの取り扱い","url":"/post/2021-03-21-gcp-credential-in-digdag/"},{"body":"GitHub ActionsとCloud Run CI/CDというと有名なのはCircle CIだろう。 他にはTravis CIやGitLab CIあたり？(Travisはなんかもうすぐ死ぬみたいなのを聞いたような気もするけど)\nそんな中、GitHubが公式に提供しているCI/CDツールとしてGitHub Actionsがある。\n今回行っていた作業はGitHub ActionsからCloud RunへのCD環境を整えることだったのだけど、その過程で色々落とし穴にハマった。\nこれらのCI/CDツールはそれぞれで文法が異なっていたりしたことや、Cloud Runのサービスアカウントのセットにミスったことなどたくさん学んだことがあったので今回はここでまとめておこうと思う。\n設定ファイル 最終的な設定ファイルとしてはこのようになっている。\nname: Deploy to Cloud Run on: push: branches: - master env: ENVIRONMENT: production GCP_SA_KEY: ${{ secrets.GCP_SERVICE_ACCOUNT_KEY }} GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }} GCP_REGION: ${{ secrets.GCP_REGION }} jobs: deploy: name: Setup EC runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v2 # gcloudコマンドの設定 - name: Install gcloud command and configure credentials uses: google-github-actions/setup-gcloud@v0.2.0 with: service_account_key: ${{ env.GCP_SA_KEY }} project_id: ${{ env.GCP_PROJECT_ID }} # DockerにgcloudコマンドのCredentialを使わせる - name: Auth Docker with gcloud credentials run: | gcloud --quiet auth configure-docker # Dockerイメージを作成 (今回はとりあえずEcho Serverで) - name: Build Docker image run: | docker pull ealen/echo-server # DockerイメージをContainer RegistryにPush - name: Publish image run: | export IMAGE_NAME=${ENVIRONMENT}_server export DOCKER_TAG=asia.gcr.io/${GCP_PROJECT_ID}/${IMAGE_NAME}:${GITHUB_SHA::8} docker tag ealen/echo-server $DOCKER_TAG docker push $DOCKER_TAG - name: Deploy run: | gcloud run deploy sample-server \\ --image $DOCKER_TAG \\ --project $GCP_PROJECT_ID \\ --region $GCP_REGION \\ --platform managed \\ --quiet 割と簡単な感じなのだけど地味にハマったポイントがいくつかあったのでまとめておく。\nDockerにCloud SDKのCredentialを使わせる 当初はGitHub Actionsでgcloudコマンドを使えれば良いと思っていて、google-github-actions/setup-gcloudのREADMEに書いてある通りのことだけを設定ファイルに記述していた。\nしかし、今回はCloud Runにデプロイする関係で一度コンテナをContainer Registryへとあげておかなければならない。\nそのためにdocker pushコマンドを叩くわけだけども、このコマンドを叩くにはdocker自体がCloud SDKのCredentialを把握しておく必要がある。\nこれは\n$ gcloud --quiet auth configure-docker で実現される。\n環境変数とGitHub Actionsの変数で文法が違う GitHub Actionsでは環境変数とワークフロー内での変数はレイヤーが異なる。\nワークフロー内のenvオブジェクトに環境変数が入り込むのである。\nワークフロー変数(GITHUB_SHAやenv.GCP_PROJECT_IDなど)を使うには${{ some_value }}として使い、環境変数を使うには${some_value}か${{ env.some_value }}とすれば良い。\nこれの何にハマったかというと、環境変数については${some_value}はオッケーだが${ some_value }はダメなのである。\n空白を入れてはいけないというルール。\n同様に、ワークフロー変数については${{ GITHUB_SHA }}はオッケーだが${{GITHUB_SHA}}はダメである。\nこれに気づかずCIを30回以上コケさせた。\nGCPでの設定 GCPではやるべきことは\nGitHub Actionsで動かす用にサービスアカウントを作成 Cloud RunとContainer Registryで使えるロールを付与 の2点だけ。\nロールの付与については\nService Account User Cloud Run Admin Storage Admin の3つ。\nこれも結構簡単なのだが結構ハマった。\nContainer Registryという名のCloud Storage Container Registryはコンテナのデータベースという感じでDocker Hubみたいなものだが、中身はCloud Storageである。\nそのためサービスアカウントにはCloud Storageの権限を与えれば良いが、Cloud Storageの権限は\nストレージの中身の操作に関するもの(閲覧、作成と消去) 別のサービスへストレージの中身を転送するもの の2つがある。\nセキュリティの観点から最小限の権利だけを与えようと思って1つ目のもののAdminだけを設定したのだが、ずっとPermission Deniedになってしまっていた。\ndenied: Token exchange failed for project \u0026#39;[project-id]\u0026#39;. Caller does not have permission \u0026#39;storage.buckets.create\u0026#39;. To configure permissions, follow instructions at: https://cloud.google.com/container-registry/docs/access-control 色々試してみた結果、Storage全体のAdmin権限を渡したら動くようになった。\nまとめ GitHub ActionsとCloud Runはめちゃくちゃ便利だけど少し慣れていないと罠にハマるので気をつけたい。\n","categories":["Tech"],"date":1611014400,"description":"GitHub ActionsとCloud Runは便利だがCI/CDの設定で今回陥った罠についてツラツラと書く","permalink":"http://komi.dev/post/2021-01-19-cloud-run-from-github-actions/","publishdate":"2021-01-19T00:00:00Z","section":"post","tags":["GitHub Actions","CI","GCP"],"title":"GitHub ActionsからCloud Runを叩く","url":"/post/2021-01-19-cloud-run-from-github-actions/"},{"body":"モチベーション 最近はWebRTCにハマっていて、別に何か作りたいものがあったからというわけでは無いのだけど単純に面白いから見ており、それに際してその周辺技術にぼちぼちコミットしたりしている(こんな感じ)。\nただ実際のところは本当に趣味といった具合なので詳細な部分についてはまだまだ勉強中だったりする。\nそんなわけでこの記事はある程度理解が進んだSDPについての勉強メモみたいな感じ。\nSDPとは まず最初にSDPとググるとだいたいゼロトラストの方のSDPが出てくる。\nゼロトラストのSDPはSoftware Defined Perimeterの略語で、WebRTCのSDPとは全くの別物であることに注意(ただ、WebRTCはP2P通信でファイアウォールなどのネットワークの壁をどう越えるかみたいなところが結構大変で、そこらへんの概念にゼロトラストのSDPみたいな考え方が出てきたりするので無関係というわけではなさそうだけども\u0026hellip;)。\nとりあえず今回の記事ではSDPとはSession Description Protocolだと最初に断っておきたい。\nオファーアンサーモデル さて、WebRTCにおけるSDPの話というわけだけど、WebRTCはP2P通信で、クライアントとクライアントが通信することになる。\n何を通信するかというと、音声だったりテキストだったり画像とか動画。 ただ、前提として各クライアントがどのメディアを使えるかはお互いに確認してみないと分からないのである。\nそこでお互いが何のメディアを使えるかを伝え合う所作をオファーアンサーモデルという。\n具体的には\nアリス「こっち電話とビデオいけるけどそっちどうよ？」 ボブ「あーこっち電話しか使えないんだわ」 的なやり取りである。\n仕様を眺めてみる SDPがP2P通信においてお互いがどのメディアを使用可能か確認するお作法であることはわかったので、具体的にどのようにやっていくかを見ていく。\nクライアント間では以下のようなデータがやり取りされる。\nv=0 o=jdoe 2890844526 2890842807 IN IP4 10.47.16.5 s=SDP Seminar i=A Seminar on the session description protocol u=http://www.example.com/seminars/sdp.pdf e=j.doe@example.com (Jane Doe) c=IN IP4 224.2.17.12/127 t=2873397496 2873404696 a=recvonly m=audio 49170 RTP/AVP 0 m=video 51372 RTP/AVP 99 a=rtpmap:99 h263-1998/90000 このv=とかみたいなのはSDPにおけるDSLみたいなもので、それぞれがセッション情報だったり扱えるメディアについての情報、どのポート番号を解放するかなどを表している。\n簡単にいくと\nv= : セッションのバージョン番号。基本的に0で固定。 o= : 送信元の情報。 s= : セッション名。 i= : セッション情報。 u= : URI e= : メールアドレス。p=で電話番号が書かれることも。 c= : 接続データ。 b= : 帯域。 t= : タイミング、時間。スタートと終わりがUnixタイムで表現される。 r= : 繰り返し回数 z= : タイムゾーン k= : 暗号化キー a= : 属性情報、セッションの拡張情報 m= : メディア記述 という具合。\nこれらは全部が必須というわけではなくオプションのものもあるが、SDPの記述においてはいくつかの制約があったりする。\n具体的に言うと、例えばv=0などでは途中に空白を入れてはいけないことや、vやoなどの出現順序を間違えてはいけないことなどがある。\n詳しい話はこのSlideshareがめちゃくちゃわかりやすく解説してあるが、これの補足をいくつかしておく。\nm=行の数のオファーとアンサーで同一でなければいけないけど、互いに扱えるメディアの数が違う時はどうするの？ 該当するメディアのポート番号を0として解放しない旨を示す 行の並びが指定されているけどm=が複数並んでる時は順序指定ってある？ audioを優先的に上にする。 ここら辺の仕様書は情報通信技術委員会が作ったものが参考になるので確認しよう。\nまた一番詳しいのはRFC4566なのでこれを読もう。\n","categories":["Tech"],"date":1609891200,"description":"WebRTCでは通信条件のネゴシエーションが必要だが、これを実現するためにSDPがある。ここではSDPがどのような形をしているかを見ていく。","permalink":"http://komi.dev/post/2021-01-06-about-sdp/","publishdate":"2021-01-06T00:00:00Z","section":"post","tags":["WebRTC","SDP"],"title":"WebRTCにおけるSDPを理解する","url":"/post/2021-01-06-about-sdp/"}]